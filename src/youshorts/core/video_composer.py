# ë³€ê²½ ì‚¬ìœ : ì‚¬ì¸íŒŒ BGM ì œê±° â†’ MP3 ë¡œë”©, BGM ë•í‚¹, ì¹´ìš´íŠ¸ë‹¤ìš´/whoosh ì œê±°, Ken Burns íš¨ê³¼, í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ 1ì´ˆ, í”„ë¡œê·¸ë ˆìŠ¤ ë°” ìƒë‹¨ 3px
"""ì˜ìƒ í•©ì„± ì—”ì§„.

ë°°ê²½ ë¸”ëŸ¬, Ken Burns íš¨ê³¼, í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ, íƒ€ì´í‹€ ìŠ¬ë¼ì´ë“œì¸,
ìë§‰, ì‹œê° íš¨ê³¼ë¥¼ ë ˆì´ì–´ë§í•˜ì—¬ ìµœì¢… MP4 ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.
ì‚¬ì¸íŒŒ BGMì„ ì™„ì „íˆ ì œê±°í•˜ê³  ë¡œì—´í‹° í”„ë¦¬ MP3ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
"""

from __future__ import annotations

import gc
import glob
import os
import random
import re
import subprocess
import shutil
from datetime import datetime
from typing import Any

import numpy as np
from PIL import Image, ImageDraw, ImageFilter

from youshorts.config.constants import (
    BG_BLUR_RADIUS,
    BG_DARKEN_OPACITY,
    BOTTOM_BAR_HEIGHT,
    CROSSFADE_DURATION,
    KEN_BURNS_ZOOM_PER_5SEC,
    PROGRESS_BAR_COLOR,
    PROGRESS_BAR_HEIGHT,
    SUBTITLE_Y_RATIO,
    TRANSITION_INTERVAL,
)
from youshorts.config.settings import Settings, get_settings
from youshorts.config.styles import EDIT_STYLES
from youshorts.rendering.subtitle_engine import (
    create_bottom_bar,
    create_subtitle_image,
    create_title_bar,
    get_section_for_time,
)
from youshorts.rendering.visual_effects import generate_visual_effects_for_script
from youshorts.utils.file_handler import ensure_dir
from youshorts.utils.logger import get_logger

logger = get_logger(__name__)

try:
    from moviepy.editor import (
        AudioFileClip,
        ColorClip,
        CompositeAudioClip,
        CompositeVideoClip,
        ImageClip,
        VideoFileClip,
    )
except ImportError:
    from moviepy import (
        AudioFileClip,
        ColorClip,
        CompositeAudioClip,
        CompositeVideoClip,
        ImageClip,
        VideoFileClip,
    )


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# FFmpeg ì§ì ‘ í˜¸ì¶œ í•¨ìˆ˜ (OOM í•´ê²°)
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


def get_ffmpeg_path() -> str | None:
    """FFmpeg ê²½ë¡œ ìë™ íƒì§€.

    Returns:
        FFmpeg ì‹¤í–‰ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None.
    """
    path = shutil.which('ffmpeg')
    if path:
        return path
    try:
        import imageio_ffmpeg
        return imageio_ffmpeg.get_ffmpeg_exe()
    except ImportError:
        pass
    common = [
        r'C:\ffmpeg\bin\ffmpeg.exe',
        r'C:\Program Files\ffmpeg\bin\ffmpeg.exe',
        r'C:\tool\ffmpeg\bin\ffmpeg.exe',
    ]
    for p in common:
        if os.path.exists(p):
            return p
    return None


def render_with_ffmpeg(
    bg_video: str,
    tts_audio: str,
    subtitle_file: str,
    output_path: str,
    config: dict[str, Any],
) -> str:
    """FFmpeg ì§ì ‘ ë Œë”ë§. MoviePy ëŒ€ë¹„ ë©”ëª¨ë¦¬ 1/10.

    ASS ìë§‰(ì›Œë“œ í•˜ì´ë¼ì´íŠ¸) ë˜ëŠ” SRT ìë§‰ ìë™ ê°ì§€.

    Args:
        bg_video: ë°°ê²½ ì˜ìƒ ê²½ë¡œ.
        tts_audio: TTS ì˜¤ë””ì˜¤ ê²½ë¡œ.
        subtitle_file: ASS ë˜ëŠ” SRT ìë§‰ íŒŒì¼ ê²½ë¡œ.
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ.
        config: ëœë¤í™” ì„¤ì • (font_size, margin_v, bg_darken ë“±).

    Returns:
        ì¶œë ¥ íŒŒì¼ ê²½ë¡œ.

    Raises:
        FileNotFoundError: FFmpeg ë¯¸ì„¤ì¹˜ ì‹œ.
        RuntimeError: FFmpeg ì‹¤í–‰ ì‹¤íŒ¨ ì‹œ.
    """
    ffmpeg = get_ffmpeg_path()
    if not ffmpeg:
        raise FileNotFoundError("FFmpeg ë¯¸ì„¤ì¹˜. pip install imageio-ffmpeg ë˜ëŠ” ì‹œìŠ¤í…œ PATHì— ì¶”ê°€í•˜ì„¸ìš”.")

    ensure_dir(os.path.join(os.getcwd(), 'temp'))
    darken = config.get('bg_darken', 0.25)
    brightness = round(-darken, 2)

    # ASS vs SRT ìë™ ê°ì§€
    is_ass = subtitle_file.endswith('.ass')

    if is_ass:
        # ASS ìë§‰: ìŠ¤íƒ€ì¼ì´ íŒŒì¼ì— ë‚´ì¥ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ass= í•„í„° ì‚¬ìš©
        safe_sub = os.path.join('temp', 'sub.ass')
        shutil.copy2(subtitle_file, safe_sub)
        safe_sub_escaped = safe_sub.replace('\\', '/').replace(':', '\\\\:')
        vf_filter = f"eq=brightness={brightness}:contrast=1.1,ass='{safe_sub_escaped}'"
        logger.info("[ë Œë”ë§] ASS ì›Œë“œ í•˜ì´ë¼ì´íŠ¸ ìë§‰ ì‚¬ìš©")
    else:
        # SRT ìë§‰: force_style ì‚¬ìš© (ê¸°ì¡´ ë¡œì§)
        safe_sub = os.path.join('temp', 'sub.srt')
        shutil.copy2(subtitle_file, safe_sub)
        safe_sub_escaped = safe_sub.replace('\\', '/').replace(':', '\\\\:')
        font_size = config.get('font_size', 30)
        margin_v = config.get('margin_v', 25)
        subtitle_style = (
            f"FontSize={font_size},"
            f"PrimaryColour=&H00FFFFFF,"
            f"OutlineColour=&H00000000,"
            f"BackColour=&H80000000,"
            f"BorderStyle=3,"
            f"Outline=2,"
            f"Shadow=1,"
            f"Alignment=2,"
            f"MarginV={margin_v}"
        )
        vf_filter = f"eq=brightness={brightness}:contrast=1.1,subtitles='{safe_sub_escaped}':force_style='{subtitle_style}'"

    cmd = [
        ffmpeg, '-y',
        '-i', bg_video,
        '-i', tts_audio,
        '-vf', vf_filter,
        '-c:v', 'libx264',
        '-preset', 'fast',
        '-crf', '23',
        '-c:a', 'aac',
        '-b:a', '128k',
        '-shortest',
        '-fps_mode', 'cfr',
        '-r', '24',
        '-s', '1080x1920',
        output_path
    ]

    logger.info("[ë Œë”ë§] FFmpeg ì‹œì‘: %s", output_path)
    result = subprocess.run(cmd, capture_output=True, timeout=600)
    if result.returncode != 0:
        stderr = result.stderr.decode("utf-8", errors="ignore") if isinstance(result.stderr, bytes) else (result.stderr or "")
        logger.error("[FFmpeg ì—ëŸ¬] %s", stderr[-500:])
        raise RuntimeError(f"FFmpeg ì‹¤íŒ¨: returncode={result.returncode}")
    logger.info("[ë Œë”ë§] FFmpeg ì™„ë£Œ: %s", output_path)
    return output_path


def merge_bg_clips_ffmpeg(clip_paths: list[str], output_path: str) -> str:
    """ë°°ê²½ í´ë¦½ë“¤ì„ FFmpeg concatìœ¼ë¡œ í•©ì¹˜ê¸° (ë©”ëª¨ë¦¬ 0 ì‚¬ìš©).

    Args:
        clip_paths: ë°°ê²½ í´ë¦½ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸.
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ.

    Returns:
        ì¶œë ¥ íŒŒì¼ ê²½ë¡œ.
    """
    ffmpeg = get_ffmpeg_path()
    if not ffmpeg:
        raise FileNotFoundError("FFmpeg ë¯¸ì„¤ì¹˜")

    ensure_dir(os.path.join(os.getcwd(), 'temp'))
    concat_list = os.path.join('temp', 'concat_list.txt')
    with open(concat_list, 'w', encoding='utf-8') as f:
        for clip in clip_paths:
            safe = clip.replace('\\', '/')
            f.write(f"file '{safe}'\n")

    cmd = [
        ffmpeg, '-y',
        '-f', 'concat', '-safe', '0',
        '-i', concat_list,
        '-c', 'copy',
        '-an',  # ì˜¤ë””ì˜¤ ì œê±° (TTSë¡œ êµì²´í•  ê±°ë‹ˆê¹Œ)
        output_path
    ]
    result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
    if result.returncode != 0:
        logger.warning("[FFmpeg concat ì‹¤íŒ¨] %s", result.stderr[-200:] if result.stderr else "")
    return output_path


def _img_to_clip(
    img_array: np.ndarray,
    duration: float,
    start_time: float,
    y_ratio: float = 0.5,
    video_height: int = 1920,
) -> ImageClip:
    """RGBA ì´ë¯¸ì§€ ë°°ì—´ì„ moviepy í´ë¦½ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        img_array: RGBA numpy ë°°ì—´.
        duration: í´ë¦½ ê¸¸ì´ (ì´ˆ).
        start_time: ì‹œì‘ ì‹œê°„ (ì´ˆ).
        y_ratio: ìˆ˜ì§ ìœ„ì¹˜ ë¹„ìœ¨ (0~1).
        video_height: ì˜ìƒ ë†’ì´.

    Returns:
        ìœ„ì¹˜ê°€ ì§€ì •ëœ ImageClip.
    """
    rgb = img_array[:, :, :3]
    alpha = img_array[:, :, 3].astype(float) / 255.0

    clip = ImageClip(rgb).set_duration(duration).set_start(start_time)
    mask = ImageClip(alpha, ismask=True).set_duration(duration).set_start(start_time)
    clip = clip.set_mask(mask)

    y = max(0, int(video_height * y_ratio - img_array.shape[0] / 2))
    clip = clip.set_position((0, y))
    return clip


def _img_to_clip_pos(
    img_array: np.ndarray,
    duration: float,
    start_time: float,
    x: int = 0,
    y: int = 0,
) -> ImageClip:
    """ì ˆëŒ€ ì¢Œí‘œë¡œ ë°°ì¹˜í•˜ëŠ” í´ë¦½.

    Args:
        img_array: RGBA numpy ë°°ì—´.
        duration: í´ë¦½ ê¸¸ì´.
        start_time: ì‹œì‘ ì‹œê°„.
        x: X ì¢Œí‘œ.
        y: Y ì¢Œí‘œ.

    Returns:
        ìœ„ì¹˜ê°€ ì§€ì •ëœ ImageClip.
    """
    rgb = img_array[:, :, :3]
    alpha = img_array[:, :, 3].astype(float) / 255.0

    clip = ImageClip(rgb).set_duration(duration).set_start(start_time)
    mask = ImageClip(alpha, ismask=True).set_duration(duration).set_start(start_time)
    clip = clip.set_mask(mask)
    clip = clip.set_position((x, y))
    return clip


def _fit_to_vertical(
    clip: VideoFileClip,
    video_width: int,
    video_height: int,
) -> VideoFileClip:
    """ì˜ìƒì„ ì„¸ë¡œ í™”ë©´ì— ë§ê²Œ í¬ë¡­í•©ë‹ˆë‹¤."""
    scale = max(video_width / clip.w, video_height / clip.h)
    new_w = int(clip.w * scale)
    new_h = int(clip.h * scale)
    resized = clip.resize((new_w, new_h))
    x1 = (new_w - video_width) // 2
    y1 = (new_h - video_height) // 2
    return resized.crop(x1=x1, y1=y1, x2=x1 + video_width, y2=y1 + video_height)


def _apply_blur_to_clip(clip: VideoFileClip, radius: int = BG_BLUR_RADIUS) -> VideoFileClip:
    """í”„ë ˆì„ ë‹¨ìœ„ë¡œ ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¥¼ ì ìš©í•©ë‹ˆë‹¤."""
    def blur_frame(get_frame: Any, t: float) -> np.ndarray:
        frame = get_frame(t)
        img = Image.fromarray(frame)
        blurred = img.filter(ImageFilter.GaussianBlur(radius=radius))
        return np.array(blurred, dtype=np.uint8)
    return clip.fl(blur_frame)


def _apply_ken_burns(
    clip: Any,
    video_width: int,
    video_height: int,
    zoom_per_5sec: float = KEN_BURNS_ZOOM_PER_5SEC,
    effect_type: str | None = None,
) -> Any:
    """Ken Burns íš¨ê³¼ë¥¼ ì ìš©í•©ë‹ˆë‹¤ (ëœë¤ ì¤Œì¸/ì¤Œì•„ì›ƒ/íŒ¬).

    ë³€ê²½ ì‚¬ìœ : í•œêµ­í˜• ìˆì¸  - ì •ì  ëŠë‚Œ ì œê±°ë¥¼ ìœ„í•œ ëœë¤ ì¹´ë©”ë¼ íš¨ê³¼
    - zoom_in: 1.0 â†’ 1.05 (5ì´ˆê°„) í™•ëŒ€
    - zoom_out: 1.05 â†’ 1.0 (5ì´ˆê°„) ì¶•ì†Œ
    - pan_left: ì¢Œâ†’ìš° ìˆ˜í‰ ì´ë™
    - pan_right: ìš°â†’ì¢Œ ìˆ˜í‰ ì´ë™

    Args:
        clip: ë°°ê²½ ë¹„ë””ì˜¤/ì´ë¯¸ì§€ í´ë¦½.
        video_width: ì˜ìƒ ë„ˆë¹„.
        video_height: ì˜ìƒ ë†’ì´.
        zoom_per_5sec: 5ì´ˆë‹¹ ì¤Œ ë¹„ìœ¨.
        effect_type: íš¨ê³¼ ì¢…ë¥˜ (Noneì´ë©´ ëœë¤).

    Returns:
        Ken Burns íš¨ê³¼ê°€ ì ìš©ëœ í´ë¦½.
    """
    if effect_type is None:
        effect_type = random.choice(["zoom_in", "zoom_out", "pan_left", "pan_right"])

    def ken_burns_frame(get_frame: Any, t: float) -> np.ndarray:
        frame = get_frame(t)
        h, w = frame.shape[:2]
        duration = clip.duration if clip.duration > 0 else 5.0
        progress = t / duration  # 0.0 ~ 1.0

        if effect_type == "zoom_in":
            zoom = 1.0 + progress * zoom_per_5sec * (duration / 5.0)
        elif effect_type == "zoom_out":
            zoom = 1.0 + zoom_per_5sec * (duration / 5.0) - progress * zoom_per_5sec * (duration / 5.0)
        else:
            zoom = 1.0 + zoom_per_5sec  # íŒ¬ íš¨ê³¼ ì‹œ ì•½ê°„ ì¤Œ

        new_h = int(h * zoom)
        new_w = int(w * zoom)

        img = Image.fromarray(frame)
        img = img.resize((new_w, new_h), Image.LANCZOS)

        if effect_type == "pan_left":
            # ì¢Œâ†’ìš° íŒ¬: x ì˜¤í”„ì…‹ì´ ì ì  ì¦ê°€
            max_offset = new_w - w
            x1 = int(max_offset * progress)
            y1 = (new_h - h) // 2
        elif effect_type == "pan_right":
            # ìš°â†’ì¢Œ íŒ¬: x ì˜¤í”„ì…‹ì´ ì ì  ê°ì†Œ
            max_offset = new_w - w
            x1 = int(max_offset * (1.0 - progress))
            y1 = (new_h - h) // 2
        else:
            # ì¤Œì¸/ì¤Œì•„ì›ƒ: ì¤‘ì•™ ê¸°ì¤€
            x1 = (new_w - w) // 2
            y1 = (new_h - h) // 2

        x1 = max(0, min(x1, new_w - w))
        y1 = max(0, min(y1, new_h - h))
        img = img.crop((x1, y1, x1 + w, y1 + h))

        return np.array(img, dtype=np.uint8)

    return clip.fl(ken_burns_frame)


def _fit_image_to_vertical(
    img_path: str,
    video_width: int,
    video_height: int,
) -> np.ndarray:
    """ì •ì  ì´ë¯¸ì§€ë¥¼ ì„¸ë¡œ í™”ë©´(1080x1920)ì— ë§ê²Œ í¬ë¡­+ë¦¬ì‚¬ì´ì¦ˆí•©ë‹ˆë‹¤.

    Args:
        img_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ.
        video_width: ì˜ìƒ ë„ˆë¹„.
        video_height: ì˜ìƒ ë†’ì´.

    Returns:
        í¬ë¡­+ë¦¬ì‚¬ì´ì¦ˆëœ numpy ë°°ì—´.
    """
    img = Image.open(img_path).convert("RGB")
    target_ratio = video_width / video_height

    img_ratio = img.width / img.height
    if img_ratio > target_ratio:
        new_w = int(img.height * target_ratio)
        left = (img.width - new_w) // 2
        img = img.crop((left, 0, left + new_w, img.height))
    else:
        new_h = int(img.width / target_ratio)
        top = (img.height - new_h) // 2
        img = img.crop((0, top, img.width, top + new_h))

    img = img.resize((video_width, video_height), Image.LANCZOS)
    return np.array(img, dtype=np.uint8)


def _prepare_screenshot_bg(
    img_path: str,
    video_width: int,
    video_height: int,
    blur_radius: int = 3,
    brightness: float = 0.4,
) -> np.ndarray:
    """ìŠ¤í¬ë¦°ìƒ·ì„ ë°°ê²½ìš©ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤ (í¬ë¡­ + ë¸”ëŸ¬ + ì–´ë‘¡ê²Œ).

    Args:
        img_path: ìŠ¤í¬ë¦°ìƒ· íŒŒì¼ ê²½ë¡œ.
        video_width: ì˜ìƒ ë„ˆë¹„.
        video_height: ì˜ìƒ ë†’ì´.
        blur_radius: ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ ë°˜ê²½.
        brightness: ë°ê¸° ë¹„ìœ¨ (0.4 = 40% ë°ê¸°).

    Returns:
        ì²˜ë¦¬ëœ numpy ë°°ì—´.
    """
    from PIL import ImageEnhance

    img = Image.open(img_path).convert("RGB")
    target_ratio = video_width / video_height

    # 9:16 ë¹„ìœ¨ë¡œ í¬ë¡­+ë¦¬ì‚¬ì´ì¦ˆ
    img_ratio = img.width / img.height
    if img_ratio > target_ratio:
        new_w = int(img.height * target_ratio)
        left = (img.width - new_w) // 2
        img = img.crop((left, 0, left + new_w, img.height))
    else:
        new_h = int(img.width / target_ratio)
        top = (img.height - new_h) // 2
        img = img.crop((0, top, img.width, top + new_h))

    img = img.resize((video_width, video_height), Image.LANCZOS)

    # ë¸”ëŸ¬ (ë°°ê²½ì´ë‹ˆê¹Œ ì ë‹¹íˆ)
    img = img.filter(ImageFilter.GaussianBlur(radius=blur_radius))

    # ì–´ë‘¡ê²Œ (ìë§‰ ê°€ë…ì„±)
    enhancer = ImageEnhance.Brightness(img)
    img = enhancer.enhance(brightness)

    return np.array(img, dtype=np.uint8)


def _generate_gradient_background(
    video_width: int,
    video_height: int,
    colors: tuple[str, ...],
    direction: str = "vertical",
) -> np.ndarray:
    """ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        video_width: ì˜ìƒ ë„ˆë¹„
        video_height: ì˜ìƒ ë†’ì´
        colors: ê·¸ë¼ë°ì´ì…˜ ìƒ‰ìƒ íŠœí”Œ (2ê°œ ë˜ëŠ” 3ê°œ)
        direction: ê·¸ë¼ë°ì´ì…˜ ë°©í–¥ ("vertical" | "horizontal" | "diagonal")

    Returns:
        RGB numpy ë°°ì—´
    """
    def hex_to_rgb(hex_color: str) -> tuple[int, int, int]:
        """í—¥ìŠ¤ ìƒ‰ìƒì„ RGB íŠœí”Œë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        hex_color = hex_color.lstrip("#")
        return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))  # type: ignore

    rgb_colors = [hex_to_rgb(c) for c in colors]

    # ê·¸ë¼ë°ì´ì…˜ ì´ë¯¸ì§€ ìƒì„±
    img = Image.new("RGB", (video_width, video_height))
    pixels = img.load()

    if direction == "vertical":
        # ìƒâ†’í•˜ ê·¸ë¼ë°ì´ì…˜
        for y in range(video_height):
            # ìƒ‰ìƒ ë³´ê°„ ìœ„ì¹˜ ê³„ì‚°
            if len(rgb_colors) == 2:
                t = y / video_height
                color = tuple(
                    int(rgb_colors[0][i] * (1 - t) + rgb_colors[1][i] * t)
                    for i in range(3)
                )
            else:  # 3ìƒ‰
                if y < video_height // 2:
                    t = y / (video_height // 2)
                    color = tuple(
                        int(rgb_colors[0][i] * (1 - t) + rgb_colors[1][i] * t)
                        for i in range(3)
                    )
                else:
                    t = (y - video_height // 2) / (video_height // 2)
                    color = tuple(
                        int(rgb_colors[1][i] * (1 - t) + rgb_colors[2][i] * t)
                        for i in range(3)
                    )

            for x in range(video_width):
                pixels[x, y] = color  # type: ignore

    elif direction == "horizontal":
        # ì¢Œâ†’ìš° ê·¸ë¼ë°ì´ì…˜
        for x in range(video_width):
            if len(rgb_colors) == 2:
                t = x / video_width
                color = tuple(
                    int(rgb_colors[0][i] * (1 - t) + rgb_colors[1][i] * t)
                    for i in range(3)
                )
            else:
                if x < video_width // 2:
                    t = x / (video_width // 2)
                    color = tuple(
                        int(rgb_colors[0][i] * (1 - t) + rgb_colors[1][i] * t)
                        for i in range(3)
                    )
                else:
                    t = (x - video_width // 2) / (video_width // 2)
                    color = tuple(
                        int(rgb_colors[1][i] * (1 - t) + rgb_colors[2][i] * t)
                        for i in range(3)
                    )

            for y in range(video_height):
                pixels[x, y] = color  # type: ignore

    elif direction == "diagonal":
        # ëŒ€ê°ì„  ê·¸ë¼ë°ì´ì…˜
        max_dist = (video_width**2 + video_height**2) ** 0.5
        for y in range(video_height):
            for x in range(video_width):
                dist = (x**2 + y**2) ** 0.5
                t = dist / max_dist
                if len(rgb_colors) == 2:
                    color = tuple(
                        int(rgb_colors[0][i] * (1 - t) + rgb_colors[1][i] * t)
                        for i in range(3)
                    )
                else:
                    if t < 0.5:
                        t_scaled = t * 2
                        color = tuple(
                            int(rgb_colors[0][i] * (1 - t_scaled) + rgb_colors[1][i] * t_scaled)
                            for i in range(3)
                        )
                    else:
                        t_scaled = (t - 0.5) * 2
                        color = tuple(
                            int(rgb_colors[1][i] * (1 - t_scaled) + rgb_colors[2][i] * t_scaled)
                            for i in range(3)
                        )

                pixels[x, y] = color  # type: ignore

    return np.array(img, dtype=np.uint8)


def _build_background(
    bg_paths: list[str],
    total_dur: float,
    edit_style: str,
    video_width: int,
    video_height: int,
    enable_ken_burns: bool = True,
    is_screenshot_bg: bool = False,
    gradient_colors: tuple[str, ...] | None = None,
) -> CompositeVideoClip | ColorClip:
    """ë°°ê²½ ì˜ìƒì„ êµ¬ì„±í•©ë‹ˆë‹¤.

    1ì´ˆ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ, Ken Burns íš¨ê³¼ë¥¼ ì ìš©í•©ë‹ˆë‹¤.
    is_screenshot_bg=Trueì´ë©´ ìŠ¤í¬ë¦°ìƒ·ì— ëŒ€í•´ ë¸”ëŸ¬+ì–´ë‘¡ê²Œ ì „ì²˜ë¦¬ í›„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    gradient_colorsê°€ ì£¼ì–´ì§€ë©´ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not bg_paths:
        # ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ ì‚¬ìš©
        if gradient_colors:
            gradient_img = _generate_gradient_background(
                video_width, video_height, gradient_colors, direction="vertical"
            )
            return ImageClip(gradient_img).set_duration(total_dur)
        else:
            # ê¸°ë³¸ ë‹¨ìƒ‰ ë°°ê²½
            return ColorClip(
                (video_width, video_height), color=(18, 18, 32)
            ).set_duration(total_dur)

    bg_clips = []
    for path in bg_paths:
        try:
            if path.endswith(".png") or path.endswith(".jpg"):
                if is_screenshot_bg:
                    processed = _prepare_screenshot_bg(
                        path, video_width, video_height,
                    )
                    c = ImageClip(processed).set_duration(total_dur)
                else:
                    c = ImageClip(path).set_duration(total_dur)
            else:
                c = VideoFileClip(path)
                c = _fit_to_vertical(c, video_width, video_height)
            # ë³€ê²½ ì‚¬ìœ : ë§Œì¡±ê° ë°°ê²½ì€ ë¸”ëŸ¬ ì œê±° (ì„ ëª…í•´ì•¼ í•¨)
            # ë¸”ëŸ¬ëŠ” ìŠ¤í¬ë¦°ìƒ· ë°°ê²½ ë˜ëŠ” blur_radius > 0ì¼ ë•Œë§Œ ì ìš©
            if is_screenshot_bg:
                c = _apply_blur_to_clip(c, radius=3)
            elif BG_BLUR_RADIUS > 0:
                c = _apply_blur_to_clip(c, radius=BG_BLUR_RADIUS)
            if enable_ken_burns:
                # ë³€ê²½ ì‚¬ìœ : ì¤Œì¸/ì¤Œì•„ì›ƒ êµì°¨ ì ìš© (ë§¤ í´ë¦½ë§ˆë‹¤ ë‹¤ë¥¸ íš¨ê³¼)
                effects = ["zoom_in", "zoom_out", "zoom_in", "zoom_out"]
                effect_type = effects[len(bg_clips) % len(effects)]
                c = _apply_ken_burns(c, video_width, video_height, effect_type=effect_type)
            bg_clips.append(c)
        except Exception as e:
            logger.warning("ë°°ê²½ ë¡œë“œ ì‹¤íŒ¨: %s", e)

    if not bg_clips:
        return ColorClip(
            (video_width, video_height), color=(18, 18, 32)
        ).set_duration(total_dur)

    # ë³€ê²½ ì‚¬ìœ : í•œêµ­í˜• ìˆì¸  ì»· í¸ì§‘ ìŠ¤íƒ€ì¼
    # - 4-6ì´ˆ ê°„ê²© ë°°ê²½ ì „í™˜ (ìŠ¤íƒ€ì¼ë³„ ì°¨ì´)
    # - ë‹¨ì¼ ë°°ê²½ ìµœëŒ€ 10ì´ˆ ì œí•œ
    # - 0.3ì´ˆ í¬ë¡œìŠ¤í˜ì´ë“œ
    interval = TRANSITION_INTERVAL  # ê¸°ë³¸ 5ì´ˆ
    if edit_style == "dynamic":
        interval = 4
    elif edit_style == "cinematic":
        interval = 6
    elif edit_style == "energetic":
        interval = 3
    elif edit_style == "storytelling":
        interval = 5  # í•œêµ­í˜•: ì ë‹¹í•œ í˜¸í¡

    fade_dur = CROSSFADE_DURATION  # 0.0ì´ˆ (í•˜ë“œì»·)

    # ë‹¨ì¼ ë°°ê²½ ìµœëŒ€ 10ì´ˆ ì œí•œ
    MAX_SINGLE_BG_SEC = 10

    segments = []
    num_segments = int(total_dur / interval) + 1
    seg_dur = min(interval, MAX_SINGLE_BG_SEC)

    for i in range(num_segments):
        clip = bg_clips[i % len(bg_clips)]
        max_start = max(0, clip.duration - seg_dur)
        # ë³€ê²½ ì‚¬ìœ : ê° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ë” ë„“ê²Œ ë¶„ì‚°ì‹œì¼œ ë°˜ë³µ ëŠë‚Œ ì œê±°
        start_pos = (i * 3.7) % max(max_start, 0.1)
        end_pos = min(start_pos + seg_dur, clip.duration)
        seg = clip.subclip(start_pos, end_pos)
        if seg.duration < seg_dur:
            seg = seg.loop(duration=seg_dur)
        seg = seg.set_start(i * interval)
        # ë³€ê²½ ì‚¬ìœ : í•˜ë“œì»· (í˜ì´ë“œ ì—†ì´ ë°”ë¡œ ì „í™˜)
        # ë ˆí¼ëŸ°ìŠ¤ ì±„ë„ ìŠ¤íƒ€ì¼: ì‡¼ì¸ ì—ì„œëŠ” í•˜ë“œì»·ì´ ë” ìì—°ìŠ¤ëŸ¬ì›€
        if fade_dur > 0 and i > 0:
            seg = seg.crossfadein(fade_dur)
        segments.append(seg)

    bg = CompositeVideoClip(segments, size=(video_width, video_height))
    return bg.set_duration(total_dur)


def _build_overlay(
    total_dur: float,
    video_width: int,
    video_height: int,
) -> ColorClip:
    """ë°°ê²½ ì–´ë‘¡ê²Œ ì˜¤ë²„ë ˆì´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    return (
        ColorClip((video_width, video_height), color=(0, 0, 0))
        .set_opacity(BG_DARKEN_OPACITY)
        .set_duration(total_dur)
    )


def _build_progress_bar(
    total_dur: float,
    video_width: int,
) -> Any:
    """ìƒë‹¨ 3px ì–‡ì€ í”„ë¡œê·¸ë ˆìŠ¤ ë°”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ì˜ìƒ ìµœìƒë‹¨ì— ì§„í–‰ë¥ ì„ ë‚˜íƒ€ë‚´ëŠ” ì–‡ì€ ë¼ì¸ì…ë‹ˆë‹¤.

    Args:
        total_dur: ì „ì²´ ì˜ìƒ ê¸¸ì´ (ì´ˆ).
        video_width: ì˜ìƒ ë„ˆë¹„.

    Returns:
        í”„ë¡œê·¸ë ˆìŠ¤ ë°” í´ë¦½.
    """
    bar_h = PROGRESS_BAR_HEIGHT
    color = PROGRESS_BAR_COLOR

    def make_frame(t: float) -> np.ndarray:
        progress = t / total_dur if total_dur > 0 else 0
        bar_w = int(video_width * progress)
        frame = np.zeros((bar_h, video_width, 3), dtype=np.uint8)
        if bar_w > 0:
            frame[:, :bar_w] = color
        return frame

    clip = ColorClip((video_width, bar_h), color=(0, 0, 0)).set_duration(total_dur)
    clip = clip.fl(lambda gf, t: make_frame(t))
    clip = clip.set_position((0, 0))
    return clip


def _load_bgm(bgm_dir: str) -> str | None:
    """data/bgm/ í´ë”ì—ì„œ ëœë¤ BGM íŒŒì¼ì„ ì„ íƒí•©ë‹ˆë‹¤.

    Args:
        bgm_dir: BGM ë””ë ‰í† ë¦¬ ê²½ë¡œ.

    Returns:
        BGM íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None.
    """
    if not os.path.isdir(bgm_dir):
        return None

    bgm_files = glob.glob(os.path.join(bgm_dir, "*.mp3"))
    bgm_files += glob.glob(os.path.join(bgm_dir, "*.wav"))
    bgm_files += glob.glob(os.path.join(bgm_dir, "*.ogg"))

    if not bgm_files:
        return None

    selected = random.choice(bgm_files)
    logger.info("BGM ì„ íƒ: %s", os.path.basename(selected))
    return selected


def _build_subtitle_clips(
    words: list[dict[str, Any]],
    script: dict[str, Any],
    time_offset: float,
    total_dur: float,
    video_height: int,
    font_size_override: int | None = None,
    y_ratio_override: float | None = None,
    highlight_color_override: tuple[int, int, int] | None = None,
) -> list[ImageClip]:
    """ìë§‰ í´ë¦½ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    community ìŠ¤íƒ€ì¼: subtitle_chunksì˜ emotion/highlight ì •ë³´ë¥¼ ìë§‰ì— ë°˜ì˜í•©ë‹ˆë‹¤.
    ëœë¤í™” íŒŒë¼ë¯¸í„°ë¥¼ ë°›ì•„ AI íƒì§€ íšŒí”¼ì— í™œìš©í•©ë‹ˆë‹¤.
    """
    clips: list[ImageClip] = []
    keywords = script.get("keywords", [])
    color_idx = 0
    y_ratio = y_ratio_override if y_ratio_override is not None else SUBTITLE_Y_RATIO

    # community ìŠ¤íƒ€ì¼ subtitle_chunksì—ì„œ emotion/highlight ë§¤í•‘ êµ¬ì¶•
    sub_chunks = script.get("subtitle_chunks", [])
    chunk_map: dict[str, dict[str, str]] = {}
    for chunk in sub_chunks:
        chunk_text = chunk.get("text", "").strip()
        if chunk_text:
            chunk_map[chunk_text] = {
                "emotion": chunk.get("emotion", ""),
                "highlight": chunk.get("highlight", ""),
            }

    for g in words:
        dur = max(g["end"] - g["start"], 0.3)
        start = g["start"] + time_offset
        if start >= total_dur:
            break

        section = get_section_for_time(start, total_dur)
        word_text = g["text"]

        # subtitle_chunksì—ì„œ emotion/highlight ë§¤ì¹­ ì‹œë„
        emotion = ""
        highlight = ""
        if chunk_map:
            # ì •í™• ë§¤ì¹­
            if word_text in chunk_map:
                emotion = chunk_map[word_text].get("emotion", "")
                highlight = chunk_map[word_text].get("highlight", "")
            else:
                # ë¶€ë¶„ ë§¤ì¹­: ìë§‰ í…ìŠ¤íŠ¸ê°€ chunk textì— í¬í•¨ë˜ê±°ë‚˜ ë°˜ëŒ€
                for ct, cv in chunk_map.items():
                    if ct in word_text or word_text in ct:
                        emotion = cv.get("emotion", "")
                        highlight = cv.get("highlight", "")
                        break

        img = create_subtitle_image(
            word_text,
            keywords=keywords,
            color_idx=color_idx,
            is_hook=(section == "hook"),
            section=section,
            emotion=emotion,
            highlight=highlight,
            font_size_override=font_size_override,
            highlight_color_override=highlight_color_override,
        )

        clip = _img_to_clip(img, dur, start, y_ratio=y_ratio, video_height=video_height)
        # ìë§‰ í˜ì´ë“œì¸/ì•„ì›ƒ 0.1ì´ˆ
        clip = clip.fadein(0.1).fadeout(0.1)
        clips.append(clip)
        color_idx += 1

    return clips


def _create_outro_overlay(
    video_width: int,
    video_height: int,
) -> np.ndarray:
    """'ì¢‹ì•„ìš” & êµ¬ë…' ì•„ì›ƒíŠ¸ë¡œ ì˜¤ë²„ë ˆì´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    ë³€ê²½ ì‚¬ìœ : í•œêµ­í˜• ìˆì¸  ìŠ¤íƒ€ì¼ - ë§ˆì§€ë§‰ 3ì´ˆ "ì¢‹ì•„ìš” & êµ¬ë…" CTA

    Args:
        video_width: ì˜ìƒ ë„ˆë¹„.
        video_height: ì˜ìƒ ë†’ì´.

    Returns:
        RGBA numpy ë°°ì—´.
    """
    from youshorts.utils.fonts import load_font

    img = Image.new("RGBA", (video_width, video_height), (0, 0, 0, 0))
    draw = ImageDraw.Draw(img)

    # ë°˜íˆ¬ëª… ë°°ê²½
    box_w, box_h = 700, 200
    x = (video_width - box_w) // 2
    y = video_height // 2 - box_h // 2

    draw.rounded_rectangle(
        [(x, y), (x + box_w, y + box_h)],
        radius=30,
        fill=(0, 0, 0, 180),
    )

    # "ì¢‹ì•„ìš” & êµ¬ë…" í…ìŠ¤íŠ¸
    main_font = load_font(52)
    main_text = "ğŸ‘ ì¢‹ì•„ìš” & êµ¬ë…"
    bbox = draw.textbbox((0, 0), main_text, font=main_font)
    tw = bbox[2] - bbox[0]
    draw.text(
        ((video_width - tw) // 2, y + 40),
        main_text, font=main_font, fill=(255, 215, 0, 255),
    )

    # "ì•Œë¦¼ ì„¤ì •ë„ ë¶€íƒí•´ìš”!" ë³´ì¡° í…ìŠ¤íŠ¸
    sub_font = load_font(32)
    sub_text = "ğŸ”” ì•Œë¦¼ ì„¤ì •ë„ ë¶€íƒí•´ìš”!"
    bbox2 = draw.textbbox((0, 0), sub_text, font=sub_font)
    tw2 = bbox2[2] - bbox2[0]
    draw.text(
        ((video_width - tw2) // 2, y + 120),
        sub_text, font=sub_font, fill=(255, 255, 255, 220),
    )

    return np.array(img)


def _build_visual_effect_clips(
    effects: list[dict[str, Any]],
    video_height: int,
) -> list[ImageClip]:
    """ì‹œê° íš¨ê³¼ í´ë¦½ ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    clips: list[ImageClip] = []
    for effect in effects:
        img = effect["image"]
        clip = _img_to_clip(img, effect["duration"], effect["start"], y_ratio=0.5, video_height=video_height)
        # í˜ì´ë“œì¸ 0.5ì´ˆ ì¶”ê°€
        clip = clip.fadein(0.5).fadeout(0.3)
        clips.append(clip)
    return clips


def _randomize_video_params() -> dict[str, Any]:
    """AI íƒì§€ íšŒí”¼ìš© ì˜ìƒ íŒŒë¼ë¯¸í„° ëœë¤í™”.

    ë§¤ ì˜ìƒë§ˆë‹¤ ìë§‰/ë°°ê²½/íƒ€ì´í‹€ íŒŒë¼ë¯¸í„°ë¥¼ ë¯¸ì„¸í•˜ê²Œ ë³€ê²½í•˜ì—¬
    ë™ì¼ ì±„ë„ì˜ ì˜ìƒì´ ë˜‘ê°™ì´ ë³´ì´ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.

    Returns:
        ëœë¤í™”ëœ íŒŒë¼ë¯¸í„° ë”•ì…”ë„ˆë¦¬.
    """
    highlight_colors = [
        (255, 215, 0),    # ê³¨ë“œ
        (0, 220, 255),    # ì‹œì•ˆ
        (255, 105, 180),  # í•‘í¬
        (100, 255, 100),  # ê·¸ë¦°
        (255, 165, 0),    # ì˜¤ë Œì§€
    ]
    return {
        # ìë§‰ (ë ˆí¼ëŸ°ìŠ¤ ì±„ë„ê¸‰ - í™”ë©´ í•˜ë‹¨ 15% ì˜ì—­)
        "font_size": random.randint(28, 32),
        "margin_v": random.randint(20, 30),
        "subtitle_font_size": random.randint(28, 32),
        "subtitle_y_ratio": round(random.uniform(0.78, 0.85), 2),
        "highlight_color": random.choice(highlight_colors),
        # ë°°ê²½ ì–´ë‘¡ê¸°
        "bg_darken": round(random.uniform(0.18, 0.35), 2),
        "bg_darken_opacity": round(random.uniform(0.18, 0.35), 2),
        # íƒ€ì´í‹€ ë°”
        "title_bar_opacity": round(random.uniform(0.5, 0.8), 2),
        "title_font_size": random.randint(28, 38),
        "title_y_pct": round(random.uniform(0.02, 0.08), 3),
        # ì˜ìƒ ê¸¸ì´ (40~70ì´ˆ)
        "target_duration_range": (40, 70),
    }


def compose(
    bg_paths: list[str],
    tts_path: str,
    words: list[dict[str, Any]],
    script: dict[str, Any],
    total_duration: float,
    edit_style: str | None = None,
    settings: Settings | None = None,
    gradient_colors: tuple[str, ...] | None = None,
) -> tuple[str, str]:
    """ëª¨ë“  ìš”ì†Œë¥¼ í•©ì„±í•˜ì—¬ MP4 ì˜ìƒì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        bg_paths: ë°°ê²½ ì˜ìƒ íŒŒì¼ ê²½ë¡œë“¤.
        tts_path: TTS ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ.
        words: ë‹¨ì–´ ê·¸ë£¹ íƒ€ì´ë° ë¦¬ìŠ¤íŠ¸.
        script: ëŒ€ë³¸ ë”•ì…”ë„ˆë¦¬.
        total_duration: ì „ì²´ ê¸¸ì´ (ì´ˆ).
        edit_style: í¸ì§‘ ìŠ¤íƒ€ì¼ (Noneì´ë©´ ëœë¤).
        settings: ì„¤ì • ì¸ìŠ¤í„´ìŠ¤.
        gradient_colors: ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ ìƒ‰ìƒ (bg_paths ì—†ì„ ë•Œ ì‚¬ìš©).

    Returns:
        (ì¶œë ¥ íŒŒì¼ ê²½ë¡œ, ì‚¬ìš©ëœ í¸ì§‘ ìŠ¤íƒ€ì¼).
    """
    if settings is None:
        settings = get_settings()

    ensure_dir(settings.output_dir)
    ensure_dir(settings.temp_dir)

    vw = settings.video_width
    vh = settings.video_height

    if edit_style is None:
        edit_style = random.choice(EDIT_STYLES)
    logger.info("í¸ì§‘ ìŠ¤íƒ€ì¼: %s", edit_style)

    # â”€â”€ AI íƒì§€ íšŒí”¼: ì˜ìƒë³„ ëœë¤ íŒŒë¼ë¯¸í„° â”€â”€
    rp = _randomize_video_params()
    logger.info(
        "[ëœë¤í™”] ìë§‰=%dpx y=%.2f / ë°°ê²½ì–´ë‘¡ê¸°=%.2f / íƒ€ì´í‹€=%.0f%% %dpx",
        rp["subtitle_font_size"], rp["subtitle_y_ratio"],
        rp["bg_darken_opacity"],
        rp["title_bar_opacity"] * 100, rp["title_font_size"],
    )

    # ìŠ¤í¬ë¦°ìƒ· ë°°ê²½ ì—¬ë¶€ ê°ì§€ (textss_*.png ë˜ëŠ” screenshot_*.png)
    is_screenshot_bg = any(
        os.path.basename(p).startswith(("textss_", "screenshot_"))
        for p in bg_paths if p
    )

    # 1. Background (Ken Burns + í•˜ë“œì»·)
    if is_screenshot_bg:
        logger.info("[1/9] ìŠ¤í¬ë¦°ìƒ· ë°°ê²½ (ë¸”ëŸ¬+ì–´ë‘¡ê²Œ + Ken Burns + í•˜ë“œì»·)...")
    else:
        logger.info("[1/9] ë§Œì¡±ê° ë°°ê²½ (Ken Burns ì¤Œ + í•˜ë“œì»· ì „í™˜)...")
    background = _build_background(
        bg_paths, total_duration, edit_style, vw, vh,
        enable_ken_burns=settings.enable_ken_burns,
        is_screenshot_bg=is_screenshot_bg,
        gradient_colors=gradient_colors,
    )

    # 2. Dark overlay (ëœë¤ ì–´ë‘¡ê¸°)
    rand_darken = rp["bg_darken_opacity"]
    logger.info("[2/9] ì–´ë‘¡ê²Œ ì˜¤ë²„ë ˆì´ (%.0f%%)...", rand_darken * 100)
    overlay = (
        ColorClip((vw, vh), color=(0, 0, 0))
        .set_opacity(rand_darken)
        .set_duration(total_duration)
    )

    # 3. Title bar (ëœë¤ íˆ¬ëª…ë„/í°íŠ¸í¬ê¸°/ìœ„ì¹˜)
    logger.info("[3/9] ìƒë‹¨ íƒ€ì´í‹€ ë°” (ëœë¤: %dpx, %.0f%%)...",
                rp["title_font_size"], rp["title_bar_opacity"] * 100)
    title = script.get("title", "")
    title_bar_img = create_title_bar(
        title,
        font_size_override=rp["title_font_size"],
        opacity_override=rp["title_bar_opacity"],
    )
    title_y = int(vh * rp["title_y_pct"])
    title_bar_clip = _img_to_clip_pos(title_bar_img, total_duration, 0, x=0, y=title_y)
    title_bar_clip = title_bar_clip.fadein(0.5)

    # 4. Bottom bar (ì±„ë„ëª…ì´ ë¹„ì–´ìˆìœ¼ë©´ ìƒëµ)
    bottom_bar_clip = None
    if settings.channel_name:
        logger.info("[4/9] í•˜ë‹¨ ì±„ë„ëª… ë°”...")
        bottom_bar_img = create_bottom_bar(settings.channel_name)
        bottom_bar_clip = _img_to_clip_pos(
            bottom_bar_img, total_duration, 0, x=0, y=vh - BOTTOM_BAR_HEIGHT,
        )
    else:
        logger.info("[4/9] í•˜ë‹¨ ì±„ë„ëª… ë°” ìƒëµ (ì±„ë„ëª… ë¯¸ì„¤ì •)")

    # 5. Progress bar (ìƒë‹¨ 3px ì–‡ì€ ë¼ì¸)
    logger.info("[5/9] í”„ë¡œê·¸ë ˆìŠ¤ ë°” (ìƒë‹¨ 3px)...")
    progress_bar = _build_progress_bar(total_duration, vw)

    # 6. Subtitles (ëœë¤ í°íŠ¸í¬ê¸°/ìœ„ì¹˜/ê°•ì¡°ìƒ‰)
    logger.info("[6/9] ìë§‰ ìƒì„± (%dpx, y=%.2f, ëœë¤ ê°•ì¡°ìƒ‰)...",
                rp["subtitle_font_size"], rp["subtitle_y_ratio"])
    subtitle_clips = _build_subtitle_clips(
        words, script, time_offset=0.0, total_dur=total_duration, video_height=vh,
        font_size_override=rp["subtitle_font_size"],
        y_ratio_override=rp["subtitle_y_ratio"],
        highlight_color_override=rp["highlight_color"],
    )
    logger.info("  %dê°œ ìë§‰ í´ë¦½", len(subtitle_clips))

    # 7. Visual effects
    logger.info("[7/9] ì‹œê° íš¨ê³¼ (ì¸í¬ê·¸ë˜í”½ + í˜ì´ë“œì¸)...")
    visual_effects = generate_visual_effects_for_script(script, total_duration)
    ve_clips = _build_visual_effect_clips(visual_effects, vh)
    logger.info("  %dê°œ íš¨ê³¼ í´ë¦½", len(ve_clips))

    # 8. ì•„ì›ƒíŠ¸ë¡œ "ì¢‹ì•„ìš” & êµ¬ë…" ì˜¤ë²„ë ˆì´ (ë§ˆì§€ë§‰ 2ì´ˆ)
    logger.info("[8/9] ì•„ì›ƒíŠ¸ë¡œ 'ì¢‹ì•„ìš” & êµ¬ë…' ì˜¤ë²„ë ˆì´...")
    outro_img = _create_outro_overlay(vw, vh)
    outro_start = max(0, total_duration - 2.0)
    outro_clip = _img_to_clip(outro_img, 2.0, outro_start, y_ratio=0.5, video_height=vh)
    outro_clip = outro_clip.fadein(0.3).fadeout(0.5)

    # 9. Composite
    logger.info("[9/9] ë ˆì´ì–´ í•©ì„± + ì˜¤ë””ì˜¤...")
    base_clips = [background, overlay, title_bar_clip, bottom_bar_clip, progress_bar]
    all_clips = (
        [c for c in base_clips if c is not None]
        + subtitle_clips + ve_clips + [outro_clip]
    )
    video = CompositeVideoClip(all_clips, size=(vw, vh)).set_duration(total_duration)

    # Audio mixing
    tts_audio = AudioFileClip(tts_path).set_start(0.0)

    # BGM: data/bgm/ í´ë”ì—ì„œ MP3 ë¡œë“œ (ì‚¬ì¸íŒŒ ì ˆëŒ€ ìƒì„±í•˜ì§€ ì•ŠìŒ)
    bgm_path = _load_bgm(settings.bgm_dir)
    audio_clips = [tts_audio]

    if bgm_path:
        logger.info("BGM ë¡œë”©: %s", os.path.basename(bgm_path))
        try:
            bgm_audio = AudioFileClip(bgm_path)

            # BGM ê¸¸ì´ë¥¼ ì˜ìƒ ê¸¸ì´ì— ë§ì¶¤
            if bgm_audio.duration < total_duration:
                bgm_audio = bgm_audio.loop(duration=total_duration)
            else:
                bgm_audio = bgm_audio.subclip(0, total_duration)

            # BGM ë³¼ë¥¨: settingsì—ì„œ dB ê°’ì„ ì„ í˜• ë¹„ìœ¨ë¡œ ë³€í™˜
            bgm_volume_linear = 10 ** (settings.bgm_volume_db / 20)
            bgm_audio = bgm_audio.volumex(bgm_volume_linear)

            # í˜ì´ë“œì¸ 2ì´ˆ / í˜ì´ë“œì•„ì›ƒ 3ì´ˆ
            bgm_audio = bgm_audio.audio_fadein(2.0).audio_fadeout(3.0)

            bgm_audio = bgm_audio.set_duration(total_duration)
            audio_clips.append(bgm_audio)
        except Exception as e:
            logger.warning("BGM ë¡œë“œ ì‹¤íŒ¨: %s - BGM ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤.", e)
    else:
        logger.info("BGM íŒŒì¼ ì—†ìŒ (data/bgm/ í´ë”) - TTSë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    final_audio = CompositeAudioClip(audio_clips)
    video = video.set_audio(final_audio)
    # ë³€ê²½ ì‚¬ìœ : ì¸íŠ¸ë¡œ 0.3ì´ˆ í˜ì´ë“œì¸, ì•„ì›ƒíŠ¸ë¡œ 0.5ì´ˆ í˜ì´ë“œì•„ì›ƒ (ë¹ ë¥¸ ì‹œì‘)
    video = video.fadein(0.3).fadeout(0.5)

    # Render
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_title = re.sub(r'[^\wê°€-í£]', '_', script.get("title", "shorts"))[:30]
    output_path = os.path.join(settings.output_dir, f"shorts_{safe_title}_{timestamp}.mp4")

    logger.info("ë Œë”ë§ -> %s", output_path)
    video.write_videofile(
        output_path,
        fps=settings.video_fps,
        codec="libx264",
        audio_codec="aac",
        preset="medium",
        bitrate=settings.bitrate,
        logger="bar",
    )

    try:
        video.close()
        tts_audio.close()
        for ac in audio_clips:
            try:
                ac.close()
            except Exception:
                pass
    except Exception:
        pass

    return output_path, edit_style
