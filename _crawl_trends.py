#!/usr/bin/env python3
"""ì‹¤ì‹œê°„ íŠ¸ë Œë“œ í¬ë¡¤ë§ â†’ ìˆì¸  ì£¼ì œ ì„ ì •"""
import requests, re, json, io, sys
import xml.etree.ElementTree as ET

if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")

try:
    from bs4 import BeautifulSoup
except ImportError:
    print("beautifulsoup4 í•„ìš”: pip install beautifulsoup4")
    sys.exit(1)

UA_M = "Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15"
UA_D = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"

all_results = []

# â”€â”€ 1. Google Trends KR â”€â”€
print("=" * 60)
print("  [1] Google Trends KR (ì‹¤ì‹œê°„ ê¸‰ìƒìŠ¹)")
print("=" * 60)
try:
    resp = requests.get(
        "https://trends.google.co.kr/trending/rss?geo=KR",
        timeout=10, headers={"User-Agent": "Mozilla/5.0"},
    )
    if resp.status_code == 200:
        root = ET.fromstring(resp.text)
        for i, item in enumerate(root.findall(".//item")[:15]):
            t = item.find("title")
            if t is not None and t.text:
                print(f"  #{i+1:2d}  {t.text}")
                all_results.append({"title": t.text, "source": "êµ¬ê¸€íŠ¸ë Œë“œ", "comments": 0, "score": 100 - i * 5})
except Exception as e:
    print(f"  FAIL: {e}")

# â”€â”€ 2. ë„¤ì´íŠ¸íŒ â”€â”€
print()
print("=" * 60)
print("  [2] ë„¤ì´íŠ¸íŒ ëª…ì˜ˆì˜ì „ë‹¹ + ì˜¤ëŠ˜ì˜íŒ")
print("=" * 60)
try:
    seen = set()
    for url in ["https://m.pann.nate.com/talk/ranking", "https://m.pann.nate.com/talk/today"]:
        resp = requests.get(url, headers={"User-Agent": UA_M}, timeout=10)
        if resp.status_code != 200:
            continue
        soup = BeautifulSoup(resp.text, "html.parser")
        for a in soup.select("a"):
            href = a.get("href", "")
            if "/talk/" not in href:
                continue
            m = re.search(r"/talk/(\d{6,})", href)
            if not m:
                continue
            raw = a.get_text(strip=True)
            if not raw or len(raw) < 10:
                continue
            title = re.sub(r"^\d{1,2}", "", raw)
            cmt = 0
            cm = re.search(r"\((\d{1,5})\)", title)
            if cm:
                cmt = int(cm.group(1))
            for p in [r"\(\d{1,5}\)", r"ì¡°íšŒ[\d,]+", r"\|?ì¶”ì²œ\d+"]:
                title = re.sub(p, "", title)
            title = title.strip()
            if not title or len(title) < 5 or title[:15] in seen:
                continue
            seen.add(title[:15])
            all_results.append({"title": title, "source": "ë„¤ì´íŠ¸íŒ", "comments": cmt, "score": cmt * 3})
    np_items = [x for x in all_results if x["source"] == "ë„¤ì´íŠ¸íŒ"]
    np_items.sort(key=lambda x: x["comments"], reverse=True)
    for i, x in enumerate(np_items[:10]):
        print(f"  #{i+1:2d}  {x['title'][:55]}  (ëŒ“ê¸€:{x['comments']})")
except Exception as e:
    print(f"  FAIL: {e}")

# â”€â”€ 3. ë””ì‹œ ì‹¤ë²  â”€â”€
print()
print("=" * 60)
print("  [3] ë””ì‹œì¸ì‚¬ì´ë“œ ì‹¤ì‹œê°„ë² ìŠ¤íŠ¸")
print("=" * 60)
try:
    resp = requests.get("https://m.dcinside.com/board/dcbest", headers={"User-Agent": UA_M}, timeout=10)
    if resp.status_code == 200:
        soup = BeautifulSoup(resp.text, "html.parser")
        cnt = 0
        seen_dc = set()
        for a in soup.select("a.lt"):
            raw = a.get_text(strip=True)
            if not raw or len(raw) < 10:
                continue
            href = a.get("href", "")
            if "/board/dcbest/" not in href:
                continue
            title = raw
            gal = re.search(r"(?:ì´ë¯¸ì§€)?\[.+?\]", title)
            if gal:
                title = title[gal.end():]
            for p in [r"ã…‡ã…‡(?:\([\d.]+\))?\d{1,2}:\d{2}", r"ì¡°íšŒ\s*[\d,]+", r"ì¶”ì²œ\s*\d+"]:
                c = re.search(p, title)
                if c:
                    title = title[:c.start()]
            title = title.strip()
            if not title or len(title) < 5 or title[:15] in seen_dc:
                continue
            seen_dc.add(title[:15])
            if cnt < 10:
                print(f"  #{cnt+1:2d}  {title[:55]}")
                all_results.append({"title": title, "source": "ë””ì‹œì‹¤ë² ", "comments": 0, "score": 80 - cnt * 5})
                cnt += 1
except Exception as e:
    print(f"  FAIL: {e}")

# â”€â”€ 4. ì—í¨ì½”ë¦¬ì•„ â”€â”€
print()
print("=" * 60)
print("  [4] ì—í¨ì½”ë¦¬ì•„ ë² ìŠ¤íŠ¸")
print("=" * 60)
try:
    resp = requests.get("https://m.fmkorea.com/best", headers={"User-Agent": UA_M}, timeout=10)
    if resp.status_code == 200:
        soup = BeautifulSoup(resp.text, "html.parser")
        cnt = 0
        seen_fm = set()
        for a in soup.select("a"):
            txt = a.get_text(strip=True)
            if not txt or len(txt) < 8 or len(txt) > 80:
                continue
            cmt = 0
            cm = re.search(r"\[(\d{1,5})\]$", txt)
            if cm:
                cmt = int(cm.group(1))
                t = txt[:cm.start()].strip()
            else:
                t = txt
            if not t or len(t) < 8 or t[:15] in seen_fm:
                continue
            seen_fm.add(t[:15])
            if cnt < 10:
                print(f"  #{cnt+1:2d}  {t[:55]}  (ëŒ“ê¸€:{cmt})")
                all_results.append({"title": t, "source": "ì—í¨ì½”ë¦¬ì•„", "comments": cmt, "score": cmt * 3})
                cnt += 1
except Exception as e:
    print(f"  FAIL: {e}")

# â”€â”€ ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„° â”€â”€
BLACKLIST = [
    "êµ­íšŒ", "ëŒ€í†µë ¹", "íƒ„í•µ", "ì—¬ë‹¹", "ì•¼ë‹¹", "ë¯¼ì£¼ë‹¹", "êµ­ë¯¼ì˜í˜", "ì´ì„ ", "ì„ ê±°",
    "ì´ì¬ëª…", "ìœ¤ì„ì—´", "í•œë™í›ˆ", "ê²€ì°°", "ê²½ì°°", "ìˆ˜ì‚¬", "ì¬íŒ", "íŒê²°", "êµ¬ì†",
    "ì‚¬ë§", "ì‚¬ê³ ", "í™”ì¬", "ì§€ì§„", "íƒœí’", "í­ë°œ", "ì¶”ëª¨", "ì‹¤ì¢…", "ì°¸ì‚¬",
    "ê¸ˆë¦¬", "í™˜ìœ¨", "ì¦ì‹œ", "ì½”ìŠ¤í”¼", "ì£¼ê°€", "ë¹„íŠ¸ì½”ì¸", "ì½”ì¸",
    "ê³µì§€", "ì´ë²¤íŠ¸", "ê´‘ê³ ", "ëª¨ì§‘", "í…”ë ˆê·¸ë¨", "í›„ë°©ì£¼ì˜", "19ê¸ˆ",
    "ì •ë‹¹", "ì˜ì›", "ì²­ì™€ëŒ€", "ì™¸êµ", "ë¶í•œ",
]

BOOST = ["ë ˆì „ë“œ", "ì‹¤í™”", "ëŒ€ë°•", "ë¯¸ì³¤", "ì†Œë¦„", "ë°˜ì „", "í›„ê¸°", "ë°ˆ", "í„°ì§", "ë‚œë¦¬",
         "ê¿€íŒ", "ã…‹ã…‹", "ë¹„êµ", "ë­í‚¹", "TOP", "ì±Œë¦°ì§€"]

filtered = []
for item in all_results:
    title = item["title"]
    if any(bw in title for bw in BLACKLIST):
        continue
    # ë¶€ìŠ¤íŠ¸ ì ìˆ˜
    boost = sum(5 for bw in BOOST if bw in title)
    item["score"] += boost
    filtered.append(item)

# ì ìˆ˜ ì •ë ¬
filtered.sort(key=lambda x: x["score"], reverse=True)

# â”€â”€ ìµœì¢… TOP 15 â”€â”€
print()
print("=" * 60)
print("  [ìµœì¢…] ìˆì¸  ì£¼ì œ ì¶”ì²œ TOP 15 (ë¸”ë™ë¦¬ìŠ¤íŠ¸ í•„í„° + ë°”ì´ëŸ´ ì ìˆ˜)")
print("=" * 60)
for i, item in enumerate(filtered[:15]):
    src = item["source"]
    score = item["score"]
    cmt = item["comments"]
    emoji = {"ë„¤ì´íŠ¸íŒ": "ğŸ”¥", "ë””ì‹œì‹¤ë² ": "âš¡", "ì—í¨ì½”ë¦¬ì•„": "ğŸŒ", "êµ¬ê¸€íŠ¸ë Œë“œ": "ğŸ“ˆ"}.get(src, "ğŸ“Œ")
    metric = f"ëŒ“ê¸€:{cmt}" if cmt else f"ì ìˆ˜:{score}"
    print(f"  {emoji} #{i+1:2d}  [{src:6s}]  {item['title'][:50]}  ({metric})")
