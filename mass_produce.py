#!/usr/bin/env python3
"""
=============================================================
ğŸ­ YouTube Shorts ëŒ€ëŸ‰ ìƒì‚° v6.0
=============================================================
main.pyë¥¼ subprocessë¡œ ë°˜ë³µ í˜¸ì¶œí•˜ì—¬ ìˆì¸ ë¥¼ ìë™ ëŒ€ëŸ‰ ìƒì‚°.

v6.0 ì‹ ê·œ:
  â”€ topics.txt í: ë¼ì¸ë³„ ì£¼ì œë¥¼ ìˆœì°¨ ì†Œí™” (ì™„ë£Œ ì‹œ ìë™ ì‚­ì œ)
  â”€ stories/ í´ë”: ì‚¬ì „ ì¤€ë¹„ëœ script.json ìë™ ì†Œí™”
  â”€ --tts-engine ì „ë‹¬: auto / elevenlabs / openai / edge
  â”€ --daemon ëª¨ë“œ: í¬ë¡¤ë§ í ìë™ ë¦¬í•„ + ë¬´í•œ ë£¨í”„
  â”€ í¬ë¡¤ë§ ì†ŒìŠ¤: ì»¤ë®¤ë‹ˆí‹° 4ì†ŒìŠ¤ (viral í†µí•©)

AI ìŠ¬ë¡­ ë°©ì§€:
  â”€ í•˜ë£¨ ìµœëŒ€ ìƒì‚° ì œí•œ (ê¸°ë³¸ 10ê°œ)
  â”€ TTS ìŒì„± ë¡œí…Œì´ì…˜ (3ê°œ ìŒì„±)
  â”€ ì˜ìƒ ê°„ ìµœì†Œ 60ì´ˆ ë”œë ˆì´
  â”€ 24ì‹œê°„ ìµœëŒ€ ëŸ°íƒ€ì„ ì•ˆì „ì¥ì¹˜

ì‚¬ìš©ë²•:
  python mass_produce.py                              # ë°”ì´ëŸ´ í¬ë¡¤ë§ 3ê°œ
  python mass_produce.py --count 5                    # 5ê°œ ìƒì‚°
  python mass_produce.py --count 3 --topic "AI í˜ëª…"  # ê³ ì • ì£¼ì œ 3ê°œ
  python mass_produce.py --topics-file topics.txt     # í íŒŒì¼ì—ì„œ ì£¼ì œ ì†Œí™”
  python mass_produce.py --stories-dir stories/       # script.json ì†Œí™”
  python mass_produce.py --daemon                     # ë¬´í•œ ë£¨í”„ (í¬ë¡¤ë§ ìë™)
  python mass_produce.py --tts-engine elevenlabs      # TTS ì—”ì§„ ì§€ì •
  python mass_produce.py --delay 180                  # 3ë¶„ ê°„ê²©
  python mass_produce.py --clean                      # ë¹„ì •ìƒ íŒŒì¼ ì •ë¦¬
=============================================================
"""

from __future__ import annotations

import argparse
import glob
import io
import json
import os
import random
import shutil
import subprocess
import sys
import time
import traceback
from datetime import datetime, date
from pathlib import Path

# Windows CP949 ì¸ì½”ë”© ì—ëŸ¬ ë°©ì§€
if sys.platform == "win32":
    try:
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")
        sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8", errors="replace")
    except Exception:
        pass

# ============================================================
# ì„¤ì •
# ============================================================
SCRIPT_DIR = Path(__file__).resolve().parent
PYTHON = sys.executable
OUTPUT_DIR = SCRIPT_DIR / "output"
LOG_DIR = SCRIPT_DIR / "logs"
HISTORY_FILE = SCRIPT_DIR / "data" / "mass_produce_history.json"

# TTS ìŒì„± ë¡œí…Œì´ì…˜ (AI ìŠ¬ë¡­ ë°©ì§€ â€” edge-tts ë¬´ë£Œ ìŒì„± 3ê°œ)
EDGE_TTS_VOICES = [
    "ko-KR-InJoonNeural",   # ë‚¨ì„± (ì°¨ë¶„í•œ)
    "ko-KR-HyunsuNeural",   # ë‚¨ì„± (ì—ë„ˆì§€)
    "ko-KR-SunHiNeural",    # ì—¬ì„± (ë°ì€)
]

# í¬ë¡¤ë§ ì†ŒìŠ¤ (v6.0: ì»¤ë®¤ë‹ˆí‹° 4ì†ŒìŠ¤ ê¸°ë°˜)
VALID_SOURCES = ["viral", "natepann", "instiz", "fmkorea", "dcinside"]


# ============================================================
# íˆìŠ¤í† ë¦¬ ê´€ë¦¬ (í•˜ë£¨ ìƒì‚°ëŸ‰ ì¶”ì )
# ============================================================
def _load_history() -> dict:
    """ìƒì‚° íˆìŠ¤í† ë¦¬ ë¡œë“œ"""
    try:
        if HISTORY_FILE.exists():
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
    except Exception:
        pass
    return {"daily": {}, "total": 0}


def _save_history(history: dict) -> None:
    """ìƒì‚° íˆìŠ¤í† ë¦¬ ì €ì¥"""
    HISTORY_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)


def _get_today_count(history: dict) -> int:
    """ì˜¤ëŠ˜ ìƒì‚° ê°œìˆ˜"""
    today = date.today().isoformat()
    return history.get("daily", {}).get(today, 0)


def _increment_today(history: dict) -> None:
    """ì˜¤ëŠ˜ ìƒì‚° ì¹´ìš´íŠ¸ +1"""
    today = date.today().isoformat()
    if "daily" not in history:
        history["daily"] = {}
    history["daily"][today] = history["daily"].get(today, 0) + 1
    history["total"] = history.get("total", 0) + 1


# ============================================================
# topics.txt í ê´€ë¦¬
# ============================================================
def _load_topics_queue(path: str) -> list[str]:
    """topics.txtì—ì„œ ì£¼ì œ ëª©ë¡ ë¡œë“œ (ë¹ˆ ì¤„/ì£¼ì„ ì œì™¸)"""
    topics = []
    try:
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#"):
                    topics.append(line)
    except FileNotFoundError:
        print(f"  âš ï¸  {path} íŒŒì¼ ì—†ìŒ")
    return topics


def _pop_topic_from_file(path: str) -> str | None:
    """topics.txtì—ì„œ ì²« ë²ˆì§¸ ì£¼ì œë¥¼ ê°€ì ¸ì˜¤ê³  íŒŒì¼ì—ì„œ ì œê±°"""
    topics = _load_topics_queue(path)
    if not topics:
        return None

    topic = topics[0]
    remaining = topics[1:]

    # ë‚¨ì€ í•­ëª©ë“¤ë¡œ íŒŒì¼ ë‹¤ì‹œ ì“°ê¸°
    with open(path, "w", encoding="utf-8") as f:
        for t in remaining:
            f.write(t + "\n")

    return topic


# ============================================================
# stories/ í´ë” ê´€ë¦¬
# ============================================================
def _find_story_jsons(stories_dir: str) -> list[str]:
    """stories/ í´ë”ì—ì„œ ì²˜ë¦¬í•  script.json íŒŒì¼ ëª©ë¡ ë°˜í™˜"""
    pattern = os.path.join(stories_dir, "*.json")
    files = sorted(glob.glob(pattern))
    return files


def _archive_story(json_path: str) -> None:
    """ì²˜ë¦¬ ì™„ë£Œëœ script.jsonì„ stories/_done/ìœ¼ë¡œ ì´ë™"""
    done_dir = os.path.join(os.path.dirname(json_path), "_done")
    os.makedirs(done_dir, exist_ok=True)
    dest = os.path.join(done_dir, os.path.basename(json_path))
    # ì¤‘ë³µ ë°©ì§€
    if os.path.exists(dest):
        base, ext = os.path.splitext(os.path.basename(json_path))
        dest = os.path.join(done_dir, f"{base}_{int(time.time())}{ext}")
    shutil.move(json_path, dest)
    print(f"  ğŸ“¦ ì•„ì¹´ì´ë¸Œ: {os.path.basename(json_path)} â†’ _done/")


# ============================================================
# ë‹¨ì¼ ì˜ìƒ ìƒì‚°
# ============================================================
def run_single(
    source: str,
    topic: str | None,
    script_json: str | None,
    voice: str,
    tts_engine: str,
    output_dir: str,
    index: int,
) -> tuple[bool, str]:
    """ë‹¨ì¼ ì˜ìƒì„ ìƒì‚°í•©ë‹ˆë‹¤.

    Args:
        source: í¬ë¡¤ë§ ì†ŒìŠ¤ (viral, natepann ë“±)
        topic: ìˆ˜ë™ ì£¼ì œ (Noneì´ë©´ ìë™ í¬ë¡¤ë§)
        script_json: ì‚¬ì „ ì¤€ë¹„ëœ script.json ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
        voice: edge-tts ìŒì„±
        tts_engine: TTS ì—”ì§„ (auto/elevenlabs/openai/edge)
        output_dir: ì¶œë ¥ ê²½ë¡œ
        index: í˜„ì¬ ì¸ë±ìŠ¤

    Returns:
        (ì„±ê³µ ì—¬ë¶€, ì¶œë ¥ ê²½ë¡œ ë˜ëŠ” ì—ëŸ¬ ë©”ì‹œì§€)
    """
    mode_label = "ğŸ“œ script.json" if script_json else (f"ğŸ“ ì£¼ì œ: {topic}" if topic else f"ğŸŒ í¬ë¡¤ë§: {source}")
    print(f"\n{'â”€' * 60}")
    print(f"  [{index + 1}] ì˜ìƒ ìƒì‚° ì‹œì‘")
    print(f"  ëª¨ë“œ: {mode_label}")
    print(f"  TTS: {tts_engine} | ìŒì„±: {voice}")
    print(f"{'â”€' * 60}")

    # ì»¤ë§¨ë“œ êµ¬ì„±
    script = str(SCRIPT_DIR / "main.py")
    cmd = [PYTHON, script]

    if script_json:
        # script.json ëª¨ë“œ (í¬ë¡¤ë§+Gemini ìŠ¤í‚µ)
        cmd.extend(["--script-json", script_json])
    elif topic:
        # ì£¼ì œ ì§€ì • ëª¨ë“œ
        cmd.extend([
            "--topic", topic,
            "--skip-crawl",
            "--count", "1",
        ])
    else:
        # ìë™ í¬ë¡¤ë§ ëª¨ë“œ
        cmd.extend([
            "--source", source,
            "--count", "1",
        ])

    # ê³µí†µ ì˜µì…˜
    cmd.extend([
        "--voice", voice,
        "--tts-engine", tts_engine,
        "--output", output_dir,
    ])

    start_t = time.time()

    try:
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=900,  # 15ë¶„ íƒ€ì„ì•„ì›ƒ (GoAPI Midjourney í´ë§ ê°ì•ˆ)
            cwd=str(SCRIPT_DIR),
            encoding="utf-8",
            errors="replace",
        )

        elapsed = time.time() - start_t

        if result.returncode == 0:
            print(f"  âœ… ì„±ê³µ! ({elapsed:.1f}ì´ˆ)")

            # stdoutì—ì„œ MP4 ê²½ë¡œ ì°¾ê¸°
            mp4_files = []
            for line in result.stdout.split("\n"):
                if ".mp4" in line and ("ğŸ“" in line or "output" in line.lower()):
                    parts = line.strip().split()
                    for p in parts:
                        if ".mp4" in p:
                            mp4_path = p.strip("()")
                            if os.path.exists(mp4_path):
                                mp4_files.append(mp4_path)

            if mp4_files:
                size_mb = os.path.getsize(mp4_files[0]) / 1024 / 1024
                print(f"  ğŸ“ {mp4_files[0]} ({size_mb:.1f}MB)")
                return True, mp4_files[0]
            return True, f"ì™„ë£Œ ({elapsed:.1f}ì´ˆ)"
        else:
            print(f"  âŒ ì‹¤íŒ¨ (exit={result.returncode}, {elapsed:.1f}ì´ˆ)")
            # ì—ëŸ¬ ì¶œë ¥ ë§ˆì§€ë§‰ 10ì¤„
            stderr_lines = result.stderr.strip().split("\n")[-10:]
            for line in stderr_lines:
                print(f"     {line}")
            # stdoutì—ì„œë„ ì—ëŸ¬ íŒíŠ¸ ì¶”ì¶œ
            stdout_errors = [l for l in result.stdout.split("\n") if "âŒ" in l or "Error" in l]
            for line in stdout_errors[-3:]:
                print(f"     {line.strip()}")
            return False, f"exit={result.returncode}"

    except subprocess.TimeoutExpired:
        print(f"  â° íƒ€ì„ì•„ì›ƒ (15ë¶„ ì´ˆê³¼)")
        return False, "timeout"
    except Exception as e:
        print(f"  âŒ ì—ëŸ¬: {e}")
        return False, str(e)


# ============================================================
# ëŒ€ëŸ‰ ìƒì‚° ë©”ì¸ ë£¨í”„
# ============================================================
def mass_produce(
    count: int,
    source: str,
    topic: str | None,
    topics_file: str | None,
    stories_dir: str | None,
    tts_engine: str,
    delay: int,
    max_retries: int,
    max_per_day: int,
    daemon: bool,
) -> None:
    """ëŒ€ëŸ‰ ìƒì‚° ë©”ì¸ ë¡œì§.

    ìš°ì„ ìˆœìœ„:
    1. stories_dir â†’ script.json ì†Œí™”
    2. topics_file â†’ topics.txt í ì†Œí™”
    3. topic â†’ ê³ ì • ì£¼ì œ ë°˜ë³µ
    4. source â†’ ìë™ í¬ë¡¤ë§
    """
    history = _load_history()
    today_count = _get_today_count(history)

    # í•˜ë£¨ ì œí•œ ì²´í¬
    remaining = max_per_day - today_count
    if remaining <= 0:
        print(f"âš ï¸  ì˜¤ëŠ˜ ì´ë¯¸ {today_count}ê°œ ìƒì‚° (ìµœëŒ€ {max_per_day}ê°œ) â†’ ë‚´ì¼ ë‹¤ì‹œ ì‹¤í–‰")
        return

    output_dir = str(OUTPUT_DIR)
    os.makedirs(output_dir, exist_ok=True)

    # â”€â”€ ì‘ì—… í êµ¬ì„± â”€â”€
    job_queue: list[dict] = []

    # 1ìˆœìœ„: stories/ í´ë”ì˜ script.json
    if stories_dir:
        story_files = _find_story_jsons(stories_dir)
        for sf in story_files:
            job_queue.append({"mode": "story", "script_json": sf, "topic": None})
        if story_files:
            print(f"  ğŸ“š stories/ í: {len(story_files)}ê°œ script.json ë°œê²¬")

    # 2ìˆœìœ„: topics.txt í
    if topics_file and os.path.exists(topics_file):
        topics_list = _load_topics_queue(topics_file)
        for t in topics_list:
            job_queue.append({"mode": "topic", "script_json": None, "topic": t})
        if topics_list:
            print(f"  ğŸ“‹ topics.txt í: {len(topics_list)}ê°œ ì£¼ì œ ë°œê²¬")

    # 3ìˆœìœ„: ê³ ì • ì£¼ì œ or ìë™ í¬ë¡¤ë§
    if not job_queue:
        if topic:
            for _ in range(count):
                job_queue.append({"mode": "topic", "script_json": None, "topic": topic})
        else:
            for _ in range(count):
                job_queue.append({"mode": "crawl", "script_json": None, "topic": None})

    # í•˜ë£¨ ì œí•œ ì ìš©
    actual_count = min(len(job_queue), remaining)
    if actual_count < len(job_queue):
        print(f"  âš ï¸  í {len(job_queue)}ê°œ â†’ {actual_count}ê°œë¡œ ì œí•œ (ì˜¤ëŠ˜ ì”ì—¬: {remaining}ê°œ)")
    job_queue = job_queue[:actual_count]

    print(f"\n{'=' * 60}")
    print(f"ğŸ­ YouTube Shorts ëŒ€ëŸ‰ ìƒì‚° v6.0")
    print(f"{'=' * 60}")
    print(f"  ëª©í‘œ: {actual_count}ê°œ")
    print(f"  ì†ŒìŠ¤: {source}")
    print(f"  TTS: {tts_engine}")
    print(f"  ë”œë ˆì´: {delay}ì´ˆ")
    print(f"  ì¬ì‹œë„: {max_retries}íšŒ")
    print(f"  í•˜ë£¨ ì œí•œ: {max_per_day}ê°œ (ì˜¤ëŠ˜: {today_count}ê°œ ì™„ë£Œ)")
    if daemon:
        print(f"  ğŸ”„ ë°ëª¬ ëª¨ë“œ: í ì†Œì§„ ì‹œ í¬ë¡¤ë§ ìë™ ë¦¬í•„")
    print(f"{'=' * 60}")

    produced = 0
    failed = 0
    results = []
    MAX_RUNTIME = 24 * 3600  # 24ì‹œê°„
    run_start = time.time()

    try:
        job_idx = 0
        while job_idx < len(job_queue):
            # ëŸ°íƒ€ì„ ì•ˆì „ì¥ì¹˜
            if time.time() - run_start > MAX_RUNTIME:
                print(f"\nâš ï¸  24ì‹œê°„ ìµœëŒ€ ëŸ°íƒ€ì„ ì´ˆê³¼ â†’ ì•ˆì „ ì¢…ë£Œ")
                break

            # í•˜ë£¨ ì œí•œ ì‹¤ì‹œê°„ ì²´í¬ (ë‚ ì§œ ë„˜ì–´ê°ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)
            history = _load_history()
            if _get_today_count(history) >= max_per_day:
                print(f"\nâš ï¸  ì˜¤ëŠ˜ í•˜ë£¨ ì œí•œ ë„ë‹¬ ({max_per_day}ê°œ) â†’ ì¢…ë£Œ")
                break

            job = job_queue[job_idx]

            # TTS ìŒì„± ë¡œí…Œì´ì…˜
            voice = EDGE_TTS_VOICES[job_idx % len(EDGE_TTS_VOICES)]

            # ì¬ì‹œë„ ë£¨í”„
            success = False
            for attempt in range(1, max_retries + 1):
                if attempt > 1:
                    retry_delay = min(delay * attempt, 300)
                    print(f"  ğŸ”„ ì¬ì‹œë„ {attempt}/{max_retries} ({retry_delay}ì´ˆ í›„)")
                    time.sleep(retry_delay)

                try:
                    success, result_info = run_single(
                        source=source,
                        topic=job["topic"],
                        script_json=job.get("script_json"),
                        voice=voice,
                        tts_engine=tts_engine,
                        output_dir=output_dir,
                        index=job_idx,
                    )
                except Exception as e:
                    print(f"  âŒ run_single ì˜ˆì™¸: {e}")
                    traceback.print_exc()
                    success = False
                    result_info = str(e)

                if success:
                    produced += 1
                    _increment_today(history)
                    _save_history(history)
                    results.append({
                        "index": job_idx + 1,
                        "status": "success",
                        "mode": job["mode"],
                        "info": result_info,
                    })

                    # story ëª¨ë“œ â†’ ì™„ë£Œëœ json ì•„ì¹´ì´ë¸Œ
                    if job["mode"] == "story" and job.get("script_json"):
                        _archive_story(job["script_json"])

                    # topics.txt ëª¨ë“œ â†’ ì²˜ë¦¬ëœ ì£¼ì œ íŒŒì¼ì—ì„œ ì œê±°
                    if job["mode"] == "topic" and topics_file:
                        _pop_topic_from_file(topics_file)

                    break

            if not success:
                failed += 1
                results.append({
                    "index": job_idx + 1,
                    "status": "failed",
                    "mode": job["mode"],
                    "info": result_info,
                })
                print(f"  ğŸ’€ {max_retries}íšŒ ì¬ì‹œë„ ì‹¤íŒ¨")

            # ì§„í–‰ ìƒí™©
            remain = len(job_queue) - job_idx - 1
            print(f"\n  ğŸ“Š ì§„í–‰: {produced}ê°œ ì„±ê³µ / {failed}ê°œ ì‹¤íŒ¨ / {remain}ê°œ ë‚¨ìŒ")

            # ë”œë ˆì´ (ë§ˆì§€ë§‰ ì•„ì´í…œ ì œì™¸)
            if job_idx < len(job_queue) - 1:
                actual_delay = max(delay, 60)
                print(f"  â³ {actual_delay}ì´ˆ ëŒ€ê¸°...")
                time.sleep(actual_delay)

            job_idx += 1

            # â”€â”€ ë°ëª¬ ëª¨ë“œ: í ì†Œì§„ ì‹œ í¬ë¡¤ë§ìœ¼ë¡œ ìë™ ë¦¬í•„ â”€â”€
            if daemon and job_idx >= len(job_queue):
                # í•˜ë£¨ ì œí•œ ì²´í¬
                history = _load_history()
                if _get_today_count(history) >= max_per_day:
                    print(f"\nâš ï¸  ë°ëª¬: í•˜ë£¨ ì œí•œ ë„ë‹¬ â†’ ë‹¤ìŒ ë‚ ê¹Œì§€ 1ì‹œê°„ ëŒ€ê¸°...")
                    time.sleep(3600)
                    continue

                print(f"\nğŸ”„ ë°ëª¬: í ì†Œì§„ â†’ í¬ë¡¤ë§ ìë™ ë¦¬í•„ (3ê°œ)")
                for _ in range(3):
                    job_queue.append({"mode": "crawl", "script_json": None, "topic": None})

                # topics.txt ë¦¬ë¡œë“œ (ì™¸ë¶€ì—ì„œ ì¶”ê°€ë  ìˆ˜ ìˆìŒ)
                if topics_file and os.path.exists(topics_file):
                    new_topics = _load_topics_queue(topics_file)
                    for t in new_topics:
                        job_queue.append({"mode": "topic", "script_json": None, "topic": t})
                    if new_topics:
                        print(f"  ğŸ“‹ topics.txtì—ì„œ {len(new_topics)}ê°œ ì£¼ì œ ì¶”ê°€")

                # stories/ ë¦¬ë¡œë“œ
                if stories_dir:
                    new_stories = _find_story_jsons(stories_dir)
                    for sf in new_stories:
                        # ì´ë¯¸ íì— ìˆëŠ”ì§€ ì²´í¬
                        existing = {j.get("script_json") for j in job_queue}
                        if sf not in existing:
                            job_queue.append({"mode": "story", "script_json": sf, "topic": None})
                    if new_stories:
                        print(f"  ğŸ“š stories/ì—ì„œ {len(new_stories)}ê°œ script.json ì¶”ê°€")

    except KeyboardInterrupt:
        print(f"\n\nâš ï¸  ì‚¬ìš©ì ì¤‘ë‹¨ (Ctrl+C)")

    # â”€â”€ ìµœì¢… ë¦¬í¬íŠ¸ â”€â”€
    elapsed = time.time() - run_start
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š ëŒ€ëŸ‰ ìƒì‚° ìµœì¢… ë¦¬í¬íŠ¸")
    print(f"{'=' * 60}")
    print(f"  â±ï¸  ì´ ì†Œìš”: {elapsed:.0f}ì´ˆ ({elapsed/60:.1f}ë¶„)")
    print(f"  âœ… ì„±ê³µ: {produced}ê°œ")
    print(f"  âŒ ì‹¤íŒ¨: {failed}ê°œ")
    if produced + failed > 0:
        rate = produced / (produced + failed) * 100
        print(f"  ğŸ“ˆ ì„±ê³µë¥ : {rate:.0f}%")
    print(f"  ğŸ“ ì¶œë ¥: {output_dir}")
    print(f"{'=' * 60}")

    # ê²°ê³¼ ë¡œê·¸ ì €ì¥
    LOG_DIR.mkdir(parents=True, exist_ok=True)
    log_path = LOG_DIR / f"mass_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(log_path, "w", encoding="utf-8") as f:
        json.dump({
            "version": "v6.0",
            "timestamp": datetime.now().isoformat(),
            "count_requested": actual_count,
            "produced": produced,
            "failed": failed,
            "elapsed_sec": round(elapsed, 1),
            "source": source,
            "tts_engine": tts_engine,
            "daemon": daemon,
            "results": results,
        }, f, ensure_ascii=False, indent=2)
    print(f"  ğŸ“‹ ë¡œê·¸: {log_path}")


# ============================================================
# ğŸ§¹ ì •ë¦¬ ìœ í‹¸
# ============================================================
def clean_output(clean_all: bool = False) -> None:
    """ë¹„ì •ìƒ ì¶œë ¥ íŒŒì¼ ì •ë¦¬"""
    output_dir = str(OUTPUT_DIR)
    if not os.path.exists(output_dir):
        print("ğŸ“ output/ ë””ë ‰í† ë¦¬ ì—†ìŒ")
        return

    removed = 0

    # ë¹„ì •ìƒ MP4 ì‚­ì œ (0KB ë˜ëŠ” 100KB ë¯¸ë§Œ)
    for mp4 in glob.glob(os.path.join(output_dir, "*.mp4")):
        size = os.path.getsize(mp4)
        if size < 100 * 1024:  # 100KB ë¯¸ë§Œ â†’ ë¹„ì •ìƒ
            os.remove(mp4)
            print(f"  ğŸ—‘ï¸  ì‚­ì œ: {os.path.basename(mp4)} ({size/1024:.0f}KB)")
            removed += 1

    if clean_all:
        # ì„ì‹œ ì‘ì—… ë””ë ‰í† ë¦¬ ì‚­ì œ
        for work in glob.glob(os.path.join(output_dir, "_work_*")):
            if os.path.isdir(work):
                shutil.rmtree(work, ignore_errors=True)
                print(f"  ğŸ—‘ï¸  ì‚­ì œ: {os.path.basename(work)}/")
                removed += 1

        # __pycache__ ì‚­ì œ
        for cache in glob.glob(os.path.join(str(SCRIPT_DIR), "**/__pycache__"), recursive=True):
            if os.path.isdir(cache):
                shutil.rmtree(cache, ignore_errors=True)
                removed += 1

        # _screenshots ì‚­ì œ
        ss_dir = os.path.join(output_dir, "_screenshots")
        if os.path.isdir(ss_dir):
            shutil.rmtree(ss_dir, ignore_errors=True)
            removed += 1

    print(f"\n  ì •ë¦¬ ì™„ë£Œ: {removed}ê°œ í•­ëª© ì‚­ì œ")


# ============================================================
# CLI
# ============================================================
def main() -> None:
    parser = argparse.ArgumentParser(
        description="ğŸ­ YouTube Shorts ëŒ€ëŸ‰ ìƒì‚° v6.0",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python mass_produce.py                                 # ë°”ì´ëŸ´ í¬ë¡¤ë§ 3ê°œ
  python mass_produce.py --count 5                       # 5ê°œ ìƒì‚°
  python mass_produce.py --count 3 --topic "AI í˜ëª…"     # ê³ ì • ì£¼ì œ 3ê°œ
  python mass_produce.py --topics-file topics.txt        # í íŒŒì¼ì—ì„œ ìˆœì°¨ ì†Œí™”
  python mass_produce.py --stories-dir stories/          # script.json ì†Œí™”
  python mass_produce.py --daemon                        # ë¬´í•œ ë£¨í”„ ë°ëª¬
  python mass_produce.py --tts-engine elevenlabs         # TTS ì—”ì§„ ì§€ì •
  python mass_produce.py --clean                         # ë¹„ì •ìƒ íŒŒì¼ ì •ë¦¬
  python mass_produce.py --clean-all                     # ì „ì²´ ì •ë¦¬
        """
    )

    prod = parser.add_argument_group("ğŸ­ ìƒì‚°")
    prod.add_argument("-c", "--count", type=int, default=3,
                      help="ìƒì„±í•  ì˜ìƒ ê°œìˆ˜ (ê¸°ë³¸ 3)")
    prod.add_argument("--source", default="viral",
                      choices=VALID_SOURCES,
                      help="í¬ë¡¤ë§ ì†ŒìŠ¤ (ê¸°ë³¸: viral)")
    prod.add_argument("-t", "--topic", default=None,
                      help="ì˜ìƒ ì£¼ì œ (ë¯¸ì§€ì • ì‹œ ìë™ ì„ ì •)")
    prod.add_argument("--topics-file", default=None,
                      help="ì£¼ì œ í íŒŒì¼ ê²½ë¡œ (ë¼ì¸ë³„ 1ì£¼ì œ, ì²˜ë¦¬ í›„ ìë™ ì‚­ì œ)")
    prod.add_argument("--stories-dir", default=None,
                      help="ì‚¬ì „ ì¤€ë¹„ëœ script.json í´ë” (ì²˜ë¦¬ í›„ _done/ìœ¼ë¡œ ì´ë™)")

    tts = parser.add_argument_group("ğŸ”Š TTS")
    tts.add_argument("--tts-engine", default="auto",
                     choices=["auto", "elevenlabs", "openai", "edge"],
                     help="TTS ì—”ì§„ (ê¸°ë³¸: auto = ElevenLabsâ†’OpenAIâ†’edge)")

    ctrl = parser.add_argument_group("âš™ï¸  ì œì–´")
    ctrl.add_argument("-d", "--delay", type=int, default=60,
                      help="ì˜ìƒ ê°„ ëŒ€ê¸° ì‹œê°„ ì´ˆ (ê¸°ë³¸ 60, ìµœì†Œ 60)")
    ctrl.add_argument("--max-retries", type=int, default=3,
                      help="ì‹¤íŒ¨ ì‹œ ìµœëŒ€ ì¬ì‹œë„ (ê¸°ë³¸ 3)")
    ctrl.add_argument("--max-per-day", type=int, default=10,
                      help="í•˜ë£¨ ìµœëŒ€ ìƒì‚° (ê¸°ë³¸ 10)")
    ctrl.add_argument("--daemon", action="store_true",
                      help="ë¬´í•œ ë£¨í”„ ë°ëª¬ ëª¨ë“œ (í ì†Œì§„ ì‹œ í¬ë¡¤ë§ ìë™ ë¦¬í•„)")

    util = parser.add_argument_group("ğŸ§¹ ì •ë¦¬")
    util.add_argument("--clean", action="store_true",
                      help="ë¹„ì •ìƒ íŒŒì¼(100KB ë¯¸ë§Œ MP4) ì‚­ì œ")
    util.add_argument("--clean-all", action="store_true",
                      help="ë¹„ì •ìƒ + ì„ì‹œíŒŒì¼ ì „ë¶€ ì‚­ì œ")

    args = parser.parse_args()

    # ì •ë¦¬ ëª¨ë“œ
    if args.clean or args.clean_all:
        clean_output(clean_all=args.clean_all)
        return

    # topics.txt ê¸°ë³¸ ê²½ë¡œ ìë™ íƒìƒ‰
    topics_file = args.topics_file
    if topics_file is None:
        default_topics = SCRIPT_DIR / "topics.txt"
        if default_topics.exists():
            topics_file = str(default_topics)
            print(f"  ğŸ“‹ ìë™ ê°ì§€: {topics_file}")

    # stories/ ê¸°ë³¸ ê²½ë¡œ ìë™ íƒìƒ‰
    stories_dir = args.stories_dir
    if stories_dir is None:
        default_stories = SCRIPT_DIR / "stories"
        if default_stories.exists() and any(default_stories.glob("*.json")):
            stories_dir = str(default_stories)
            print(f"  ğŸ“š ìë™ ê°ì§€: {stories_dir}")

    # ëŒ€ëŸ‰ ìƒì‚°
    mass_produce(
        count=args.count,
        source=args.source,
        topic=args.topic,
        topics_file=topics_file,
        stories_dir=stories_dir,
        tts_engine=args.tts_engine,
        delay=args.delay,
        max_retries=args.max_retries,
        max_per_day=args.max_per_day,
        daemon=args.daemon,
    )


if __name__ == "__main__":
    main()
