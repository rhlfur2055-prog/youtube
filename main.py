#!/usr/bin/env python3
"""
=============================================================
ğŸ¬ YouTube Shorts íŒ©í† ë¦¬ v5.0 'The Viral Machine'
=============================================================
v4.3 â†’ v5.0 ë³€ê²½ì‚¬í•­:
  âœ… ë©€í‹°í”Œë«í¼ í¬ë¡¤ëŸ¬ (ì—í¨ì½”ë¦¬ì•„/ë£¨ë¦¬ì›¹/ì¸ìŠ¤í‹°ì¦ˆ/ë”ì¿ /ë„¤ì´íŠ¸íŒ)
  âœ… í”Œë«í¼ ìë™ ê°ì§€ ë³¸ë¬¸ ì¶”ì¶œ (_fetch_article_by_platform)
  âœ… ê° í”Œë«í¼ë³„ ëŒ“ê¸€ ì¶”ì¶œ
  âœ… requests ìš°ì„  â†’ Apify í´ë°± (ì „ í”Œë«í¼ í†µì¼)
v4.2 â†’ v4.3 ë³€ê²½ì‚¬í•­:
  âœ… ë°”ì´ëŸ´ ì „ë¬¸ í”„ë¡¬í”„íŠ¸ ì ìš© (ì™œ ë² ìŠ¤íŠ¸ì¸ì§€ ë¶„ì„ â†’ ëŒ€ë³¸)
  âœ… ê°ì • íƒœê·¸ í™•ì¥ (excited/shocked/warm/whisper/funny ë“±)
  âœ… ë°”ì´ëŸ´ ê°€ì‚°ì  URL ì •ë ¬ (ã…‹ã…‹/ë ˆì „ë“œ/ì†Œë¦„/ì‹¤í™”/ëŒ€ë°• ìš°ì„ )
  âœ… pause_ms ë²”ìœ„ í™•ëŒ€ (ë°˜ì „ 800~1200ms, í‰ì†Œ 200~400ms)
  âœ… viral_reason í•„ë“œ ì¶”ê°€ (ì™œ ë² ìŠ¤íŠ¸ì¸ì§€ í•œì¤„)
v4.1 â†’ v4.2 ë³€ê²½ì‚¬í•­:
  âœ… í¬ë¡¤ëŸ¬ 2ë‹¨ê³„ ë¶„ë¦¬ (ëª©ë¡â†’ê°œë³„ URL) + UI í‚¤ì›Œë“œ í•„í„°ë§
  âœ… ëŒ€ë³¸ ì†ŒìŠ¤ í’ˆì§ˆ ê²€ì¦ (200ì ë¯¸ë§Œ/ìŠ¤íŒ¸ â†’ None)
  âœ… TTS ë¬¸ì¥ë³„ ê°œë³„ ìƒì„± (ì™„ë²½ ìŒì„±-ìë§‰ ì‹±í¬)
  âœ… Pillow stroke_width ë‚´ì¥ ì‚¬ìš© (ë Œë”ë§ 20ë°° ê°€ì†)
  âœ… ì‚¬ì¸íŒŒ ì•°ë¹„ì–¸íŠ¸ ë“œë¡  BGM (í•‘í¬ë…¸ì´ì¦ˆ â†’ 220+330+440Hz)
  âœ… ë””ì‹œ ì‹¤ì‹œê°„ë² ìŠ¤íŠ¸/ê°œë…ê¸€ ì†ŒìŠ¤ ì¶”ê°€
v4.0 â†’ v4.1 ë³€ê²½ì‚¬í•­:
  âœ… 3ë‹¨ ë¹„ì£¼ì–¼ ë ˆì´ì•„ì›ƒ (ë¸”ëŸ¬ë°°ê²½ + ì„ ëª…ìŠ¤í¬ë¦°ìƒ· + íƒ€ì´í‹€ë°”)
  âœ… Imagen 4.0 ë§¥ë½ ê¸°ë°˜ ì •ë°€ í”„ë¡¬í”„íŠ¸
  âœ… ë‹¨ì–´ë³„ í•˜ì´ë¼ì´íŠ¸ Pop + 4px ì™¸ê³½ì„  + 5px ê·¸ë¦¼ì
  âœ… Sidechain Ducking -20dB + ê³µë°± 80ms
  âœ… Ken Burns + Dynamic Blur + Voice ë§ˆìŠ¤í„°ë§
  âœ… 3ì´ˆ í›„í‚¹ ëŒ€ë³¸ + êµ¬ë… ìœ ë„ CTA ì—”ë”©
  âœ… upload_info.json ìë™ ìƒì„±

íŒŒì´í”„ë¼ì¸:
  [í¬ë¡¤ë§+ìŠ¤í¬ë¦°ìƒ·] Apify â†’ ê¸€ í…ìŠ¤íŠ¸ + í˜ì´ì§€ ìº¡ì²˜
      â†“
  [ëŒ€ë³¸ìƒì„±] Claude API â†’ í›„í‚¹ ëŒ€ë³¸ + SEO íƒœê·¸ 15ê°œ
      â†“
  [TTS+ìë§‰] edge-tts â†’ ê°ì •ë³„ prosody + WordBoundary íƒ€ì´ë°
      â†“
  [AI ë°°ê²½] Imagen 4.0 â†’ í•µì‹¬ ì¥ë©´ AI ì´ë¯¸ì§€ 2~3ì¥
      â†“
  [ì˜ìƒì¡°ë¦½] FFmpeg â†’ Dynamic Blur + Ken Burns + ìë§‰ + BGM Ducking
      â†“
  [ì¶œë ¥] shorts_ì œëª©_ë‚ ì§œ.mp4 + upload_info.json

ì‚¬ìš©ë²•:
  python main.py --source dcinside_realtime_best --count 1
  python main.py --source fmkorea --count 3
  python main.py --source ruliweb --count 2
  python main.py --source theqoo --count 1
  python main.py --source instiz --count 1
  python main.py --source natepann --count 5
  python main.py --url "https://gall.dcinside.com/..."
  python main.py --topic "ìƒê²¬ë¡€ íŒŒí† " --skip-crawl
=============================================================
"""

import argparse
import asyncio
import io
import json
import os
import re
import subprocess
import sys
import time
import math
import textwrap
import shutil
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass
from typing import Optional

# Windows cp949 ì½˜ì†”ì—ì„œ ì´ëª¨ì§€/í•œê¸€ ì¶œë ¥ ê¹¨ì§ ë°©ì§€
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8", errors="replace")

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    _env_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), ".env")
    if os.path.exists(_env_path):
        load_dotenv(_env_path, override=True)
except ImportError:
    pass  # dotenv ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì§ì ‘ ì½ìŒ

# ============================================================
# ğŸ“¦ ì˜ì¡´ì„± ì²´í¬ & ì„¤ì¹˜
# ============================================================
def _get_ffmpeg_path() -> str:
    """FFmpeg ì‹¤í–‰ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤ (imageio_ffmpeg ìš°ì„ )."""
    # 1ì°¨: imageio_ffmpeg ë²ˆë“¤
    try:
        import imageio_ffmpeg
        path = imageio_ffmpeg.get_ffmpeg_exe()
        if path and os.path.exists(path):
            return path
    except ImportError:
        pass

    # 2ì°¨: PATHì—ì„œ ê²€ìƒ‰
    ffmpeg_cmd = "where" if sys.platform == "win32" else "which"
    result = subprocess.run([ffmpeg_cmd, "ffmpeg"], capture_output=True, text=True, encoding="utf-8", errors="replace")
    if result.returncode == 0:
        return result.stdout.strip().split("\n")[0].strip()

    return ""


# ì „ì—­ FFmpeg ê²½ë¡œ (check_dependencies í›„ ì„¤ì •)
FFMPEG_PATH = ""
FFPROBE_PATH = ""


def check_dependencies():
    """í•„ìš”í•œ íŒ¨í‚¤ì§€ ìë™ ì„¤ì¹˜"""
    global FFMPEG_PATH, FFPROBE_PATH

    required = {
        "anthropic": "anthropic",
        "edge_tts": "edge-tts",
        "requests": "requests",
        "apify_client": "apify-client",
        "PIL": "Pillow",
        "imageio_ffmpeg": "imageio-ffmpeg",
        "google.genai": "google-genai",
    }
    for module, package in required.items():
        try:
            __import__(module)
        except ImportError:
            print(f"[+] {package} ì„¤ì¹˜ ì¤‘...")
            subprocess.check_call([
                sys.executable, "-m", "pip", "install",
                package, "--break-system-packages", "-q"
            ])

    # FFmpeg ê²½ë¡œ í™•ë³´
    FFMPEG_PATH = _get_ffmpeg_path()
    if not FFMPEG_PATH:
        if sys.platform == "win32":
            print("[!] FFmpegê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install imageio-ffmpeg")
        else:
            print("[!] FFmpegê°€ í•„ìš”í•©ë‹ˆë‹¤: sudo apt install ffmpeg")
        sys.exit(1)

    # ffprobe ê²½ë¡œ (ê°™ì€ ë””ë ‰í† ë¦¬ì—ì„œ íƒìƒ‰)
    ffmpeg_dir = os.path.dirname(FFMPEG_PATH)
    for name in ["ffprobe", "ffprobe.exe"]:
        probe = os.path.join(ffmpeg_dir, name)
        if os.path.exists(probe):
            FFPROBE_PATH = probe
            break
    if not FFPROBE_PATH:
        # PATHì—ì„œ ì‹œë„
        probe_cmd = "where" if sys.platform == "win32" else "which"
        r = subprocess.run([probe_cmd, "ffprobe"], capture_output=True, text=True, encoding="utf-8", errors="replace")
        if r.returncode == 0:
            FFPROBE_PATH = r.stdout.strip().split("\n")[0].strip()

    print(f"  FFmpeg: {FFMPEG_PATH}")
    if FFPROBE_PATH:
        print(f"  FFprobe: {FFPROBE_PATH}")

check_dependencies()

import anthropic
import edge_tts
import requests
from apify_client import ApifyClient
from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageEnhance
from google import genai as google_genai
from google.genai import types as genai_types


# ============================================================
# âš™ï¸ ì„¤ì •ê°’
# ============================================================
@dataclass
class Config:
    # API í‚¤
    claude_api_key: str = ""
    apify_api_token: str = ""
    google_api_key: str = ""

    # í¬ë¡¤ë§
    source: str = "dcinside"
    gallery: str = "humor"
    crawl_count: int = 3
    target_url: str = ""

    # ëŒ€ë³¸
    script_style: str = "storytelling"
    max_duration: int = 58
    skip_crawl: bool = False
    manual_topic: str = ""

    # TTS (v3.3: HyunsuNeural + ê°ì •ë³„ prosody)
    tts_voice: str = "ko-KR-HyunsuNeural"
    tts_rate: str = "+5%"
    tts_pitch: str = "-1Hz"

    # ì˜ìƒ
    width: int = 1080
    height: int = 1920
    fps: int = 30
    quality: int = 80

    # í°íŠ¸ (ìì—°ìŠ¤ëŸ¬ìš´ í•œê¸€)
    font_name: str = "NanumSquareRound"
    font_size: int = 56
    font_size_highlight: int = 67

    # v4.0: ë¹„ì£¼ì–¼/ì˜¤ë””ì˜¤ ì„¤ì •
    use_ai_bg: bool = True         # Imagen 4.0 AI ë°°ê²½ ì‚¬ìš©
    bgm_enabled: bool = True       # BGM + Auto-Ducking

    # ì¶œë ¥
    output_dir: str = "./output"

    def __post_init__(self):
        self.claude_api_key = os.getenv("ANTHROPIC_API_KEY", self.claude_api_key)
        self.apify_api_token = os.getenv("APIFY_API_TOKEN", self.apify_api_token)
        self.google_api_key = os.getenv("GOOGLE_API_KEY", self.google_api_key)
        os.makedirs(self.output_dir, exist_ok=True)


# ============================================================
# ğŸ”¤ í°íŠ¸ ë§¤ë‹ˆì € (ìì—°ìŠ¤ëŸ¬ìš´ í•œê¸€ í°íŠ¸ ìë™ ì„¤ì¹˜)
# ============================================================
class FontManager:
    """ì‹œìŠ¤í…œì— ìì—°ìŠ¤ëŸ¬ìš´ í•œê¸€ í°íŠ¸ í™•ë³´"""

    # ìš°ì„ ìˆœìœ„ í°íŠ¸ ëª©ë¡
    FONT_PRIORITY = [
        # aptë¡œ ì„¤ì¹˜ ê°€ëŠ¥í•œ í°íŠ¸
        ("NanumSquareRound", "fonts-nanum"),
        ("NanumGothic", "fonts-nanum"),
        ("NanumGothicBold", "fonts-nanum"),
        # ê¸°ë³¸ ë‚´ì¥ ê°€ëŠ¥ì„±
        ("NotoSansCJK-Bold", None),
        ("NotoSansKR-Bold", None),
        ("DejaVuSans", None),
    ]

    @staticmethod
    def get_font(size: int, bold: bool = False) -> ImageFont.FreeTypeFont:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ê°€ì¥ ì¢‹ì€ í•œê¸€ í°íŠ¸ ë°˜í™˜"""
        # 1ì°¨: Windows í°íŠ¸ ë””ë ‰í† ë¦¬ ê²€ìƒ‰
        if sys.platform == "win32":
            font_path = FontManager._find_windows_font(bold)
            if font_path:
                return ImageFont.truetype(font_path, size)

        # 2ì°¨: fc-listë¡œ ì‹œìŠ¤í…œ í•œê¸€ í°íŠ¸ ê²€ìƒ‰ (Linux/macOS)
        font_path = FontManager._find_system_font(bold)
        if font_path:
            return ImageFont.truetype(font_path, size)

        # 3ì°¨: aptë¡œ ë‚˜ëˆ” í°íŠ¸ ì„¤ì¹˜ ì‹œë„ (Linux)
        FontManager._install_nanum_fonts()
        font_path = FontManager._find_system_font(bold)
        if font_path:
            return ImageFont.truetype(font_path, size)

        # 4ì°¨: ì›¹ì—ì„œ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹œë„
        font_path = FontManager._download_font()
        if font_path:
            return ImageFont.truetype(font_path, size)

        # ìµœí›„: ê¸°ë³¸ í°íŠ¸
        print("  [!] í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
        return ImageFont.load_default()

    @staticmethod
    def _find_windows_font(bold: bool = False) -> Optional[str]:
        """Windows í°íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ í•œê¸€ í°íŠ¸ ê²€ìƒ‰"""
        font_dirs = [
            os.path.join(os.environ.get("WINDIR", "C:\\Windows"), "Fonts"),
            os.path.join(os.environ.get("LOCALAPPDATA", ""), "Microsoft", "Windows", "Fonts"),
        ]
        if bold:
            filenames = [
                "NanumSquareRoundB.ttf", "NanumSquareRoundEB.ttf",
                "NanumGothicBold.ttf", "malgunbd.ttf",
            ]
        else:
            filenames = [
                "NanumSquareRoundR.ttf", "NanumSquareRound.ttf",
                "NanumGothic.ttf", "malgun.ttf", "malgunbd.ttf",
            ]
        for font_dir in font_dirs:
            if not os.path.isdir(font_dir):
                continue
            for filename in filenames:
                path = os.path.join(font_dir, filename)
                if os.path.exists(path):
                    return path
        return None

    @staticmethod
    def _find_system_font(bold: bool = False) -> Optional[str]:
        """fc-listë¡œ í•œê¸€ í°íŠ¸ ê²½ë¡œ ì°¾ê¸° (Linux/macOS)"""
        if sys.platform == "win32":
            return None
        try:
            preferred = [
                "NanumSquareRoundB" if bold else "NanumSquareRoundR",
                "NanumSquareRound",
                "NanumGothicBold" if bold else "NanumGothic",
                "NanumGothic",
                "NotoSansCJK",
                "NotoSansKR",
                "Pretendard",
                "D2Coding",
            ]
            result = subprocess.run(
                ["fc-list", ":lang=ko", "file"],
                capture_output=True, text=True, encoding="utf-8", errors="replace", timeout=5
            )
            font_lines = result.stdout.strip().split("\n")

            for pref in preferred:
                for line in font_lines:
                    path = line.split(":")[0].strip()
                    if pref.lower() in path.lower() and os.path.exists(path):
                        return path

            # ì•„ë¬´ í•œê¸€ í°íŠ¸ë¼ë„
            for line in font_lines:
                path = line.split(":")[0].strip()
                if os.path.exists(path) and path.endswith((".ttf", ".otf")):
                    return path

        except Exception:
            pass
        return None

    @staticmethod
    def _install_nanum_fonts():
        """aptë¡œ ë‚˜ëˆ” í°íŠ¸ ì„¤ì¹˜"""
        try:
            print("  ğŸ“¦ í•œê¸€ í°íŠ¸ ì„¤ì¹˜ ì¤‘ (NanumSquareRound)...")
            subprocess.run(
                ["apt-get", "install", "-y", "-qq",
                 "fonts-nanum", "fonts-nanum-extra"],
                capture_output=True, timeout=30
            )
            subprocess.run(["fc-cache", "-f"], capture_output=True, timeout=10)
        except Exception:
            pass

    @staticmethod
    def _download_font() -> Optional[str]:
        """ë‚˜ëˆ”ìŠ¤í€˜ì–´ë¼ìš´ë“œ í°íŠ¸ ë‹¤ìš´ë¡œë“œ"""
        font_dir = os.path.expanduser("~/.local/share/fonts")
        os.makedirs(font_dir, exist_ok=True)
        font_path = os.path.join(font_dir, "NanumSquareRoundR.ttf")

        if os.path.exists(font_path):
            return font_path

        try:
            # ë‚˜ëˆ”ìŠ¤í€˜ì–´ë¼ìš´ë“œ ë‹¤ìš´ë¡œë“œ URL
            url = ("https://github.com/nicedoctor/NanumSquareRound/raw/"
                   "master/NanumSquareRoundR.ttf")
            print(f"  ğŸ“¥ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            resp = requests.get(url, timeout=15)
            if resp.status_code == 200:
                with open(font_path, "wb") as f:
                    f.write(resp.content)
                subprocess.run(["fc-cache", "-f"], capture_output=True)
                return font_path
        except Exception:
            pass
        return None


# ============================================================
# ğŸ¨ ê°ì • ìŠ¤íƒ€ì¼ (v3: ë” ìì—°ìŠ¤ëŸ¬ìš´ ìƒ‰ìƒ)
# ============================================================
EMOTION_STYLES = {
    "anger": {
        "text_color": (255, 80, 80),       # ë¹¨ê°• (ë¶€ë“œëŸ½ê²Œ)
        "bg_color": (40, 10, 10, 200),      # ì–´ë‘ìš´ ë¹¨ê°• ë°°ê²½
        "border_color": (255, 60, 60),
    },
    "fun": {
        "text_color": (255, 220, 50),       # ê³¨ë“œ (ë°ê²Œ)
        "bg_color": (40, 35, 5, 200),
        "border_color": (255, 200, 0),
    },
    "surprise": {
        "text_color": (100, 230, 255),      # í•˜ëŠ˜ìƒ‰
        "bg_color": (5, 30, 40, 200),
        "border_color": (0, 200, 255),
    },
    "sad": {
        "text_color": (200, 160, 255),      # ë¼ë²¤ë”
        "bg_color": (25, 15, 40, 200),
        "border_color": (180, 130, 255),
    },
    "neutral": {
        "text_color": (255, 255, 255),      # í°ìƒ‰
        "bg_color": (20, 20, 20, 190),
        "border_color": (100, 100, 100),
    },
    "tension": {
        "text_color": (255, 130, 100),      # ì½”ë„
        "bg_color": (40, 15, 10, 200),
        "border_color": (255, 100, 70),
    },
    "relief": {
        "text_color": (130, 255, 190),      # ë¯¼íŠ¸
        "bg_color": (10, 35, 20, 200),
        "border_color": (100, 230, 160),
    },
    "shock": {
        "text_color": (255, 180, 50),       # ì£¼í™©
        "bg_color": (40, 25, 5, 200),
        "border_color": (255, 150, 0),
    },
}


# ============================================================
# ğŸ•·ï¸ Stage 1: í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
# ============================================================
class CommunityScraper:
    """ë””ì‹œ/ë„¤ì´íŠ¸íŒ ë² ìŠ¤íŠ¸ê¸€ í¬ë¡¤ë§ + í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜"""

    SOURCES = {
        "natepann": {
            "best_url": "https://pann.nate.com/talk/ranking/d",
            "name": "ë„¤ì´íŠ¸íŒ",
            "platform": "natepann",
        },
        "dcinside": {
            "best_url": "https://gall.dcinside.com/board/lists/?id={gallery}&exception_mode=recommend&sort_type=N&page=1",
            "name": "ë””ì‹œì¸ì‚¬ì´ë“œ",
            "platform": "dcinside",
        },
        "dcinside_realtime_best": {
            "best_url": "https://gall.dcinside.com/board/lists/?id=dcbest",
            "name": "ë””ì‹œ ì‹¤ì‹œê°„ë² ìŠ¤íŠ¸",
            "platform": "dcinside",
        },
        "dcinside_hit": {
            "best_url": "https://gall.dcinside.com/board/lists/?id=hit",
            "name": "ë””ì‹œ ê°œë…ê¸€",
            "platform": "dcinside",
        },
        "fmkorea": {
            "best_url": "https://www.fmkorea.com/best",
            "name": "ì—í¨ì½”ë¦¬ì•„",
            "platform": "fmkorea",
        },
        "ruliweb": {
            "best_url": "https://bbs.ruliweb.com/best/humor/best",
            "name": "ë£¨ë¦¬ì›¹ ìœ ë¨¸ ë² ìŠ¤íŠ¸",
            "platform": "ruliweb",
        },
        "instiz": {
            "best_url": "https://www.instiz.net/pt",
            "name": "ì¸ìŠ¤í‹°ì¦ˆ",
            "platform": "instiz",
        },
        "theqoo": {
            "best_url": "https://theqoo.net/hot",
            "name": "ë”ì¿ ",
            "platform": "theqoo",
        },
    }

    # UI/ê´‘ê³ /ì†Œê°œê¸€/ê³µì§€ê¸€ í‚¤ì›Œë“œ (1ê°œë¼ë„ í¬í•¨ â†’ ì¦‰ì‹œ ì°¨ë‹¨)
    BLOCK_KEYWORDS = [
        # DC
        "ê°¤ëŸ¬ë¦¬ ì´ìš© ì•ˆë‚´", "ê°¤ëŸ¬ë¦¬ ì´ìš©ì•ˆë‚´", "ì´ìš© ì•ˆë‚´",
        "ê°¤ëŸ¬ë¦¬ ì†Œê°œ", "ê°¤ëŸ¬ë¦¬ë¥¼ ì†Œê°œ", "ê°¤ëŸ¬ë¦¬ ê°œì„¤",
        "ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬", "ë§ˆì´ë„ˆê°¤ëŸ¬ë¦¬",
        "CONNECTING HEARTS", "ë””ì‹œì¸ì‚¬ì´ë“œì…ë‹ˆë‹¤",
        # ê³µí†µ ê³µì§€/ì•ˆë‚´
        "[ê³µì§€]", "[í•„ë…]", "[ì•ˆë‚´]", "[ìš´ì˜]", "[ê·œì¹™]",
        "[Notice]", "[notice]",
        "ìš´ì˜ìì…ë‹ˆë‹¤", "ê³µì§€ì‚¬í•­ì…ë‹ˆë‹¤", "ì´ìš©ê·œì¹™",
    ]
    # UI/ìŠ¤íŒ¸ í‚¤ì›Œë“œ (2ê°œ ì´ìƒ í¬í•¨ â†’ ì°¨ë‹¨)
    UI_KEYWORDS = [
        "ê°¤ëŸ¬ë¦¬ ë§Œë“¤ê¸°", "íšŒì›ê°€ì…", "ë¡œê·¸ì¸", "ê´‘ê³  ë¬¸ì˜",
        "ì´ ê°¤ëŸ¬ë¦¬ë¥¼ , , ,", "ê°¤ëŸ¬ë¦¬ ê·œì •", "ê³µì§€ì‚¬í•­",
        "ìš´ì˜ ë°©ì¹¨", "ë§¤ë‹ˆì € ì‹ ì²­", "ë¶€ë§¤ë‹ˆì €",
    ]

    # Apify removeElements ê°•í™” ì…€ë ‰í„°
    DC_REMOVE_CSS = (
        "nav, footer, .ad, .advertisement, #header, .sidebar, "
        "script, style, .comment_box, .reply_box, "
        ".minor_intro_banner, .dchead_bg, .visit_card, .pop_wrap, "
        ".issue_wrap, .dc_logo, .gnb_bar, .user_info, .fl, "
        ".btn_recommend, .gall_exposure, .ad_bottom_list, .appdown, "
        ".notion_tag, #dchead, .darkmode-layer, .issue_contentbox, "
        ".minor_banner_list, .dcwiki, .listwrap.clear, "
        "#dccon_progress_bar, .repimg_thumb"
    )

    def __init__(self, config: Config):
        self.config = config
        self.client = None
        if config.apify_api_token:
            self.client = ApifyClient(config.apify_api_token)

    def scrape_with_screenshots(self) -> list[dict]:
        """
        ë² ìŠ¤íŠ¸ê¸€ í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
        Returns: [{title, content, url, screenshots: [path1, path2, ...]}]
        """
        print(f"\n{'='*60}")
        print(f"ğŸ•·ï¸  Stage 1: í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ·")
        src_name = self.SOURCES.get(self.config.source, {}).get('name', self.config.source)
        print(f"  ì†ŒìŠ¤: {src_name}")
        print(f"{'='*60}")

        if self.config.target_url:
            return self._scrape_single_with_screenshot(self.config.target_url)

        if self.client:
            return self._scrape_apify_with_screenshots()

        return self._scrape_fallback_with_fake_screenshots()

    # ë””ì‹œ ê³µì§€/ì†Œê°œê¸€ ë²ˆí˜¸ (í•­ìƒ ëª©ë¡ ìµœìƒë‹¨ì— ê³ ì •, ì‹¤ì œ ë² ìŠ¤íŠ¸ê¸€ì´ ì•„ë‹˜)
    DC_NOTICE_NOS = {
        "30638",   # ì‹¤ì‹œê°„ë² ìŠ¤íŠ¸ ê°¤ëŸ¬ë¦¬ ì´ìš© ì•ˆë‚´
        "17784",   # ê°œë…ê¸€ ê°¤ëŸ¬ë¦¬ ì´ìš© ì•ˆë‚´
    }

    # ë°”ì´ëŸ´ ê°€ì‚°ì  í‚¤ì›Œë“œ (ì œëª©ì— í¬í•¨ ì‹œ ìš°ì„  ì„ íƒ)
    VIRAL_BOOST_KEYWORDS = [
        "ã…‹ã…‹", "ë ˆì „ë“œ", "ì†Œë¦„", "ì‹¤í™”", "ëŒ€ë°•",
        "ì¶©ê²©", "ë°˜ì „", "ì›ƒê¸´", "ë¯¸ì³¤", "ì—­ëŒ€ê¸‰",
        "ã„¹ã…‡", "ã…‡ã…ˆ", "ê°œì›ƒ", "ã…‚ã„·ã…‚ã„·", "í—",
    ]

    def _extract_article_urls_requests(self, list_url: str) -> list[str]:
        """requestsë¡œ ëª©ë¡ í˜ì´ì§€ HTMLì—ì„œ ê°œë³„ ê¸€ URL+ì œëª© ì¶”ì¶œ (ë°”ì´ëŸ´ ê°€ì‚°ì  ì •ë ¬)"""
        try:
            import requests as _req
            headers = {
                "User-Agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/131.0.0.0 Safari/537.36"
                ),
                "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8",
                "Referer": "https://gall.dcinside.com/",
            }
            r = _req.get(list_url, headers=headers, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            # â”€â”€ URL + ì œëª© í•¨ê»˜ ì¶”ì¶œ â”€â”€
            url_title_pairs = []

            # ë””ì‹œ: view-msg ì†ì„± <a> íƒœê·¸ (ì œëª© ë§í¬ë§Œ ì •í™•íˆ ë§¤ì¹­)
            dc_title_links = re.findall(
                r'<a\s+href="(/board/view/\?id=\w+&no=\d+[^"]*)"\s*view-msg\s*[^>]*>'
                r'(.*?)</a>',
                html, re.DOTALL
            )
            for path, inner_html in dc_title_links:
                full = "https://gall.dcinside.com" + path.replace("&amp;", "&")
                # inner_htmlì—ì„œ íƒœê·¸ ì œê±° â†’ ìˆœìˆ˜ ì œëª© í…ìŠ¤íŠ¸
                title = re.sub(r'<[^>]+>', '', inner_html).strip()
                if title:
                    url_title_pairs.append((full, title))

            # í´ë°±: view-msg ì—†ëŠ” ì¼ë°˜ íŒ¨í„´
            if not url_title_pairs:
                dc_rows = re.findall(
                    r'<a[^>]*href="(/board/view/\?id=\w+&no=\d+[^"]*)"[^>]*>'
                    r'\s*(?:<[^>]*>)*\s*([^<]{2,})',
                    html
                )
                for path, title in dc_rows:
                    full = "https://gall.dcinside.com" + path.replace("&amp;", "&")
                    url_title_pairs.append((full, title.strip()))

            # ë””ì‹œ: reply_numbox ë“± ì „ì²´ URL (ì œëª© ì—†ì´, ì¤‘ë³µ ì œê±°ìš©)
            dc_full_pat = re.findall(
                r'https?://gall\.dcinside\.com/board/view/\?id=\w+&no=\d+[^\s"\'<>]*',
                html
            )
            existing_urls = {u for u, _ in url_title_pairs}
            for u in dc_full_pat:
                if u not in existing_urls:
                    url_title_pairs.append((u, ""))

            # ë„¤ì´íŠ¸íŒ: /talk/ìˆ«ì
            nate_pat = re.findall(r'href="(/talk/\d+)"', html)
            for path in nate_pat:
                url_title_pairs.append(("https://pann.nate.com" + path, ""))

            nate_full = re.findall(r'https?://pann\.nate\.com/talk/\d+', html)
            for u in nate_full:
                url_title_pairs.append((u, ""))

            # ì—í¨ì½”ë¦¬ì•„: /ìˆ«ì (document_srl 10ìë¦¬)
            fm_links = re.findall(
                r'<a[^>]*href="(/\d{8,})"[^>]*>(.*?)</a>', html, re.DOTALL
            )
            for path, inner in fm_links:
                full = "https://www.fmkorea.com" + path
                title = re.sub(r'<[^>]+>', '', inner).strip()
                url_title_pairs.append((full, title))

            # ë£¨ë¦¬ì›¹: bbs.ruliweb.com/.../read/ìˆ«ì
            ruli_links = re.findall(
                r'<a[^>]*href="(https?://bbs\.ruliweb\.com/[^"]*read/\d+)"[^>]*>(.*?)</a>',
                html, re.DOTALL
            )
            for href, inner in ruli_links:
                title = re.sub(r'<[^>]+>', '', inner).strip()
                if title and len(title) > 3:
                    url_title_pairs.append((href, title))

            # ì¸ìŠ¤í‹°ì¦ˆ: /pt/ìˆ«ì
            instiz_links = re.findall(
                r'href="(?:https?://www\.instiz\.net)?(/pt/\d+)[^"]*"', html
            )
            for path in instiz_links:
                url_title_pairs.append(("https://www.instiz.net" + path, ""))

            # ë”ì¿ : /hot/ìˆ«ì
            theqoo_links = re.findall(
                r'href="(/hot/\d{5,})"', html
            )
            for path in theqoo_links:
                url_title_pairs.append(("https://theqoo.net" + path, ""))

            # â”€â”€ ê³µì§€/ì†Œê°œê¸€ í•„í„°ë§ â”€â”€
            filtered = []
            for u, title in url_title_pairs:
                no_m = re.search(r'no=(\d+)', u)
                if no_m and no_m.group(1) in self.DC_NOTICE_NOS:
                    continue
                if no_m and ("dcbest" in u or "hit" in u):
                    if int(no_m.group(1)) < 100000:
                        continue
                if title and any(kw in title for kw in self.BLOCK_KEYWORDS):
                    continue
                filtered.append((u, title))

            # â”€â”€ ë°”ì´ëŸ´ ê°€ì‚°ì  ì •ë ¬ (í‚¤ì›Œë“œ ë§ì„ìˆ˜ë¡ ìƒìœ„) â”€â”€
            def _viral_score(pair):
                _, t = pair
                return sum(1 for kw in self.VIRAL_BOOST_KEYWORDS if kw in t)

            filtered.sort(key=_viral_score, reverse=True)

            # ì œëª© ì •ë³´ë¥¼ ì¸ìŠ¤í„´ìŠ¤ì— ì €ì¥ (í›„ì† ë‹¨ê³„ì—ì„œ í™œìš©)
            self._url_titles = {u: t for u, t in filtered if t}

            result_urls = [u for u, _ in filtered]
            if result_urls:
                top_title = filtered[0][1] if filtered[0][1] else "(ì œëª© ë¯¸í™•ì¸)"
                print(f"  âœ… requestsë¡œ {len(result_urls)}ê°œ URL ì¶”ì¶œ (ê³µì§€ ì œì™¸)")
                print(f"     ğŸ”¥ 1ìˆœìœ„: {top_title[:50]}")
            else:
                print(f"  âš ï¸  requests HTMLì—ì„œ URL ë¯¸ë°œê²¬")
            return result_urls

        except Exception as e:
            print(f"  âš ï¸  requests ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return []

    def _extract_article_urls_apify(self, list_url: str) -> list[str]:
        """Apifyë¡œ ëª©ë¡ í˜ì´ì§€ì—ì„œ ê°œë³„ ê¸€ URL ì¶”ì¶œ (í´ë°±)"""
        try:
            list_input = {
                "startUrls": [{"url": list_url}],
                "crawlerType": "playwright:firefox",
                "maxCrawlPages": 1,
                "maxCrawlDepth": 0,
                "outputFormats": ["markdown"],
                "removeCookieWarnings": True,
                "saveScreenshots": False,
            }
            list_run = self.client.actor("apify/website-content-crawler").call(
                run_input=list_input, timeout_secs=120,
            )

            urls = []
            list_dataset = self.client.dataset(list_run["defaultDatasetId"])
            for item in list_dataset.iterate_items():
                page_text = item.get("text", "") or item.get("markdown", "")

                dc_pat = re.findall(
                    r'https?://gall\.dcinside\.com/board/view/\?id=\w+&no=\d+[^\s"\'<>]*',
                    page_text + " " + str(item)
                )
                urls.extend(dc_pat)

                nate_pat = re.findall(
                    r'https?://pann\.nate\.com/talk/\d+',
                    page_text + " " + str(item)
                )
                urls.extend(nate_pat)

            return urls

        except Exception as e:
            print(f"  âš ï¸  Apify ëª©ë¡ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return []

    def _scrape_apify_with_screenshots(self) -> list[dict]:
        """
        v4.2: 2ë‹¨ê³„ í¬ë¡¤ë§ â€” ëª©ë¡â†’URL ì¶”ì¶œâ†’ê°œë³„ ê¸€ í¬ë¡¤ë§
        [1ë‹¨ê³„] ê¸€ ëª©ë¡ í˜ì´ì§€ì—ì„œ ê°œë³„ ê¸€ URLë§Œ ì¶”ì¶œ
        [2ë‹¨ê³„] ê° ê°œë³„ ê¸€ URLì„ ë³„ë„ë¡œ í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ·
        """
        source_info = self.SOURCES[self.config.source]
        url = source_info["best_url"]
        if self.config.source == "dcinside":
            url = url.format(gallery=self.config.gallery)
        # dcinside_realtime_best, dcinside_hitì€ format ë¶ˆí•„ìš”

        print(f"  ğŸ”— ëª©ë¡ URL: {url}")
        print(f"  ğŸ“¡ [1ë‹¨ê³„] ê¸€ ëª©ë¡ì—ì„œ ê°œë³„ URL ì¶”ì¶œ ì¤‘...")

        try:
            # â”â” 1ë‹¨ê³„: ëª©ë¡ í˜ì´ì§€ì—ì„œ ê°œë³„ ê¸€ URL ì¶”ì¶œ â”â”
            # requestsë¡œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸° (Apifyë³´ë‹¤ ë¹ ë¥´ê³  ë¬´ë£Œ)
            article_urls = self._extract_article_urls_requests(url)

            # requests ì‹¤íŒ¨ ì‹œ Apify í´ë°±
            if not article_urls and self.client:
                print(f"  ğŸ“¡ requests ì‹¤íŒ¨, Apifyë¡œ 1ë‹¨ê³„ ì¬ì‹œë„...")
                article_urls = self._extract_article_urls_apify(url)

            # ì¤‘ë³µ ì œê±° + ì œí•œ
            seen = set()
            unique_urls = []
            for u in article_urls:
                base = re.sub(r'&page=\d+', '', u)
                if base not in seen:
                    seen.add(base)
                    unique_urls.append(u)
            unique_urls = unique_urls[:self.config.crawl_count]

            if not unique_urls:
                print(f"  âš ï¸  ê°œë³„ ê¸€ URLì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í´ë°± ì‹œë„...")
                return self._scrape_fallback_with_fake_screenshots()

            print(f"  âœ… {len(unique_urls)}ê°œ ê¸€ URL ì¶”ì¶œ ì™„ë£Œ")
            for u in unique_urls:
                print(f"     ğŸ“„ {u[:80]}")

            # â”â” 2ë‹¨ê³„: ê° ê°œë³„ ê¸€ í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ· â”â”
            print(f"  ğŸ“¡ [2ë‹¨ê³„] ê°œë³„ ê¸€ í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ·...")
            posts = []

            for art_idx, art_url in enumerate(unique_urls):
                # 1ë‹¨ê³„ì—ì„œ ê°€ì ¸ì˜¨ ì œëª© ì •ë³´ í™œìš©
                known_title = getattr(self, '_url_titles', {}).get(art_url, "")
                title_display = known_title[:40] if known_title else art_url[:60]
                print(f"  ğŸ“– [{art_idx+1}/{len(unique_urls)}] {title_display}...")

                post = None

                # â”€â”€ requestsë¡œ ë³¸ë¬¸ ë¨¼ì € ì‹œë„ (ë¹ ë¥´ê³  ì•ˆì •ì ) â”€â”€
                try:
                    req_post = self._fetch_article_by_platform(art_url)
                    if req_post and len(req_post.get("content", "")) >= 200:
                        # í’ˆì§ˆ í•„í„°
                        text = req_post["content"]
                        title = req_post["title"]
                        if any(kw in text for kw in self.BLOCK_KEYWORDS):
                            blk = [kw for kw in self.BLOCK_KEYWORDS if kw in text]
                            print(f"     ğŸš« ì†Œê°œ/ê³µì§€ê¸€ ì°¨ë‹¨: {blk[0]}")
                            continue
                        if any(kw in title for kw in self.BLOCK_KEYWORDS):
                            print(f"     ğŸš« ì œëª©ì—ì„œ ì†Œê°œê¸€ ê°ì§€, ê±´ë„ˆëœ€")
                            continue
                        spam_count = sum(1 for kw in self.UI_KEYWORDS if kw in text)
                        if spam_count >= 2:
                            print(f"     âš ï¸  UI í…ìŠ¤íŠ¸ ê°ì§€ ({spam_count}ê°œ), ê±´ë„ˆëœ€")
                            continue
                        post = req_post
                        print(f"     âœ… requests ë³¸ë¬¸ í™•ë³´ ({len(text)}ì)")
                except Exception as e:
                    print(f"     âš ï¸  requests ì‹¤íŒ¨: {e}")

                # â”€â”€ requests ì‹¤íŒ¨ ì‹œ Apify í´ë°± â”€â”€
                if not post:
                    try:
                        art_input = {
                            "startUrls": [{"url": art_url}],
                            "crawlerType": "playwright:firefox",
                            "maxCrawlPages": 1,
                            "maxCrawlDepth": 0,
                            "outputFormats": ["markdown"],
                            "removeCookieWarnings": True,
                            "saveScreenshots": True,
                            "screenshotQuality": 80,
                            "removeElementsCssSelector": self.DC_REMOVE_CSS,
                        }
                        art_run = self.client.actor("apify/website-content-crawler").call(
                            run_input=art_input, timeout_secs=120,
                        )

                        art_dataset = self.client.dataset(art_run["defaultDatasetId"])
                        art_kvs = self.client.key_value_store(art_run["defaultKeyValueStoreId"])

                        for item in art_dataset.iterate_items():
                            text = item.get("text", "") or item.get("markdown", "")
                            if len(text) < 200:
                                continue
                            if any(kw in text for kw in self.BLOCK_KEYWORDS):
                                blk = [kw for kw in self.BLOCK_KEYWORDS if kw in text]
                                print(f"     ğŸš« ì†Œê°œ/ê³µì§€ê¸€ ì°¨ë‹¨: {blk[0]}")
                                continue
                            item_title = item.get("metadata", {}).get("title", "")
                            if any(kw in item_title for kw in self.BLOCK_KEYWORDS):
                                print(f"     ğŸš« ì œëª©ì—ì„œ ì†Œê°œê¸€ ê°ì§€, ê±´ë„ˆëœ€")
                                continue
                            spam_count = sum(1 for kw in self.UI_KEYWORDS if kw in text)
                            if spam_count >= 2:
                                continue

                            post = {
                                "title": item_title or "ì œëª©ì—†ìŒ",
                                "content": text[:3000],
                                "url": item.get("url", art_url),
                                "source": self.config.source,
                                "screenshots": [],
                            }
                            # ìŠ¤í¬ë¦°ìƒ· ë‹¤ìš´ë¡œë“œ
                            ss_key = item.get("screenshotUrl", "")
                            if ss_key:
                                ss_path = self._download_screenshot(
                                    art_kvs, ss_key, len(posts)
                                )
                                if ss_path:
                                    post["screenshots"].append(ss_path)
                            break

                    except Exception as e:
                        print(f"     âš ï¸  Apify í´ë°±ë„ ì‹¤íŒ¨: {e}")

                if post:
                    posts.append(post)

            # ìŠ¤í¬ë¦°ìƒ· ì—†ëŠ” ê¸€ â†’ í…ìŠ¤íŠ¸ ê¸°ë°˜ ìƒì„±
            for post in posts:
                if not post["screenshots"]:
                    fake_ss = self._generate_text_screenshots(post)
                    post["screenshots"] = fake_ss

            if not posts:
                print(f"  âš ï¸  í¬ë¡¤ë§ëœ ê¸€ ì¤‘ ë³¸ë¬¸ì´ ìˆëŠ” ê¸€ì´ ì—†ìŠµë‹ˆë‹¤")
                return self._scrape_fallback_with_fake_screenshots()

            print(f"  âœ… {len(posts)}ê°œ ê¸€ ìˆ˜ì§‘ ì™„ë£Œ! (ë³¸ë¬¸ í™•ì¸ë¨)")
            for p in posts:
                print(f"     ğŸ“„ {p['title'][:30]} ({len(p['content'])}ì)")
            return posts

        except Exception as e:
            print(f"  âš ï¸  Apify ì—ëŸ¬: {e}")
            return self._scrape_fallback_with_fake_screenshots()

    def _scrape_single_with_screenshot(self, url: str) -> list[dict]:
        """ë‹¨ì¼ URL í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ·"""
        print(f"  ğŸ”— ë‹¨ì¼ URL: {url}")

        post = {"title": "", "content": "", "url": url,
                "source": "direct", "screenshots": []}

        if self.client:
            try:
                run_input = {
                    "startUrls": [{"url": url}],
                    "crawlerType": "playwright:firefox",
                    "maxCrawlPages": 1,
                    "maxCrawlDepth": 0,
                    "outputFormats": ["markdown"],
                    "saveScreenshots": True,
                    "screenshotQuality": 80,
                }
                run = self.client.actor("apify/website-content-crawler").call(
                    run_input=run_input, timeout_secs=90
                )
                dataset = self.client.dataset(run["defaultDatasetId"])
                for item in dataset.iterate_items():
                    post["title"] = item.get("metadata", {}).get("title", "")
                    post["content"] = (
                        item.get("text", "") or item.get("markdown", "")
                    )[:3000]

                    # ìŠ¤í¬ë¦°ìƒ·
                    ss_key = item.get("screenshotUrl", "")
                    if ss_key:
                        kvs = self.client.key_value_store(
                            run["defaultKeyValueStoreId"]
                        )
                        ss_path = self._download_screenshot(kvs, ss_key, 0)
                        if ss_path:
                            post["screenshots"].append(ss_path)
                    break

            except Exception as e:
                print(f"  âš ï¸  Apify ì—ëŸ¬: {e}, í´ë°± ì‹œë„...")

        # ë‚´ìš©ì´ ì—†ìœ¼ë©´ requests í´ë°±
        if not post["content"]:
            post = self._fetch_simple(url)

        # ìŠ¤í¬ë¦°ìƒ· ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ìƒì„±
        if not post["screenshots"]:
            post["screenshots"] = self._generate_text_screenshots(post)

        return [post]

    def _download_screenshot(self, kvs, key: str, idx: int) -> Optional[str]:
        """Apify KVSì—ì„œ ìŠ¤í¬ë¦°ìƒ· ë‹¤ìš´ë¡œë“œ"""
        try:
            ss_dir = os.path.join(self.config.output_dir, "_screenshots")
            os.makedirs(ss_dir, exist_ok=True)
            path = os.path.join(ss_dir, f"screenshot_{idx}.png")

            record = kvs.get_record(key)
            if record and record.get("value"):
                with open(path, "wb") as f:
                    f.write(record["value"])
                print(f"  ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {path}")
                return path
        except Exception:
            pass
        return None

    def _fetch_dc_article_requests(self, url: str) -> Optional[dict]:
        """requestsë¡œ ë””ì‹œ ê°œë³„ ê¸€ ë³¸ë¬¸+ëŒ“ê¸€ ì§ì ‘ ì¶”ì¶œ (Apify ë¶ˆí•„ìš”, ë¹ ë¦„)"""
        try:
            import requests as _req
            headers = {
                "User-Agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/131.0.0.0 Safari/537.36"
                ),
                "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8",
                "Referer": "https://gall.dcinside.com/",
            }
            r = _req.get(url, headers=headers, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            # ì œëª© ì¶”ì¶œ
            title = ""
            title_m = re.search(r'<span\s+class="title_subject">(.*?)</span>', html)
            if title_m:
                title = re.sub(r'<[^>]+>', '', title_m.group(1)).strip()
            if not title:
                title_m = re.search(r'<title>(.*?)</title>', html)
                title = title_m.group(1).strip() if title_m else ""

            # ë³¸ë¬¸ ì¶”ì¶œ (write_div ì˜ì—­)
            body = ""
            body_m = re.search(
                r'<div\s+class="write_div"[^>]*>(.*?)</div>\s*(?:<div\s+class="btn)',
                html, re.DOTALL
            )
            if not body_m:
                body_m = re.search(
                    r'<div\s+class="write_div"[^>]*>(.*?)</div>',
                    html, re.DOTALL
                )
            if body_m:
                raw = body_m.group(1)
                # <br> â†’ ì¤„ë°”ê¿ˆ, íƒœê·¸ ì œê±°
                raw = re.sub(r'<br\s*/?>', '\n', raw)
                raw = re.sub(r'<[^>]+>', ' ', raw)
                raw = re.sub(r'&[a-zA-Z]+;', ' ', raw)
                raw = re.sub(r'&#\d+;', ' ', raw)
                body = re.sub(r'\s+', ' ', raw).strip()

            # ëŒ“ê¸€ ì¶”ì¶œ (ë² ìŠ¤íŠ¸ ëŒ“ê¸€ ìš°ì„ )
            comments = []
            cmt_matches = re.findall(
                r'<p\s+class="usertxt\s*[^"]*">(.*?)</p>', html
            )
            for cmt in cmt_matches[:5]:
                cmt_text = re.sub(r'<[^>]+>', '', cmt).strip()
                if cmt_text and len(cmt_text) > 5:
                    comments.append(cmt_text)

            if not body or len(body) < 50:
                return None

            return {
                "title": title,
                "content": body[:3000],
                "url": url,
                "source": self.config.source,
                "comments": comments,
                "screenshots": [],
            }

        except Exception as e:
            return None

    def _fetch_article_by_platform(self, url: str) -> Optional[dict]:
        """URL ê¸°ë°˜ìœ¼ë¡œ í”Œë«í¼ ìë™ ê°ì§€ â†’ í•´ë‹¹ í”Œë«í¼ íŒŒì„œë¡œ ë³¸ë¬¸ ì¶”ì¶œ"""
        if "dcinside.com" in url:
            return self._fetch_dc_article_requests(url)
        elif "fmkorea.com" in url:
            return self._fetch_fmkorea_article(url)
        elif "ruliweb.com" in url:
            return self._fetch_ruliweb_article(url)
        elif "instiz.net" in url:
            return self._fetch_instiz_article(url)
        elif "theqoo.net" in url:
            return self._fetch_theqoo_article(url)
        elif "pann.nate.com" in url:
            return self._fetch_natepann_article(url)
        return None

    _REQ_HEADERS = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/131.0.0.0 Safari/537.36"
        ),
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8",
    }

    def _clean_html(self, raw: str) -> str:
        """HTML íƒœê·¸ ì œê±° + ê³µë°± ì •ë¦¬"""
        raw = re.sub(r'<br\s*/?>', '\n', raw)
        raw = re.sub(r'<[^>]+>', ' ', raw)
        raw = re.sub(r'&[a-zA-Z]+;', ' ', raw)
        raw = re.sub(r'&#\d+;', ' ', raw)
        return re.sub(r'\s+', ' ', raw).strip()

    def _fetch_fmkorea_article(self, url: str) -> Optional[dict]:
        """ì—í¨ì½”ë¦¬ì•„ ê°œë³„ ê¸€ ë³¸ë¬¸ ì¶”ì¶œ"""
        try:
            import requests as _req
            r = _req.get(url, headers=self._REQ_HEADERS, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            title = ""
            title_m = re.search(r'<title>(.*?)</title>', html)
            if title_m:
                title = self._clean_html(title_m.group(1))

            # document_* í´ë˜ìŠ¤ ë˜ëŠ” xe_content
            body = ""
            body_m = re.search(
                r'class="document_\d+_\d+\s+[^"]*xe_content[^"]*"[^>]*>(.*?)</div>\s*(?:<div|<script)',
                html, re.DOTALL
            )
            if not body_m:
                body_m = re.search(r'class="xe_content"[^>]*>(.*?)</div>', html, re.DOTALL)
            if body_m:
                body = self._clean_html(body_m.group(1))

            # ëŒ“ê¸€ ì¶”ì¶œ
            comments = []
            cmt_matches = re.findall(r'class="xe_content"[^>]*>(.*?)</div>', html)
            for i, cmt in enumerate(cmt_matches[1:6]):  # ì²« ë²ˆì§¸ëŠ” ë³¸ë¬¸
                cmt_text = self._clean_html(cmt)
                if cmt_text and 5 < len(cmt_text) < 200:
                    comments.append(cmt_text)

            if not body or len(body) < 50:
                return None

            return {
                "title": title,
                "content": body[:3000],
                "url": url,
                "source": "fmkorea",
                "comments": comments,
                "screenshots": [],
            }
        except Exception:
            return None

    def _fetch_ruliweb_article(self, url: str) -> Optional[dict]:
        """ë£¨ë¦¬ì›¹ ê°œë³„ ê¸€ ë³¸ë¬¸ ì¶”ì¶œ"""
        try:
            import requests as _req
            r = _req.get(url, headers=self._REQ_HEADERS, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            title = ""
            title_m = re.search(r'<title>(.*?)</title>', html)
            if title_m:
                title = self._clean_html(title_m.group(1))

            body = ""
            # view_content í´ë˜ìŠ¤ (autolink ë“± ë’¤ì— ì˜¬ ìˆ˜ ìˆìŒ)
            body_m = re.search(
                r'class="view_content[^"]*"[^>]*>(.*?)<div\s+class="(?:view_bottom|board_bottom|row)',
                html, re.DOTALL
            )
            if not body_m:
                body_m = re.search(r'class="view_content[^"]*"[^>]*>(.*?)</article>', html, re.DOTALL)
            if body_m:
                body = self._clean_html(body_m.group(1))

            # ëŒ“ê¸€
            comments = []
            cmt_matches = re.findall(r'class="text_wrapper[^"]*"[^>]*>(.*?)</div>', html)
            for cmt in cmt_matches[:5]:
                cmt_text = self._clean_html(cmt)
                if cmt_text and 5 < len(cmt_text) < 200:
                    comments.append(cmt_text)

            if not body or len(body) < 50:
                return None

            return {
                "title": title,
                "content": body[:3000],
                "url": url,
                "source": "ruliweb",
                "comments": comments,
                "screenshots": [],
            }
        except Exception:
            return None

    def _fetch_instiz_article(self, url: str) -> Optional[dict]:
        """ì¸ìŠ¤í‹°ì¦ˆ ê°œë³„ ê¸€ ë³¸ë¬¸ ì¶”ì¶œ"""
        try:
            import requests as _req
            r = _req.get(url, headers=self._REQ_HEADERS, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            title = ""
            title_m = re.search(r'<title>(.*?)</title>', html)
            if title_m:
                title = self._clean_html(title_m.group(1))
                # "- ì¸ìŠ¤í‹°ì¦ˆ(instiz) ..." ì ‘ë¯¸ì‚¬ ì œê±°
                title = re.sub(r'\s*-\s*ì¸ìŠ¤í‹°ì¦ˆ.*$', '', title)

            body = ""
            body_m = re.search(r'class="memo_content[^"]*"[^>]*>(.*?)</div>', html, re.DOTALL)
            if not body_m:
                body_m = re.search(r'id="memo_content_\d+"[^>]*>(.*?)</div>', html, re.DOTALL)
            if body_m:
                body = self._clean_html(body_m.group(1))

            # ëŒ“ê¸€
            comments = []
            cmt_matches = re.findall(r'class="reply_content[^"]*"[^>]*>(.*?)</div>', html)
            for cmt in cmt_matches[:5]:
                cmt_text = self._clean_html(cmt)
                if cmt_text and 5 < len(cmt_text) < 200:
                    comments.append(cmt_text)

            if not body or len(body) < 50:
                return None

            return {
                "title": title,
                "content": body[:3000],
                "url": url,
                "source": "instiz",
                "comments": comments,
                "screenshots": [],
            }
        except Exception:
            return None

    def _fetch_theqoo_article(self, url: str) -> Optional[dict]:
        """ë”ì¿  ê°œë³„ ê¸€ ë³¸ë¬¸ ì¶”ì¶œ (Rhymix/XE CMS ê¸°ë°˜)"""
        try:
            import requests as _req
            r = _req.get(url, headers=self._REQ_HEADERS, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            title = ""
            title_m = re.search(r'<title>(.*?)</title>', html)
            if title_m:
                title = self._clean_html(title_m.group(1))
                title = re.sub(r'\s*-\s*ë”ì¿ .*$', '', title)

            body = ""
            # xe_content / rhymix_content
            body_m = re.search(
                r'class="[^"]*xe_content[^"]*"[^>]*>(.*?)</div>\s*(?:<div\s+class="(?:document_|rd_body|comment)|<script)',
                html, re.DOTALL
            )
            if not body_m:
                body_m = re.search(r'class="[^"]*xe_content[^"]*"[^>]*>(.*?)</div>', html, re.DOTALL)
            if body_m:
                body = self._clean_html(body_m.group(1))

            # ëŒ“ê¸€
            comments = []
            cmt_matches = re.findall(r'class="[^"]*xe_content[^"]*"[^>]*>(.*?)</div>', html)
            for cmt in cmt_matches[1:6]:
                cmt_text = self._clean_html(cmt)
                if cmt_text and 5 < len(cmt_text) < 200:
                    comments.append(cmt_text)

            if not body or len(body) < 50:
                return None

            return {
                "title": title,
                "content": body[:3000],
                "url": url,
                "source": "theqoo",
                "comments": comments,
                "screenshots": [],
            }
        except Exception:
            return None

    def _fetch_natepann_article(self, url: str) -> Optional[dict]:
        """ë„¤ì´íŠ¸íŒ ê°œë³„ ê¸€ ë³¸ë¬¸ ì¶”ì¶œ"""
        try:
            import requests as _req
            r = _req.get(url, headers=self._REQ_HEADERS, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            title = ""
            title_m = re.search(r'<title>(.*?)</title>', html)
            if title_m:
                title = self._clean_html(title_m.group(1))

            body = ""
            body_m = re.search(r'id="contentArea"[^>]*>(.*?)</div>', html, re.DOTALL)
            if not body_m:
                body_m = re.search(r'class="posting_area[^"]*"[^>]*>(.*?)</div>', html, re.DOTALL)
            if body_m:
                body = self._clean_html(body_m.group(1))

            # ëŒ“ê¸€
            comments = []
            cmt_matches = re.findall(r'class="txt_detail[^"]*"[^>]*>(.*?)</p>', html)
            for cmt in cmt_matches[:5]:
                cmt_text = self._clean_html(cmt)
                if cmt_text and 5 < len(cmt_text) < 200:
                    comments.append(cmt_text)

            if not body or len(body) < 50:
                return None

            return {
                "title": title,
                "content": body[:3000],
                "url": url,
                "source": "natepann",
                "comments": comments,
                "screenshots": [],
            }
        except Exception:
            return None

    def _fetch_simple(self, url: str) -> dict:
        """requests í´ë°± í¬ë¡¤ë§"""
        try:
            headers = {
                "User-Agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36"
                )
            }
            resp = requests.get(url, headers=headers, timeout=15)
            resp.encoding = "utf-8"

            from html.parser import HTMLParser

            class TextExtractor(HTMLParser):
                def __init__(self):
                    super().__init__()
                    self.texts = []
                    self.skip = False
                def handle_starttag(self, tag, attrs):
                    if tag in ("script", "style", "nav", "footer"):
                        self.skip = True
                def handle_endtag(self, tag):
                    if tag in ("script", "style", "nav", "footer"):
                        self.skip = False
                def handle_data(self, data):
                    if not self.skip and data.strip():
                        self.texts.append(data.strip())

            parser = TextExtractor()
            parser.feed(resp.text)
            content = "\n".join(parser.texts)

            title_match = re.search(r"<title>(.*?)</title>", resp.text)
            title = title_match.group(1) if title_match else "í¬ë¡¤ë§ëœ ê¸€"

            return {
                "title": title,
                "content": content[:3000],
                "url": url,
                "source": "fallback",
                "screenshots": [],
            }
        except Exception as e:
            print(f"  âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return {"title": "ì‹¤íŒ¨", "content": "", "url": url,
                    "source": "error", "screenshots": []}

    def _scrape_fallback_with_fake_screenshots(self) -> list[dict]:
        """Apify ì—†ì„ ë•Œ í´ë°± + í…ìŠ¤íŠ¸ ìŠ¤í¬ë¦°ìƒ· ìƒì„±"""
        source_info = self.SOURCES[self.config.source]
        url = source_info["best_url"]
        if self.config.source == "dcinside":
            url = url.format(gallery=self.config.gallery)
        post = self._fetch_simple(url)
        post["screenshots"] = self._generate_text_screenshots(post)
        return [post]

    def _generate_text_screenshots(self, post: dict) -> list[str]:
        """
        ğŸ¨ í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°€ì§œ 'ì»¤ë®¤ë‹ˆí‹° ìŠ¤í¬ë¦°ìƒ·' ìƒì„±
        ì‹¤ì œ ë””ì‹œ/ë„¤ì´íŠ¸íŒ UIë¥¼ í‰ë‚´ë‚¸ ì´ë¯¸ì§€
        """
        print(f"  ğŸ¨ í…ìŠ¤íŠ¸ ê¸°ë°˜ ìŠ¤í¬ë¦°ìƒ· ìƒì„± ì¤‘...")
        ss_dir = os.path.join(self.config.output_dir, "_screenshots")
        os.makedirs(ss_dir, exist_ok=True)

        w, h = self.config.width, self.config.height
        content = post.get("content", "")
        title = post.get("title", "")
        source = post.get("source", "community")

        # ë‚´ìš©ì„ 3~5 ì²­í¬ë¡œ ë¶„í•  (ê° ì²­í¬ê°€ í•œ ì¥ë©´ì˜ ë°°ê²½)
        paragraphs = [p.strip() for p in content.split("\n") if p.strip()]
        if not paragraphs:
            paragraphs = [content[:200]]

        # ìµœì†Œ 3ì¥, ìµœëŒ€ 6ì¥
        chunk_size = max(1, len(paragraphs) // 5)
        text_chunks = []
        for i in range(0, len(paragraphs), max(1, chunk_size)):
            chunk = "\n".join(paragraphs[i:i + chunk_size])
            if chunk.strip():
                text_chunks.append(chunk[:300])
        text_chunks = text_chunks[:6] if text_chunks else ["ë‚´ìš© ì—†ìŒ"]

        font = FontManager.get_font(36)
        title_font = FontManager.get_font(44, bold=True)

        paths = []
        for idx, chunk_text in enumerate(text_chunks):
            img = Image.new("RGB", (w, h))
            draw = ImageDraw.Draw(img)

            # ì»¤ë®¤ë‹ˆí‹° ëŠë‚Œì˜ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½
            # (ì–´ë‘ìš´ ë°°ê²½ + ë³¸ë¬¸ í…ìŠ¤íŠ¸ = ë””ì‹œ/ë„¤ì´íŠ¸íŒ ëŠë‚Œ)
            colors = [
                [(25, 28, 35), (45, 38, 30)],   # ë‹¤í¬ë¸”ë£¨ â†’ ë‹¤í¬ë¸Œë¼ìš´
                [(35, 25, 30), (25, 35, 40)],   # ë‹¤í¬ë ˆë“œ â†’ ë‹¤í¬í‹¸
                [(30, 30, 20), (20, 25, 40)],   # ë‹¤í¬ì˜ë¡œ â†’ ë‹¤í¬ë¸”ë£¨
                [(20, 30, 25), (35, 25, 35)],   # ë‹¤í¬ê·¸ë¦° â†’ ë‹¤í¬í¼í”Œ
                [(35, 30, 20), (25, 20, 35)],   # ë‹¤í¬ì˜¤ë Œì§€ â†’ ë‹¤í¬í¼í”Œ
                [(25, 25, 35), (35, 30, 25)],   # ë‹¤í¬ë¸”ë£¨ â†’ ë‹¤í¬ë¸Œë¼ìš´
            ]
            c1, c2 = colors[idx % len(colors)]
            for y in range(h):
                ratio = y / h
                r = int(c1[0] * (1 - ratio) + c2[0] * ratio)
                g = int(c1[1] * (1 - ratio) + c2[1] * ratio)
                b = int(c1[2] * (1 - ratio) + c2[2] * ratio)
                draw.line([(0, y), (w, y)], fill=(r, g, b))

            # ìƒë‹¨: ì†ŒìŠ¤ í‘œì‹œ ë°”
            bar_h = 80
            draw.rectangle([(0, 0), (w, bar_h)], fill=(18, 18, 22, 230))
            source_labels = {
                "dcinside": "ë””ì‹œì¸ì‚¬ì´ë“œ ë² ìŠ¤íŠ¸",
                "natepann": "ë„¤ì´íŠ¸íŒ HOT",
                "direct": "ì»¤ë®¤ë‹ˆí‹° ê¸€",
                "fallback": "ì»¤ë®¤ë‹ˆí‹°",
                "manual": "ì°",
            }
            label = source_labels.get(source, "ì»¤ë®¤ë‹ˆí‹°")
            draw.text((30, 20), f"ğŸ“‹ {label}", fill=(180, 180, 180), font=font)

            # ì œëª© ì˜ì—­ (ì²« ë²ˆì§¸ ì¥ì—ë§Œ)
            y_offset = bar_h + 30
            if idx == 0 and title:
                # ì œëª© ë°°ê²½ ë°•ìŠ¤
                title_wrapped = textwrap.fill(title[:40], width=20)
                draw.rectangle(
                    [(40, y_offset), (w - 40, y_offset + 120)],
                    fill=(255, 255, 255, 15),
                    outline=(80, 80, 80),
                    width=1
                )
                draw.text(
                    (60, y_offset + 15), title_wrapped,
                    fill=(255, 255, 255), font=title_font
                )
                y_offset += 140

            # ë³¸ë¬¸ í…ìŠ¤íŠ¸ (ì»¤ë®¤ë‹ˆí‹° ê¸€ ëŠë‚Œ)
            # ì¤„ë°”ê¿ˆ ì²˜ë¦¬
            wrapped_lines = []
            for line in chunk_text.split("\n"):
                wrapped = textwrap.fill(line, width=24)  # ì„¸ë¡œ í™”ë©´ì´ë¼ ì¢ê²Œ
                wrapped_lines.extend(wrapped.split("\n"))

            text_y = y_offset + 40
            for line in wrapped_lines[:20]:  # ìµœëŒ€ 20ì¤„
                if text_y > h - 200:
                    break
                # ì•½ê°„ì˜ íˆ¬ëª… ë°°ê²½
                bbox = draw.textbbox((60, text_y), line, font=font)
                text_w = bbox[2] - bbox[0]
                draw.rectangle(
                    [(50, text_y - 5), (70 + text_w, text_y + 42)],
                    fill=(0, 0, 0, 60)
                )
                draw.text(
                    (60, text_y), line,
                    fill=(220, 220, 220), font=font
                )
                text_y += 48

            # í•˜ë‹¨: í˜ì´ì§€ í‘œì‹œ
            page_text = f"{idx + 1} / {len(text_chunks)}"
            draw.text(
                (w // 2 - 30, h - 80), page_text,
                fill=(120, 120, 120), font=font
            )

            # ì €ì¥
            path = os.path.join(ss_dir, f"textss_{idx:02d}.png")
            img.save(path, quality=90)
            paths.append(path)

        print(f"  âœ… {len(paths)}ì¥ ìŠ¤í¬ë¦°ìƒ· ì´ë¯¸ì§€ ìƒì„±")
        return paths


# ============================================================
# ğŸ“ Stage 2: ëŒ€ë³¸ ìƒì„± (Claude API) â€” v3 ì—…ê·¸ë ˆì´ë“œ
# ============================================================
class ScriptGenerator:
    """v4.3: í•œêµ­ ì¸í„°ë„· ì»¤ë®¤ë‹ˆí‹° ë°”ì´ëŸ´ ì½˜í…ì¸  ì „ë¬¸ ëŒ€ë³¸ ìƒì„±ê¸°"""

    SYSTEM_PROMPT = """ë„ˆëŠ” í•œêµ­ ì¸í„°ë„· ì»¤ë®¤ë‹ˆí‹° ë°”ì´ëŸ´ ì½˜í…ì¸  ì „ë¬¸ ì‘ê°€ì•¼.
ìœ íŠœë¸Œ ìˆì¸  ì¡°íšŒìˆ˜ 100ë§Œ+ ì°ëŠ” ëŒ€ë³¸ë§Œ ë§Œë“ ë‹¤.

## ğŸ¯ í•µì‹¬: "ì™œ ë² ìŠ¤íŠ¸ì— ì˜¬ëëŠ”ì§€"ë¥¼ ê¿°ëš«ì–´ë¼
- ê³µê°ì„±: "ì•„ ë‚˜ë„ ã…‹ã…‹" ë°˜ì‘ ë‚˜ì˜¬ í¬ì¸íŠ¸
- ë°˜ì „ë ¥: ê²°ë§ì´ ì˜ˆìƒ ë°–ì¸ ë¶€ë¶„
- ê°ì • ë¡¤ëŸ¬ì½”ìŠ¤í„°: ì›ƒë‹¤ê°€ ìš¸ë‹¤ê°€ ì†Œë¦„ë‹ëŠ” êµ¬ê°„
- ë°ˆ ì ì¬ë ¥: ì§¤ë¡œ í¼ì§ˆ ìˆ˜ ìˆëŠ” ëª…ëŒ€ì‚¬

## ğŸ“ ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥)
```json
{
  "title": "ìˆì¸  ì œëª© (15ì ì´ë‚´, ì´ëª¨ì§€ í¬í•¨)",
  "hook": "ì²« 3ì´ˆ í›„í‚¹ ë©˜íŠ¸ (ì§ˆë¬¸í˜• or ì¶©ê²©í˜•)",
  "script": [
    {
      "text": "ìë§‰ ë¬¸ì¥ (15ì ì´ë‚´)",
      "emotion": "excited|shocked|warm|sad|funny|serious|whisper|angry|neutral|tension",
      "highlight": false,
      "pause_ms": 0,
      "scene_hint": "ë°°ê²½ ì´ë¯¸ì§€ í‚¤ì›Œë“œ (ì˜ì–´, ë¶„ìœ„ê¸° ë¬˜ì‚¬)"
    }
  ],
  "tags": ["#íƒœê·¸1", ..., "#íƒœê·¸15"],
  "thumbnail_text": "ì¸ë„¤ì¼ í…ìŠ¤íŠ¸ (5ì ì´ë‚´)",
  "description": "ì˜ìƒ ì„¤ëª… (50ì ì´ë‚´, í•´ì‹œíƒœê·¸ í¬í•¨)",
  "viral_reason": "ì´ ê¸€ì´ ë² ìŠ¤íŠ¸ ëœ ì´ìœ  í•œì¤„ ìš”ì•½"
}
```

## ğŸ¬ ëŒ€ë³¸ êµ¬ì„± ê·œì¹™
1. **ì²« 3ì´ˆ (Hook)**: ì‹œì²­ìê°€ ìŠ¤í¬ë¡¤ì„ ë©ˆì¶œ í›„í‚¹ ë©˜íŠ¸
   - ì§ˆë¬¸í˜•: "ì´ê±° ì‹¤í™”ëƒê³ ìš”?" / "ì´ëŸ° ê²½í—˜ ì €ë§Œ ìˆë‚˜ìš”?"
   - ì¶©ê²©í˜•: "ë³‘ì›ì—ì„œ ì ˆëŒ€ ì•ˆ ì•Œë ¤ì£¼ëŠ” ê±°" / "ì½ë‹¤ê°€ ì†Œë¦„ë‹ì•˜ìŠµë‹ˆë‹¤"
   - ê²°ë§ ìŠ¤í¬ì¼ëŸ¬í˜•: "ê²°êµ­ ì´ë ‡ê²Œ ëìŠµë‹ˆë‹¤"
2. **ë³¸ë¬¸**: ì›ê¸€ì˜ í•µì‹¬ ì°ì„ êµ¬ì–´ì²´ë¡œ í’€ì–´ì„œ ì „ë‹¬
   - "~í–ˆëŠ”ë°ìš”" "~ê±°ë“ ìš”" "~ì–ì•„ìš”" ë§íˆ¬ í•„ìˆ˜
   - ë°˜ì „ í¬ì¸íŠ¸ëŠ” ë°˜ë“œì‹œ ì‚´ë ¤ì„œ
   - ëŒ“ê¸€ ë°˜ì‘ë„ 1~2ê°œ ì¸ìš© ("ëŒ“ê¸€ì—ì„œ ë‚œë¦¬ë‚¨ ã…‹ã…‹", "ë°˜ì‘ì´ ì‹¤í™”ì„")
3. **ë§ˆë¬´ë¦¬**: CTA (ì¢‹ì•„ìš”/êµ¬ë… ìœ ë„) + ì—¬ìš´ í•œë§ˆë””
4. **ì—­ìˆœ êµ¬ì¡°**: ê²°ë§/ë°˜ì „ì„ ì²« ì¤„ì— ë˜ì§ â†’ "ì´ ì‚¬ê±´ì˜ ì‹œì‘ì€..."ìœ¼ë¡œ ëŒì•„ê°
5. **ë¬¸ì¥ ê¸¸ì´**: í•œ ì¤„ ìµœëŒ€ 15ì (ìˆì¸  ê°€ë…ì„±)
6. **ê°ì • ë³€í™”**: ìµœì†Œ 5ê°€ì§€ ì´ìƒ ê°ì • ì „í™˜ìœ¼ë¡œ ì´íƒˆ ë°©ì§€
7. **highlight**: í•µì‹¬ ë°˜ì „/ì¶©ê²©/ì›ƒìŒ í¬ì¸íŠ¸ì— true (25-35%)
8. **ë¶„ëŸ‰**: 18~25ë¬¸ì¥ (50~58ì´ˆ)
9. **pause_ms**: ë°˜ì „ ì§ì „ 800~1200ms, í‰ì†Œ 200~400ms (ê¸´ì¥ê° ê·¹ëŒ€í™”)
10. **scene_hint**: AI ì´ë¯¸ì§€ ìƒì„±ìš©, ì˜ì–´ë¡œ ë¶„ìœ„ê¸° ë¬˜ì‚¬
11. **tags**: ë°˜ë“œì‹œ 15ê°œ. SEO ìµœì í™” (#ìˆì¸  #ì° #ë ˆì „ë“œ ë“±)

## ğŸš« ì ˆëŒ€ ê¸ˆì§€
- ê°¤ëŸ¬ë¦¬ ì†Œê°œê¸€, ì´ìš©ì•ˆë‚´, ê³µì§€ì‚¬í•­ ë‚´ìš© ì¼ì²´ ê¸ˆì§€
- "ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬", "ê°¤ëŸ¬ë¦¬ ê°œì„¤", "ë§¤ë‹ˆì € ì‹ ì²­" ë“± ìš´ì˜ ê´€ë ¨ ë©˜íŠ¸ ê¸ˆì§€
- ë„¤ì´íŠ¸íŒ/ë””ì‹œ ì‚¬ì´íŠ¸ UI ì„¤ëª… ê¸ˆì§€
- ë”±ë”±í•œ ë‰´ìŠ¤ ë³´ë„ì²´ ê¸ˆì§€ (êµ¬ì–´ì²´ë§Œ!)
- ì‹¤ëª…/ê°œì¸ì •ë³´ ì‚¬ìš© ê¸ˆì§€
- ë¹„ì†ì–´ ìˆœí™” (ìì—°ìŠ¤ëŸ½ê²Œ)
- í—ˆìœ„ì‚¬ì‹¤ ì¶”ê°€ ê¸ˆì§€ (ì›ë¬¸ ê¸°ë°˜ ê°ìƒ‰ë§Œ)
- text í•„ë“œì— ë”°ì˜´í‘œ ì‚¬ìš© ì‹œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
"""

    def __init__(self, config: Config):
        self.config = config
        self.client = anthropic.Anthropic(api_key=config.claude_api_key)

    def generate(self, post: dict) -> Optional[dict]:
        """ì»¤ë®¤ë‹ˆí‹° ê¸€ â†’ ìˆì¸  ëŒ€ë³¸. ì†ŒìŠ¤ ë¶€ì¡± ì‹œ None ë°˜í™˜."""
        print(f"\n{'='*60}")
        print(f"ğŸ“ Stage 2: ëŒ€ë³¸ ìƒì„±")
        print(f"  ì œëª©: {post['title'][:40]}...")
        print(f"{'='*60}")

        content = post.get("content", "")
        title = post.get("title", "")

        # â”€â”€ ì†ŒìŠ¤ í’ˆì§ˆ ì²´í¬ â”€â”€
        if len(content) < 200:
            print(f"  âš ï¸  ì†ŒìŠ¤ ë‚´ìš© ë¶€ì¡± ({len(content)}ì), ê±´ë„ˆëœ€")
            return None

        # ì†Œê°œê¸€/ê³µì§€ê¸€ ì¦‰ì‹œ ì°¨ë‹¨ (1ê°œë§Œ ìˆì–´ë„ OUT)
        block_kw = [
            "ê°¤ëŸ¬ë¦¬ ì´ìš© ì•ˆë‚´", "ê°¤ëŸ¬ë¦¬ ì´ìš©ì•ˆë‚´", "ì´ìš© ì•ˆë‚´",
            "ê°¤ëŸ¬ë¦¬ ì†Œê°œ", "ê°¤ëŸ¬ë¦¬ë¥¼ ì†Œê°œ", "ê°¤ëŸ¬ë¦¬ ê°œì„¤",
            "ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬", "ë§ˆì´ë„ˆê°¤ëŸ¬ë¦¬",
            "CONNECTING HEARTS", "ë””ì‹œì¸ì‚¬ì´ë“œì…ë‹ˆë‹¤",
        ]
        for kw in block_kw:
            if kw in content or kw in title:
                print(f"  ğŸš« ì†Œê°œ/ê³µì§€ê¸€ ì°¨ë‹¨: '{kw}' ë°œê²¬ â†’ ê±´ë„ˆëœ€")
                return None

        # UI/ìŠ¤íŒ¸ í‚¤ì›Œë“œ (2ê°œ ì´ìƒ)
        spam_keywords = [
            "ê°¤ëŸ¬ë¦¬ ë§Œë“¤ê¸°", "íšŒì›ê°€ì…", "ë¡œê·¸ì¸", "ê´‘ê³  ë¬¸ì˜",
            "ê°¤ëŸ¬ë¦¬ ê·œì •", "ê³µì§€ì‚¬í•­", "ìš´ì˜ ë°©ì¹¨", "ë§¤ë‹ˆì € ì‹ ì²­",
        ]
        spam_count = sum(1 for kw in spam_keywords if kw in content)
        if spam_count >= 2:
            print(f"  âš ï¸  UI/ê´‘ê³  í…ìŠ¤íŠ¸ ê°ì§€ ({spam_count}ê°œ í‚¤ì›Œë“œ), ê±´ë„ˆëœ€")
            return None

        start = time.time()

        # ë² ìŠ¤íŠ¸ ëŒ“ê¸€ ì¶”ì¶œ
        comments = post.get('comments', [])
        comments_text = ""
        if comments:
            top_comments = comments[:4]
            comments_text = "\n## ë² ìŠ¤íŠ¸ ëŒ“ê¸€ (ë°˜ì‘ í™œìš© ê°€ëŠ¥)\n"
            for c in top_comments:
                comments_text += f"- {c}\n"

        source_name = post.get('source', 'ì»¤ë®¤ë‹ˆí‹°')
        user_prompt = f"""[ì†ŒìŠ¤ ì •ë³´]
- ì¶œì²˜: {source_name}
- ì›ë¬¸ ì œëª©: {post['title']}

[ì›ë¬¸ ë‚´ìš©]
{post['content'][:2500]}
{comments_text}
[ì„ë¬´]
ì´ ê¸€ì´ ì™œ ë² ìŠ¤íŠ¸ì— ì˜¬ëëŠ”ì§€ í•µì‹¬ í¬ì¸íŠ¸ë¥¼ íŒŒì•…í•˜ê³ ,
ìœ íŠœë¸Œ ìˆì¸  60ì´ˆ ë¶„ëŸ‰ì˜ ëŒ€ë³¸ìœ¼ë¡œ ì¬êµ¬ì„±í•´ë¼.

[í•„ìˆ˜ ê·œì¹™]
1. ì²« 3ì´ˆ: ì‹œì²­ìê°€ ìŠ¤í¬ë¡¤ì„ ë©ˆì¶œ í›„í‚¹ ë©˜íŠ¸ (ì§ˆë¬¸í˜• or ì¶©ê²©í˜•)
   ì˜ˆ: "ì´ê±° ì‹¤í™”ëƒê³ ìš”?" / "ë³‘ì›ì—ì„œ ì ˆëŒ€ ì•ˆ ì•Œë ¤ì£¼ëŠ” ê±°" / "ì½ë‹¤ê°€ ì†Œë¦„ë‹ì•˜ìŠµë‹ˆë‹¤"
2. ë³¸ë¬¸: ì›ê¸€ì˜ í•µì‹¬ ì°ì„ êµ¬ì–´ì²´ë¡œ í’€ì–´ì„œ ì „ë‹¬
   - "~í–ˆëŠ”ë°ìš”" "~ê±°ë“ ìš”" "~ì–ì•„ìš”" ë§íˆ¬ í•„ìˆ˜
   - ë°˜ì „ í¬ì¸íŠ¸ëŠ” ë°˜ë“œì‹œ ì‚´ë ¤ì„œ
   - ëŒ“ê¸€ ë°˜ì‘ë„ 1~2ê°œ ì¸ìš© ("ëŒ“ê¸€ì—ì„œ ë‚œë¦¬ë‚¨ ã…‹ã…‹")
3. ë§ˆë¬´ë¦¬: CTA (ì¢‹ì•„ìš”/êµ¬ë… ìœ ë„) + ì—¬ìš´ í•œë§ˆë””
4. ê°ì • íƒœê·¸: excited/shocked/warm/sad/funny/serious/whisper/angry/neutral/tension
5. pause_ms: ë°˜ì „ ì§ì „ 800~1200ms, í‰ì†Œ 200~400ms
6. scene_hint: AI ì´ë¯¸ì§€ ìƒì„±ìš© â†’ ì˜ì–´ë¡œ ë¶„ìœ„ê¸° ë¬˜ì‚¬
7. viral_reason: ì´ ê¸€ì´ ì™œ ë² ìŠ¤íŠ¸ì¸ì§€ í•œì¤„ë¡œ
8. í•œ ë¬¸ì¥ ìµœëŒ€ 15ì (ìë§‰ ê°€ë…ì„±)
9. ì´ 18~25ë¬¸ì¥ (50~58ì´ˆ)
10. JSONë§Œ ì¶œë ¥ (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´)
"""

        try:
            response = self.client.messages.create(
                model="claude-sonnet-4-20250514",
                max_tokens=2000,
                system=self.SYSTEM_PROMPT,
                messages=[{"role": "user", "content": user_prompt}],
            )

            elapsed = time.time() - start
            raw = response.content[0].text
            script_data = self._extract_json(raw)

            script_data["_meta"] = {
                "time": f"{elapsed:.1f}s",
                "model": "claude-sonnet-4-20250514",
                "source": post.get("content", "")[:100],
            }

            n = len(script_data.get("script", []))
            print(f"  âœ… ëŒ€ë³¸ ì™„ë£Œ! ({elapsed:.1f}ì´ˆ, {n}ë¬¸ì¥)")
            return script_data

        except Exception as e:
            print(f"  âŒ Claude API ì—ëŸ¬: {e}")
            return self._fallback_script(post)

    def generate_from_topic(self, topic: str) -> Optional[dict]:
        # manual topicì€ í’ˆì§ˆ í•„í„°ë¥¼ ìš°íšŒí•˜ê¸° ìœ„í•´ 200ì ì´ìƒ íŒ¨ë”©
        padded = (f"'{topic}'ì— ëŒ€í•œ ì»¤ë®¤ë‹ˆí‹° ì°ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”. "
                  f"ì‹¤ì œ ìˆì„ë²•í•œ ì—í”¼ì†Œë“œ, ë°˜ì „ê³¼ ê°ì • ë³€í™” í¬í•¨. "
                  f"ë””í…Œì¼í•œ ìƒí™© ë¬˜ì‚¬ì™€ ì‚¬ëŒë“¤ì˜ ë°˜ì‘, ëŒ“ê¸€ ë°˜ì‘ê¹Œì§€ í¬í•¨í•´ì„œ ìƒìƒí•˜ê²Œ ì‘ì„±. "
                  f"ì£¼ì œ: {topic}. ì´ ì£¼ì œë¡œ ì¡°íšŒìˆ˜ í­ë°œí˜• ìˆì¸  ëŒ€ë³¸ì„ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.")
        fake = {
            "title": topic,
            "content": padded,
            "source": "manual",
        }
        return self.generate(fake)

    def _extract_json(self, text: str) -> dict:
        json_match = re.search(r"```json\s*(.*?)\s*```", text, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))
        json_match = re.search(r"\{.*\}", text, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(0))
        raise ValueError("JSON íŒŒì‹± ì‹¤íŒ¨")

    def _fallback_script(self, post: dict) -> dict:
        t = post["title"][:10]
        return {
            "title": t, "hook": f"{t} ì´ ì‚¬ê±´ì˜ ì „ë§",
            "script": [
                {"text": t, "emotion": "surprise", "highlight": True,
                 "pause_ms": 0, "scene_hint": "ì œëª© ì¥ë©´"},
                {"text": "ì´ ì´ì•¼ê¸°ì˜ ì‹œì‘ì€", "emotion": "neutral",
                 "highlight": False, "pause_ms": 0, "scene_hint": "ë„ì…"},
                {"text": "ì•„ë¬´ë„ ì˜ˆìƒ ëª»í–ˆì£ ", "emotion": "tension",
                 "highlight": False, "pause_ms": 500, "scene_hint": "ê¸´ì¥"},
                {"text": "ì—¬ëŸ¬ë¶„ ìƒê°ì€?", "emotion": "neutral",
                 "highlight": False, "pause_ms": 0, "scene_hint": "ë§ˆë¬´ë¦¬"},
            ],
            "tags": ["#ì°", "#ë ˆì „ë“œ"], "thumbnail_text": t[:5],
        }


# ============================================================
# ğŸ”Š Stage 3: TTS + ìë§‰ íƒ€ì´ë°
# ============================================================
class TTSEngine:
    """v4.2: ë¬¸ì¥ë³„ ê°œë³„ TTS â€” ì™„ë²½í•œ ìŒì„±-ìë§‰ ì‹±í¬

    ê° ë¬¸ì¥ì„ ë…ë¦½ì ìœ¼ë¡œ TTS ìƒì„± â†’ ffprobeë¡œ ì •í™•í•œ ê¸¸ì´ ì¸¡ì •.
    ê°ì •ë³„ rate/pitchë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì ìš©.
    """

    # ê°ì •ë³„ ì†ë„/í”¼ì¹˜ ë§¤í•‘ (v4.3 í™•ì¥)
    EMOTION_PROSODY = {
        "neutral":  {"rate": "+5%",  "pitch": "-1Hz"},
        "tension":  {"rate": "+12%", "pitch": "+1Hz"},
        "surprise": {"rate": "+0%",  "pitch": "+3Hz"},
        "anger":    {"rate": "+8%",  "pitch": "-3Hz"},
        "angry":    {"rate": "+8%",  "pitch": "-3Hz"},
        "sad":      {"rate": "-5%",  "pitch": "-4Hz"},
        "fun":      {"rate": "+10%", "pitch": "+2Hz"},
        "funny":    {"rate": "+10%", "pitch": "+2Hz"},
        "shock":    {"rate": "-3%",  "pitch": "+0Hz"},
        "shocked":  {"rate": "-3%",  "pitch": "+0Hz"},
        "relief":   {"rate": "+3%",  "pitch": "-2Hz"},
        "excited":  {"rate": "+15%", "pitch": "+4Hz"},
        "warm":     {"rate": "-2%",  "pitch": "-2Hz"},
        "serious":  {"rate": "+0%",  "pitch": "-3Hz"},
        "whisper":  {"rate": "-8%",  "pitch": "-5Hz"},
    }

    def __init__(self, config: Config):
        self.config = config

    async def generate(self, script_data: dict, work_dir: str) -> list[dict]:
        print(f"\n{'='*60}")
        print(f"ğŸ”Š Stage 3: TTS ìƒì„± (ë¬¸ì¥ë³„ ê°œë³„ ëª¨ë“œ v4.2)")
        print(f"{'='*60}")

        script_lines = script_data.get("script", [])
        chunks = []
        current_ms = 0

        for idx, line in enumerate(script_lines):
            text = line["text"]
            emotion = line.get("emotion", "neutral")
            prosody = self.EMOTION_PROSODY.get(emotion, self.EMOTION_PROSODY["neutral"])

            # ë¬¸ì¥ ê°„ ê°„ê²© (80ms)
            if idx > 0:
                pause_extra = line.get("pause_ms", 0)
                current_ms += 80 + pause_extra

            # ê°œë³„ ì˜¤ë””ì˜¤ íŒŒì¼
            audio_path = os.path.join(work_dir, f"sent_{idx:03d}.mp3")

            try:
                communicate = edge_tts.Communicate(
                    text=text,
                    voice=self.config.tts_voice,
                    rate=prosody["rate"],
                    pitch=prosody["pitch"],
                )

                with open(audio_path, "wb") as f:
                    async for ev in communicate.stream():
                        if ev["type"] == "audio":
                            f.write(ev["data"])

                # ë¹ˆ íŒŒì¼ ì²´í¬
                if not os.path.exists(audio_path) or os.path.getsize(audio_path) < 100:
                    raise ValueError(f"ë¹ˆ ì˜¤ë””ì˜¤ íŒŒì¼: {os.path.getsize(audio_path) if os.path.exists(audio_path) else 0}B")

                # ì •í™•í•œ ê¸¸ì´ ì¸¡ì •
                duration_ms = self._get_duration_ms(audio_path)

            except Exception as e:
                print(f"  âš ï¸  TTS ì‹¤íŒ¨ [{idx}] {text}: {e}")
                duration_ms = 1500
                # ë¬´ìŒ íŒŒì¼ ìƒì„±
                subprocess.run([
                    FFMPEG_PATH, "-y", "-f", "lavfi",
                    "-i", f"anoisesrc=a=0.001:c=pink:r=44100:d=1.5",
                    "-c:a", "libmp3lame", "-b:a", "128k", audio_path,
                ], capture_output=True)

            start_ms = current_ms
            end_ms = current_ms + duration_ms

            chunks.append({
                "index": idx,
                "text": text,
                "emotion": emotion,
                "highlight": line.get("highlight", False),
                "scene_hint": line.get("scene_hint", ""),
                "audio_file": audio_path,
                "batch_idx": idx,
                "start_ms": start_ms,
                "end_ms": end_ms,
                "duration_ms": duration_ms,
                "pause_ms": line.get("pause_ms", 0),
            })

            current_ms = end_ms

            emo = emotion[:3]
            marker = "â­" if line.get("highlight") else "  "
            print(
                f"  ğŸ™ï¸ {marker}[{idx+1:02d}] "
                f"[{emo}|{prosody['rate']}/{prosody['pitch']}] "
                f"{text} ({duration_ms}ms)"
            )

        total = current_ms / 1000
        print(f"\n  âœ… TTS ì™„ë£Œ: {len(chunks)}ë¬¸ì¥, ê°œë³„ìƒì„±, {total:.1f}ì´ˆ")
        return chunks

    def _get_duration_ms(self, path: str) -> int:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ê¸¸ì´ë¥¼ ë°€ë¦¬ì´ˆë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # 1ì°¨: ffprobe ì‚¬ìš©
        if FFPROBE_PATH:
            try:
                r = subprocess.run(
                    [FFPROBE_PATH, "-v", "quiet", "-show_entries",
                     "format=duration", "-of", "csv=p=0", path],
                    capture_output=True, text=True, encoding="utf-8", errors="replace"
                )
                if r.returncode == 0 and r.stdout.strip():
                    return int(float(r.stdout.strip()) * 1000)
            except Exception:
                pass

        # 2ì°¨: ffmpeg -i ë¡œ duration íŒŒì‹± (ffprobe ì—†ì„ ë•Œ)
        try:
            r = subprocess.run(
                [FFMPEG_PATH, "-i", path, "-f", "null", "-"],
                capture_output=True, text=True, encoding="utf-8", errors="replace"
            )
            # stderrì—ì„œ Duration ì •ë³´ íŒŒì‹±
            import re as _re
            m = _re.search(r"Duration:\s*(\d+):(\d+):(\d+)\.(\d+)", r.stderr)
            if m:
                h, mi, s, cs = int(m.group(1)), int(m.group(2)), int(m.group(3)), int(m.group(4))
                return (h * 3600 + mi * 60 + s) * 1000 + cs * 10
        except Exception:
            pass

        return 2000


# ============================================================
# ğŸ¬ Stage 4: ì˜ìƒ ì¡°ë¦½ (ìŠ¤í¬ë¦°ìƒ· ë°°ê²½ + ìì—°ìŠ¤ëŸ¬ìš´ ìë§‰)
# ============================================================
class VideoAssembler:
    """
    v3 í•µì‹¬ ë³€ê²½:
    - ë°°ê²½: ë‹¨ìƒ‰ â†’ ì»¤ë®¤ë‹ˆí‹° ê¸€ ìŠ¤í¬ë¦°ìƒ· (ë¸”ëŸ¬+ì–´ë‘¡ê²Œ)
    - ìë§‰: ASS â†’ Pillowë¡œ í”„ë ˆì„ë³„ ë Œë”ë§ (í°íŠ¸ ììœ ë„ â†‘)
    - ì¥ë©´ ì „í™˜: ìŠ¤í¬ë¦°ìƒ· ê°„ ë¶€ë“œëŸ¬ìš´ ì „í™˜
    """

    def __init__(self, config: Config):
        self.config = config
        self.w = config.width
        self.h = config.height
        self.font = FontManager.get_font(config.font_size)
        self.font_bold = FontManager.get_font(config.font_size_highlight, bold=True)

    def assemble(self, script_data: dict, chunks: list[dict],
                 screenshots: list[str], work_dir: str) -> str:
        """ìŠ¤í¬ë¦°ìƒ· ë°°ê²½ + ìì—°ìŠ¤ëŸ¬ìš´ ìë§‰ â†’ ìµœì¢… MP4"""
        print(f"\n{'='*60}")
        print(f"ğŸ¬ Stage 4: ì˜ìƒ ì¡°ë¦½")
        print(f"  ìŠ¤í¬ë¦°ìƒ·: {len(screenshots)}ì¥")
        print(f"{'='*60}")

        # Step 1: ì˜¤ë””ì˜¤ í•©ì¹˜ê¸°
        concat_audio = os.path.join(work_dir, "full_audio.mp3")
        self._concat_audio(chunks, concat_audio, work_dir)

        total_ms = max(c["end_ms"] for c in chunks) + 500
        total_sec = total_ms / 1000
        total_frames = int(total_sec * self.config.fps)

        # Step 2: ìŠ¤í¬ë¦°ìƒ· ë°°ê²½ ì¤€ë¹„ (ë¸”ëŸ¬ + ì–´ë‘¡ê²Œ)
        bg_frames = self._prepare_backgrounds(
            screenshots, total_frames, script_data, work_dir
        )

        # Step 3: í”„ë ˆì„ë³„ ìë§‰ ë Œë”ë§ â†’ PNG ì‹œí€€ìŠ¤
        frames_dir = os.path.join(work_dir, "frames")
        os.makedirs(frames_dir, exist_ok=True)

        print(f"  ğŸ–¼ï¸  {total_frames}í”„ë ˆì„ ë Œë”ë§ ì¤‘...")
        for frame_idx in range(total_frames):
            current_time_ms = (frame_idx / self.config.fps) * 1000

            # ë°°ê²½ ì„ íƒ (ì‹œê°„ì— ë”°ë¼ ìŠ¤í¬ë¦°ìƒ· ì „í™˜)
            bg_idx = min(
                int(frame_idx / total_frames * len(bg_frames)),
                len(bg_frames) - 1
            )
            frame = bg_frames[bg_idx].copy()

            # Ken Burns íš¨ê³¼: ëŠë¦° ì¤Œì¸ (1.0â†’1.08x over total duration)
            progress = frame_idx / max(1, total_frames)
            zoom = 1.0 + 0.08 * progress
            if zoom > 1.01:
                zw = int(self.w * zoom)
                zh = int(self.h * zoom)
                frame = frame.resize((zw, zh), Image.LANCZOS)
                left = (zw - self.w) // 2
                top = (zh - self.h) // 2
                frame = frame.crop((left, top, left + self.w, top + self.h))

            # í˜„ì¬ ì‹œê°„ì— í•´ë‹¹í•˜ëŠ” ìë§‰ ì°¾ê¸°
            active_chunk = None
            for chunk in chunks:
                if chunk["start_ms"] <= current_time_ms <= chunk["end_ms"]:
                    active_chunk = chunk
                    break

            # ìë§‰ ë Œë”ë§
            if active_chunk:
                frame = self._render_subtitle(frame, active_chunk, current_time_ms)

            # ìƒë‹¨ íƒ€ì´í‹€ ë°” (í•­ìƒ ë…¸ì¶œ)
            title = script_data.get("title", "")
            if title:
                frame = self._render_title_bar(frame, title, alpha=0.9)

            # ì•„ì›ƒíŠ¸ë¡œ: ë§ˆì§€ë§‰ 2ì´ˆ êµ¬ë… ìœ ë„ CTA
            remaining_sec = (total_ms - current_time_ms) / 1000
            if remaining_sec <= 2.0 and remaining_sec >= 0:
                frame = self._render_cta_outro(frame, remaining_sec)

            # ì €ì¥
            frame_path = os.path.join(frames_dir, f"frame_{frame_idx:06d}.png")
            frame.save(frame_path, optimize=True)

            # ì§„í–‰ë¥ 
            if frame_idx % (self.config.fps * 5) == 0:
                pct = (frame_idx / total_frames) * 100
                print(f"  ğŸ“Š ë Œë”ë§ ì§„í–‰: {pct:.0f}%")

        print(f"  âœ… í”„ë ˆì„ ë Œë”ë§ ì™„ë£Œ!")

        # Step 4: FFmpegë¡œ PNG ì‹œí€€ìŠ¤ + ì˜¤ë””ì˜¤ â†’ MP4
        title_safe = re.sub(r'[^\wê°€-í£]', '_',
                            script_data.get("title", "shorts"))[:20]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = f"shorts_{title_safe}_{timestamp}.mp4"
        output_path = os.path.join(self.config.output_dir, output_filename)

        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (Windows FFmpeg í˜¸í™˜)
        abs_frames_pattern = os.path.abspath(
            os.path.join(frames_dir, "frame_%06d.png")
        )
        abs_audio = os.path.abspath(concat_audio)
        abs_output = os.path.abspath(output_path)

        # v3.1: 2-pass ì¸ì½”ë”© â€” ë¹„ë””ì˜¤ 2Mbps ë³´ì¥, AAC 256k@44100Hz
        # ì–´ë‘ìš´/ë‹¨ìˆœ ë°°ê²½ì—ì„œë„ ìµœì†Œ ë¹„íŠ¸ë ˆì´íŠ¸ ê°•ì œ
        print(f"  ğŸ”§ FFmpeg 2-pass ì¸ì½”ë”© ì¤‘...")

        # Pass 1 (ë¶„ì„ë§Œ, ì¶œë ¥ ì•ˆ í•¨)
        passlog = os.path.join(work_dir, "ffmpeg2pass")
        null_out = "NUL" if sys.platform == "win32" else "/dev/null"
        cmd_pass1 = [
            FFMPEG_PATH, "-y",
            "-framerate", str(self.config.fps),
            "-i", abs_frames_pattern,
            "-c:v", "libx264",
            "-preset", "fast",
            "-b:v", "2000k",
            "-maxrate", "5000k",
            "-bufsize", "4000k",
            "-pass", "1",
            "-passlogfile", passlog,
            "-pix_fmt", "yuv420p",
            "-an",
            "-f", "null", null_out,
        ]
        result1 = subprocess.run(cmd_pass1, capture_output=True, text=True, encoding="utf-8", errors="replace")

        # Pass 2 (ì‹¤ì œ ì¸ì½”ë”©)
        cmd_pass2 = [
            FFMPEG_PATH, "-y",
            "-framerate", str(self.config.fps),
            "-i", abs_frames_pattern,
            "-i", abs_audio,
            "-c:v", "libx264",
            "-preset", "fast",
            "-b:v", "2000k",
            "-maxrate", "5000k",
            "-bufsize", "4000k",
            "-pass", "2",
            "-passlogfile", passlog,
            "-c:a", "aac",
            "-b:a", "256k",          # ì˜¤ë””ì˜¤ 256kbps AAC
            "-ar", "44100",          # 44.1kHz ìƒ˜í”Œë ˆì´íŠ¸
            "-pix_fmt", "yuv420p",
            "-shortest",
            "-metadata", f"title={script_data.get('title', 'Shorts')}",
            abs_output,
        ]

        result = subprocess.run(cmd_pass2, capture_output=True, text=True, encoding="utf-8", errors="replace")

        # 2-pass ë¡œê·¸ ì •ë¦¬
        for ext in [".log", "-0.log", "-0.log.mbtree", ".log.mbtree"]:
            logf = passlog + ext
            if os.path.exists(logf):
                os.remove(logf)

        if result.returncode != 0:
            print(f"  âš ï¸  FFmpeg ì—ëŸ¬: {result.stderr[-500:] if result.stderr else 'unknown'}")
            print(f"  ğŸ”„ ê°„ì†Œí™” ë²„ì „ìœ¼ë¡œ ì¬ì‹œë„...")
            return self._assemble_simple_fallback(
                concat_audio, total_sec, chunks, output_path, work_dir
            )

        size_mb = os.path.getsize(output_path) / (1024 * 1024)
        print(f"  âœ… ì˜ìƒ ì™„ì„±! {output_path} ({size_mb:.1f}MB)")

        # í”„ë ˆì„ ì •ë¦¬ (ê³µê°„ ì ˆì•½)
        shutil.rmtree(frames_dir, ignore_errors=True)
        return output_path

    def _generate_ai_image(self, scene_hint: str, work_dir: str,
                            idx: int, context_text: str = "") -> Optional[str]:
        """
        v4.1: Imagen 4.0 ë§¥ë½ ê¸°ë°˜ AI ë°°ê²½ â€” scene_hintì˜ 'ìƒí™©+ë¶„ìœ„ê¸°' ì •ë°€ ë°˜ì˜
        context_text: í•´ë‹¹ ì¥ë©´ì˜ ëŒ€ë³¸ ë¬¸ì¥ (ë§¥ë½ ë³´ê°•ìš©)
        """
        api_key = self.config.google_api_key
        if not api_key:
            return None
        try:
            client = google_genai.Client(api_key=api_key)
            # ë§¥ë½ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸: scene_hintë¥¼ ìµœìš°ì„ , contextë¡œ ë³´ê°•
            prompt = (
                f"Abstract atmospheric background illustration for a Korean YouTube Shorts video. "
                f"Scene: {scene_hint}. "
                f"Style: dark cinematic color grading, soft depth-of-field blur, "
                f"moody dramatic lighting, vertical 9:16 composition, "
                f"NO text, NO faces, NO logos, NO UI elements. "
                f"Color palette: deep blues, muted oranges, atmospheric fog."
            )
            response = client.models.generate_images(
                model="imagen-4.0-generate-001",
                prompt=prompt,
                config=genai_types.GenerateImagesConfig(number_of_images=1),
            )
            for img in response.generated_images:
                path = os.path.join(work_dir, f"ai_bg_{idx:03d}.png")
                with open(path, "wb") as f:
                    f.write(img.image.image_bytes)
                print(f"    ğŸ¨ AI ë°°ê²½ ìƒì„±: {scene_hint[:40]}...")
                return path
        except Exception as e:
            print(f"    âš ï¸  AI ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

    def _prepare_backgrounds(self, screenshots: list[str],
                              total_frames: int,
                              script_data: dict = None,
                              work_dir: str = "") -> list[Image.Image]:
        """
        v4.1: 3ë‹¨ ë¹„ì£¼ì–¼ ë ˆì´ì•„ì›ƒ
        â”€ ë°°ê²½(í•˜ë‹¨): ìŠ¤í¬ë¦°ìƒ· 1.5ë°° í™•ëŒ€ + GaussianBlur(20px) â†’ ê¹Šì´ê°ë§Œ
        â”€ ì¤‘ì•™(ë©”ì¸): ìŠ¤í¬ë¦°ìƒ· ì„ ëª… ì›ë³¸ (ë¸”ëŸ¬ ì—†ìŒ) + ì™¸ê³½ì„  + ê·¸ë¦¼ì â†’ ë¦¬ì–¼ë¦¬í‹°
        â”€ ìƒë‹¨: íƒ€ì´í‹€ë°”ëŠ” í”„ë ˆì„ ë£¨í”„ì—ì„œ _render_title_bar()ê°€ ì²˜ë¦¬
        â”€ AI ë°°ê²½ì€ scene_hint ë§¥ë½ ì •ë°€ í”„ë¡¬í”„íŠ¸ë¡œ ìƒì„±
        """
        print(f"  ğŸ–¼ï¸  ë°°ê²½ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ (3ë‹¨ ë ˆì´ì•„ì›ƒ)...")
        backgrounds = []

        # â”€â”€ Imagen AI ë°°ê²½ (highlight ì¥ë©´, ìµœëŒ€ 3ì¥) â”€â”€
        ai_images = {}
        if script_data and self.config.use_ai_bg and work_dir:
            lines = script_data.get("script", [])
            ai_targets = []
            for i, line in enumerate(lines):
                if line.get("highlight") or line.get("emotion") in ("shock", "surprise"):
                    hint = line.get("scene_hint", "dramatic cinematic atmosphere")
                    ctx = line.get("text", "")
                    ai_targets.append((i, hint, ctx))
            ai_targets = ai_targets[:3]

            for target_idx, hint, ctx in ai_targets:
                ai_path = self._generate_ai_image(hint, work_dir, target_idx, ctx)
                if ai_path:
                    try:
                        ai_img = Image.open(ai_path).convert("RGB")
                        ai_img = self._fit_to_vertical(ai_img)
                        enhancer = ImageEnhance.Brightness(ai_img)
                        ai_img = enhancer.enhance(0.55)
                        ai_images[target_idx] = ai_img
                    except Exception:
                        pass

        # â”€â”€ 3ë‹¨ ë ˆì´ì•„ì›ƒ í•©ì„± â”€â”€
        if not screenshots:
            bg = self._create_gradient_bg(0)
            backgrounds.append(bg)
        else:
            for ss_path in screenshots:
                try:
                    orig = Image.open(ss_path).convert("RGB")
                    fitted = self._fit_to_vertical(orig)

                    # â–¼ ë°°ê²½ ë ˆì´ì–´: 1.5ë°° í™•ëŒ€ + GaussianBlur(20px) + ì–´ë‘¡ê²Œ
                    bg_w, bg_h = int(self.w * 1.5), int(self.h * 1.5)
                    bg_layer = fitted.resize((bg_w, bg_h), Image.LANCZOS)
                    left = (bg_w - self.w) // 2
                    top = (bg_h - self.h) // 2
                    bg_layer = bg_layer.crop((left, top, left + self.w, top + self.h))
                    bg_layer = bg_layer.filter(ImageFilter.GaussianBlur(radius=20))
                    enhancer = ImageEnhance.Brightness(bg_layer)
                    bg_layer = enhancer.enhance(0.30)

                    # â–¼ ì „ê²½ ë ˆì´ì–´: ì„ ëª…í•œ ì›ë³¸ (ë¸”ëŸ¬ ì—†ìŒ) + ì™¸ê³½ì„  + ê·¸ë¦¼ì
                    # ìƒë‹¨ íƒ€ì´í‹€ë°”(~60px) ì•„ë˜, ìë§‰ ì˜ì—­(h*0.60~) ìœ„ì— ë°°ì¹˜
                    fg_w = int(self.w * 0.88)
                    fg_h = int(fitted.height * (fg_w / fitted.width))
                    max_fg_h = int(self.h * 0.50)
                    if fg_h > max_fg_h:
                        fg_h = max_fg_h
                        fg_w = int(fitted.width * (fg_h / fitted.height))
                    fg = fitted.resize((fg_w, fg_h), Image.LANCZOS)

                    fg_x = (self.w - fg_w) // 2
                    fg_y = int(self.h * 0.08)  # íƒ€ì´í‹€ë°” ë°”ë¡œ ì•„ë˜

                    # ê·¸ë¦¼ì (8px offset + blur 15px)
                    shadow = Image.new("RGBA", (self.w, self.h), (0, 0, 0, 0))
                    shadow_draw = ImageDraw.Draw(shadow)
                    shadow_draw.rectangle(
                        [(fg_x + 6, fg_y + 6), (fg_x + fg_w + 6, fg_y + fg_h + 6)],
                        fill=(0, 0, 0, 140)
                    )
                    shadow = shadow.filter(ImageFilter.GaussianBlur(radius=15))

                    # í•©ì„±
                    composite = bg_layer.convert("RGBA")
                    composite = Image.alpha_composite(composite, shadow)

                    # í°ìƒ‰ ì™¸ê³½ì„  (4px)
                    border = 4
                    fg_draw = ImageDraw.Draw(composite)
                    fg_draw.rectangle(
                        [(fg_x - border, fg_y - border),
                         (fg_x + fg_w + border, fg_y + fg_h + border)],
                        fill=(255, 255, 255, 230)
                    )
                    # ì„ ëª…í•œ ì›ë³¸ ë¶™ì´ê¸° (ë¸”ëŸ¬ ì—†ìŒ)
                    composite.paste(fg, (fg_x, fg_y))

                    backgrounds.append(composite.convert("RGB"))
                except Exception as e:
                    print(f"    âš ï¸  ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    backgrounds.append(self._create_gradient_bg(len(backgrounds)))

        if not backgrounds:
            backgrounds = [self._create_gradient_bg(0)]

        # AI ì´ë¯¸ì§€ë¥¼ ë°°ê²½ ë¦¬ìŠ¤íŠ¸ì— ì‚½ì…
        if ai_images:
            total_bg = len(backgrounds)
            script_len = len(script_data.get("script", [])) if script_data else 1
            for line_idx, ai_bg in ai_images.items():
                bg_pos = min(int(line_idx / script_len * total_bg), total_bg - 1)
                if bg_pos < len(backgrounds):
                    backgrounds.insert(bg_pos + 1, ai_bg)
            print(f"    ğŸ¨ AI ë°°ê²½ {len(ai_images)}ì¥ ì‚½ì… ì™„ë£Œ")

        return backgrounds

    def _fit_to_vertical(self, img: Image.Image) -> Image.Image:
        """ì´ë¯¸ì§€ë¥¼ 1080x1920ì— ë§ê²Œ í¬ë¡­+ë¦¬ì‚¬ì´ì¦ˆ"""
        target_ratio = self.w / self.h  # 0.5625
        img_ratio = img.width / img.height

        if img_ratio > target_ratio:
            # ì´ë¯¸ì§€ê°€ ë” ë„“ìŒ â†’ ì¢Œìš° í¬ë¡­
            new_w = int(img.height * target_ratio)
            left = (img.width - new_w) // 2
            img = img.crop((left, 0, left + new_w, img.height))
        else:
            # ì´ë¯¸ì§€ê°€ ë” ë†’ìŒ â†’ ìƒí•˜ í¬ë¡­
            new_h = int(img.width / target_ratio)
            top = (img.height - new_h) // 2
            img = img.crop((0, top, img.width, top + new_h))

        return img.resize((self.w, self.h), Image.LANCZOS)

    def _create_gradient_bg(self, idx: int) -> Image.Image:
        """ê·¸ë¼ë°ì´ì…˜ í´ë°± ë°°ê²½"""
        img = Image.new("RGB", (self.w, self.h))
        draw = ImageDraw.Draw(img)
        gradients = [
            [(30, 25, 40), (50, 35, 25)],
            [(25, 35, 30), (40, 25, 40)],
            [(35, 30, 25), (25, 30, 45)],
        ]
        c1, c2 = gradients[idx % len(gradients)]
        for y in range(self.h):
            r = y / self.h
            color = tuple(int(c1[i] * (1-r) + c2[i] * r) for i in range(3))
            draw.line([(0, y), (self.w, y)], fill=color)
        return img

    def _render_title_bar(self, frame: Image.Image, title: str,
                           alpha: float = 1.0) -> Image.Image:
        """
        v4.1: ì„¸ë ¨ëœ ìƒë‹¨ íƒ€ì´í‹€ ë°”
        â”€ ë…¸ë€ìƒ‰ ì•…ì„¼íŠ¸ ë°•ìŠ¤ + í•µì‹¬ ì£¼ì œ ê³ ì • íƒ€ì´í‹€
        â”€ ì–´ë‘ìš´ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ìœ¼ë¡œ ì‹œì¸ì„± í™•ë³´
        """
        overlay = Image.new("RGBA", (self.w, self.h), (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)
        font = FontManager.get_font(30, bold=True)

        # íƒ€ì´í‹€ í…ìŠ¤íŠ¸ (ìµœëŒ€ 18ì)
        title_text = title[:18] + ("..." if len(title) > 18 else "")
        bbox = draw.textbbox((0, 0), title_text, font=font)
        tw, th = bbox[2] - bbox[0], bbox[3] - bbox[1]

        bar_h = th + 32
        a = int(220 * alpha)

        # ë°°ê²½: ê·¸ë¼ë°ì´ì…˜ (ìœ„ìª½ ë¶ˆíˆ¬ëª… â†’ ì•„ë˜ìª½ ë°˜íˆ¬ëª…)
        for y in range(bar_h + 10):
            fade = max(0, a - int(y * 1.5))
            draw.line([(0, y), (self.w, y)], fill=(10, 10, 10, fade))

        # ë…¸ë€ìƒ‰ ì•…ì„¼íŠ¸ ë¼ì¸ (ìƒë‹¨ 3px)
        draw.rectangle([(0, 0), (self.w, 3)], fill=(255, 220, 0, a))

        # í…ìŠ¤íŠ¸ ì¤‘ì•™ (Pillow stroke_width)
        tx = (self.w - tw) // 2
        ty = 8 + (bar_h - th) // 2
        draw.text((tx, ty), title_text, font=font,
                   fill=(255, 255, 255, int(250 * alpha)),
                   stroke_width=2,
                   stroke_fill=(0, 0, 0, int(200 * alpha)))

        frame = frame.convert("RGBA")
        return Image.alpha_composite(frame, overlay).convert("RGB")

    def _render_cta_outro(self, frame: Image.Image,
                           remaining_sec: float) -> Image.Image:
        """v4.0: ë§ˆì§€ë§‰ 2ì´ˆ êµ¬ë… ìœ ë„ CTA ì• ë‹ˆë©”ì´ì…˜"""
        overlay = Image.new("RGBA", (self.w, self.h), (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)

        # í˜ì´ë“œì¸ (0â†’1 over 0.3ì´ˆ)
        alpha = min(1.0, (2.0 - remaining_sec) / 0.3)

        # ë°˜íˆ¬ëª… ë°°ê²½
        draw.rectangle(
            [(0, int(self.h * 0.40)), (self.w, int(self.h * 0.60))],
            fill=(0, 0, 0, int(160 * alpha))
        )

        # "êµ¬ë…" ë²„íŠ¼ (ë¹¨ê°„ìƒ‰ ë‘¥ê·¼ ì‚¬ê°í˜•)
        btn_w, btn_h = 240, 70
        btn_x = (self.w - btn_w) // 2
        btn_y = int(self.h * 0.44)
        draw.rounded_rectangle(
            [(btn_x, btn_y), (btn_x + btn_w, btn_y + btn_h)],
            radius=12, fill=(255, 0, 0, int(230 * alpha))
        )

        # "êµ¬ë…" í…ìŠ¤íŠ¸
        font_btn = FontManager.get_font(32, bold=True)
        bbox = draw.textbbox((0, 0), "êµ¬ë…", font=font_btn)
        tw = bbox[2] - bbox[0]
        draw.text(
            (btn_x + (btn_w - tw) // 2, btn_y + 16),
            "êµ¬ë…", font=font_btn,
            fill=(255, 255, 255, int(255 * alpha))
        )

        # "ì¢‹ì•„ìš”ì™€ êµ¬ë… ë¶€íƒí•´ìš”!" í…ìŠ¤íŠ¸
        font_msg = FontManager.get_font(26, bold=False)
        msg = "ì¢‹ì•„ìš”ì™€ êµ¬ë… ë¶€íƒí•´ìš”!"
        bbox2 = draw.textbbox((0, 0), msg, font=font_msg)
        mw = bbox2[2] - bbox2[0]
        draw.text(
            ((self.w - mw) // 2, btn_y + btn_h + 15),
            msg, font=font_msg,
            fill=(255, 255, 0, int(220 * alpha))
        )

        frame = frame.convert("RGBA")
        return Image.alpha_composite(frame, overlay).convert("RGB")

    def _render_subtitle(self, frame: Image.Image, chunk: dict,
                          current_ms: float) -> Image.Image:
        """
        v4.1 High-Retention Captions â€” ë‹¨ì–´ë³„ í•˜ì´ë¼ì´íŠ¸ Pop
        â”€ ê¸°ë³¸: í°ìƒ‰ ê¸€ì + ê²€ì • 4px ì™¸ê³½ì„  â†’ ì–´ë–¤ ë°°ê²½ì—ì„œë„ ê°€ë…ì„± 1ìˆœìœ„
        â”€ ë™ì  í•˜ì´ë¼ì´íŠ¸: í˜„ì¬ ì½ê³  ìˆëŠ” ë‹¨ì–´ë§Œ ë…¸ë€ìƒ‰(#FFFF00) + ì‚´ì§ ì»¤ì§(Pop)
        â”€ ë“±ì¥: scale 0.7â†’1.0 (120ms ease-out), í‡´ì¥: fade-out (80ms)
        """
        text = chunk["text"]
        emotion = chunk.get("emotion", "neutral")
        highlight = chunk.get("highlight", False)
        start_ms = chunk["start_ms"]
        end_ms = chunk["end_ms"]

        # â”€â”€ ì• ë‹ˆë©”ì´ì…˜ ê³„ì‚° â”€â”€
        elapsed = current_ms - start_ms
        remaining = end_ms - current_ms
        duration = end_ms - start_ms
        fade_in_ms = 120
        fade_out_ms = 80

        alpha = 1.0
        if elapsed < fade_in_ms:
            alpha = elapsed / fade_in_ms
        elif remaining < fade_out_ms:
            alpha = remaining / fade_out_ms
        alpha = max(0.0, min(1.0, alpha))

        # ë“±ì¥ ìŠ¤ì¼€ì¼
        scale = 1.0
        if elapsed < fade_in_ms:
            t = elapsed / fade_in_ms
            scale = 0.7 + 0.3 * (1 - (1 - t) ** 3)

        # â”€â”€ í°íŠ¸ (Bold, í°ìƒ‰ ê¸°ë³¸) â”€â”€
        fs = int(self.config.font_size * scale)
        font = FontManager.get_font(max(24, fs), bold=True)
        font_pop = FontManager.get_font(max(24, int(fs * 1.15)), bold=True)

        # â”€â”€ ë‹¨ì–´ ë¶„í•  + í˜„ì¬ ì½ëŠ” ë‹¨ì–´ ê³„ì‚° â”€â”€
        words = text.split() if " " in text else list(text)
        # í•œê¸€ì€ ê³µë°±ì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, 2~4ê¸€ì ë‹¨ìœ„ë¡œ ë¶„í• 
        if len(words) == 1 and len(text) > 4:
            # í•œê¸€ í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„í• 
            words = []
            chunk_size = max(2, len(text) // max(2, len(text) // 3))
            for j in range(0, len(text), chunk_size):
                words.append(text[j:j + chunk_size])

        n_words = len(words)
        progress = max(0.0, min(1.0, elapsed / max(1, duration)))
        active_word_idx = min(int(progress * n_words), n_words - 1)

        # â”€â”€ ì¤„ë°”ê¿ˆ (ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ì¤€) â”€â”€
        full_text = " ".join(words) if " " in text else "".join(words)
        max_chars = 15
        if len(full_text) > max_chars:
            mid = len(full_text) // 2
            best_break = mid
            for offset in range(min(6, mid)):
                for pos in [mid + offset, mid - offset]:
                    if 0 < pos < len(full_text) and full_text[pos] in " .,!?ì€ëŠ”ì´ê°€ì„ë¥¼ì—ì„œë„ë¡œì˜":
                        best_break = pos + 1
                        break
                else:
                    continue
                break
            lines = [full_text[:best_break].strip(), full_text[best_break:].strip()]
        else:
            lines = [full_text]

        # â”€â”€ ì¸¡ì • (ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ì¤€) â”€â”€
        draw_temp = ImageDraw.Draw(frame)
        line_heights, line_widths = [], []
        for line in lines:
            bbox = draw_temp.textbbox((0, 0), line, font=font)
            line_widths.append(bbox[2] - bbox[0])
            line_heights.append(bbox[3] - bbox[1])

        max_line_w = max(line_widths) if line_widths else 100
        total_text_h = sum(line_heights) + (len(lines) - 1) * 12
        padding_x, padding_y = 44, 28
        box_w = max_line_w + padding_x * 2
        box_h = total_text_h + padding_y * 2

        box_x = (self.w - box_w) // 2
        box_y = int(self.h * 0.65)

        # â”€â”€ ì˜¤ë²„ë ˆì´ â”€â”€
        overlay = Image.new("RGBA", (self.w, self.h), (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)

        # ë°°ê²½ ë°•ìŠ¤ (ì–´ë‘ìš´ ë°˜íˆ¬ëª…)
        bg_a = int(min(230, 200) * alpha)
        draw.rounded_rectangle(
            [(box_x, box_y), (box_x + box_w, box_y + box_h)],
            radius=16, fill=(15, 15, 15, bg_a),
        )

        # â”€â”€ ë‹¨ì–´ë³„ ë Œë”ë§ (ì™¸ê³½ì„  4px + ê·¸ë¦¼ì + ë©”ì¸) â”€â”€
        text_y = box_y + padding_y
        word_global_idx = 0

        for i, line in enumerate(lines):
            line_w = line_widths[i]
            line_x = box_x + (box_w - line_w) // 2

            # ì´ ì¤„ì˜ ë‹¨ì–´ë“¤ì„ ì¶”ì í•˜ë©° ê°œë³„ ë Œë”ë§
            cursor_x = line_x
            # ì¤„ ë‚´ ë¬¸ìë¥¼ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë§¤ì¹­
            remaining_line = line
            while remaining_line and word_global_idx < n_words:
                word = words[word_global_idx]
                # ì¤„ì—ì„œ ì´ ë‹¨ì–´ì˜ ìœ„ì¹˜ í™•ì¸
                pos = remaining_line.find(word)
                if pos < 0:
                    break

                # ë‹¨ì–´ ì•ì˜ ê³µë°±/ë¬¸ì ë Œë”ë§ (ì¼ë°˜)
                prefix = remaining_line[:pos]
                if prefix:
                    p_bbox = draw.textbbox((0, 0), prefix, font=font)
                    p_w = p_bbox[2] - p_bbox[0]
                    self._draw_text_with_stroke(
                        draw, cursor_x, text_y, prefix, font,
                        (255, 255, 255), alpha, stroke_px=4
                    )
                    cursor_x += p_w

                # í˜„ì¬ ì½ê³  ìˆëŠ” ë‹¨ì–´ íŒë³„
                is_active = (word_global_idx == active_word_idx)

                if is_active and highlight:
                    # â˜… í™œì„± ë‹¨ì–´ + highlight: ë…¸ë€ìƒ‰ Pop
                    pop_scale = 1.0 + 0.08 * math.sin(
                        min(1.0, (elapsed % 500) / 250) * math.pi
                    )
                    w_font = FontManager.get_font(
                        max(24, int(fs * 1.15 * pop_scale)), bold=True
                    )
                    self._draw_text_with_stroke(
                        draw, cursor_x, text_y - 2, word, w_font,
                        (255, 255, 0), alpha, stroke_px=4
                    )
                    w_bbox = draw.textbbox((0, 0), word, font=w_font)
                elif is_active:
                    # â˜… í™œì„± ë‹¨ì–´ (non-highlight): ë…¸ë€ìƒ‰
                    self._draw_text_with_stroke(
                        draw, cursor_x, text_y, word, font,
                        (255, 255, 0), alpha, stroke_px=4
                    )
                    w_bbox = draw.textbbox((0, 0), word, font=font)
                else:
                    # ì¼ë°˜ ë‹¨ì–´: í°ìƒ‰
                    self._draw_text_with_stroke(
                        draw, cursor_x, text_y, word, font,
                        (255, 255, 255), alpha, stroke_px=4
                    )
                    w_bbox = draw.textbbox((0, 0), word, font=font)

                w_w = w_bbox[2] - w_bbox[0]
                cursor_x += w_w
                remaining_line = remaining_line[pos + len(word):]
                word_global_idx += 1

            # ë‚¨ì€ ë¬¸ìê°€ ìˆìœ¼ë©´ ë Œë”ë§
            if remaining_line.strip():
                self._draw_text_with_stroke(
                    draw, cursor_x, text_y, remaining_line, font,
                    (255, 255, 255), alpha, stroke_px=4
                )

            text_y += line_heights[i] + 12

        frame = frame.convert("RGBA")
        frame = Image.alpha_composite(frame, overlay)
        return frame.convert("RGB")

    def _draw_text_with_stroke(self, draw: ImageDraw.Draw,
                                x: int, y: int, text: str,
                                font: ImageFont.FreeTypeFont,
                                color: tuple, alpha: float,
                                stroke_px: int = 4):
        """v4.2: Pillow ë‚´ì¥ stroke_width ì‚¬ìš© â†’ 49ë£¨í”„â†’1ì½œ (20ë°° ê°€ì†)"""
        a = int(255 * alpha)
        stroke_a = int(230 * alpha)
        shadow_a = int(140 * alpha)

        # 1) ê·¸ë¦¼ì (5px offset)
        draw.text((x + 5, y + 5), text, font=font,
                   fill=(0, 0, 0, shadow_a))

        # 2) ì™¸ê³½ì„  + ë©”ì¸ í…ìŠ¤íŠ¸ (Pillow built-in stroke_width)
        draw.text((x, y), text, font=font,
                   fill=(*color, a),
                   stroke_width=stroke_px,
                   stroke_fill=(0, 0, 0, stroke_a))

    def _concat_audio(self, chunks: list[dict], output: str, work_dir: str):
        """
        v4.1: Voice EQ + BGM + Sidechain Ducking -20dB
        â”€ ê³µë°±: 0.08ì´ˆ (80ms) â†’ ì‰´ í‹ˆ ì—†ëŠ” í…ì…˜
        â”€ Ducking: ratio=20 + threshold=0.008 â†’ ë³´ì´ìŠ¤ ìˆì„ ë•Œ BGM -20dB
        """
        concat_list = os.path.join(work_dir, "concat_list.txt")

        # v4.2: ë¬¸ì¥ë³„ ê°œë³„ TTS â†’ ìˆœì„œëŒ€ë¡œ concat
        # ê° ë¬¸ì¥ ì‚¬ì´ì— 80ms + pause_ms ë¬´ìŒ ì‚½ì…

        # â”€â”€ Step 1: ë³´ì´ìŠ¤ concat (80ms ê¸°ë³¸ + pause_ms ì¶”ê°€) â”€â”€
        with open(concat_list, "w", encoding="utf-8") as f:
            for i, chunk in enumerate(chunks):
                if i > 0:
                    # ê¸°ë³¸ 80ms + ìŠ¤í¬ë¦½íŠ¸ ì§€ì • pause_ms
                    pause_sec = 0.08 + chunk.get("pause_ms", 0) / 1000
                    pause_file = os.path.join(work_dir, f"pause_{i:03d}.mp3")
                    subprocess.run([
                        FFMPEG_PATH, "-y", "-f", "lavfi",
                        "-i", "anullsrc=r=44100:cl=mono",
                        "-t", f"{pause_sec:.3f}",
                        "-c:a", "libmp3lame", "-b:a", "128k",
                        "-ar", "44100", pause_file
                    ], capture_output=True)
                    abs_pause = os.path.abspath(pause_file).replace("\\", "/")
                    f.write(f"file '{abs_pause}'\n")
                abs_audio = os.path.abspath(chunk['audio_file']).replace("\\", "/")
                f.write(f"file '{abs_audio}'\n")

        raw_voice = os.path.join(work_dir, "voice_raw.mp3")
        result = subprocess.run([
            FFMPEG_PATH, "-y", "-f", "concat", "-safe", "0",
            "-i", concat_list,
            "-c:a", "libmp3lame", "-b:a", "128k", "-ar", "44100",
            raw_voice
        ], capture_output=True, text=True, encoding="utf-8", errors="replace")
        if result.returncode != 0:
            print(f"  âš ï¸  ì˜¤ë””ì˜¤ concat ì‹¤íŒ¨: {result.stderr[-300:] if result.stderr else ''}")
            # í´ë°±: ì²« ë²ˆì§¸ ì˜¤ë””ì˜¤ íŒŒì¼ì´ë¼ë„ ì‚¬ìš©
            if os.path.exists(raw_voice):
                shutil.move(raw_voice, output)
            elif chunks and os.path.exists(chunks[0].get("audio_file", "")):
                shutil.copy2(chunks[0]["audio_file"], output)
            return

        # â”€â”€ Step 2: Voice ë§ˆìŠ¤í„°ë§ (ê°•í™” EQ + compressor) â”€â”€
        print(f"  ğŸ›ï¸  Voice ë§ˆìŠ¤í„°ë§...")
        mastered_voice = os.path.join(work_dir, "voice_mastered.mp3")
        voice_filter = (
            "acompressor=threshold=-18dB:ratio=4:attack=5:release=50,"
            "equalizer=f=200:t=q:w=1:g=3,"
            "equalizer=f=3000:t=q:w=0.8:g=2,"
            "equalizer=f=5000:t=q:w=1:g=1,"
            "loudnorm=I=-14:TP=-1:LRA=9"
        )
        r = subprocess.run([
            FFMPEG_PATH, "-y", "-i", raw_voice,
            "-af", voice_filter,
            "-c:a", "libmp3lame", "-b:a", "192k", "-ar", "44100",
            mastered_voice
        ], capture_output=True, text=True, encoding="utf-8", errors="replace")
        if r.returncode != 0:
            print(f"  âš ï¸  Voice ë§ˆìŠ¤í„°ë§ ì‹¤íŒ¨, raw ì‚¬ìš©")
            mastered_voice = raw_voice

        # â”€â”€ Step 3: BGM ìƒì„± + Sidechain Ducking (-20dB) â”€â”€
        if self.config.bgm_enabled:
            print(f"  ğŸµ ì•°ë¹„ì–¸íŠ¸ ë“œë¡  BGM + Sidechain Ducking (-20dB)...")
            total_sec = max(c["end_ms"] for c in chunks) / 1000 + 1
            bgm_file = os.path.join(work_dir, "bgm.mp3")
            # v4.2: ì‚¬ì¸íŒŒ ì•°ë¹„ì–¸íŠ¸ ë“œë¡  (220Hz+330Hz+440Hz)
            # í•‘í¬ë…¸ì´ì¦ˆ ëŒ€ì‹  ë”°ëœ»í•œ ë“œë¡  â†’ ëª°ì…ê° + ì§‘ì¤‘ë„ UP
            drone_src = (
                f"sine=f=220:r=44100:d={total_sec:.1f},"
                f"volume=0.03[s1];"
                f"sine=f=330:r=44100:d={total_sec:.1f},"
                f"volume=0.02[s2];"
                f"sine=f=440:r=44100:d={total_sec:.1f},"
                f"volume=0.015[s3];"
                f"[s1][s2][s3]amix=inputs=3:duration=shortest,"
                f"lowpass=f=500,"
                f"afade=t=in:st=0:d=1.5,"
                f"afade=t=out:st={max(0, total_sec - 2):.1f}:d=2,"
                f"volume=0.4"
            )
            subprocess.run([
                FFMPEG_PATH, "-y", "-f", "lavfi",
                "-i", drone_src,
                "-c:a", "libmp3lame", "-b:a", "64k", "-ar", "44100",
                bgm_file
            ], capture_output=True)

            ducked_output = os.path.join(work_dir, "final_mix.mp3")
            abs_voice = os.path.abspath(mastered_voice)
            abs_bgm = os.path.abspath(bgm_file)

            # Sidechain: threshold=0.008 ratio=20 â†’ voiceì‹œ BGM -20dB
            duck_filter = (
                "[1:a]acompressor=threshold=0.008:ratio=20:attack=20:release=300"
                ":detection=peak:link=average:level_sc=1[bgm_ducked];"
                "[0:a][bgm_ducked]amix=inputs=2:weights=1 0.25:duration=shortest"
            )
            r2 = subprocess.run([
                FFMPEG_PATH, "-y",
                "-i", abs_voice,
                "-i", abs_bgm,
                "-filter_complex", duck_filter,
                "-c:a", "libmp3lame", "-b:a", "192k", "-ar", "44100",
                ducked_output
            ], capture_output=True, text=True, encoding="utf-8", errors="replace")

            if r2.returncode == 0:
                shutil.move(ducked_output, output)
                print(f"  âœ… BGM + Sidechain Ducking (-20dB) ì™„ë£Œ")
            else:
                print(f"  âš ï¸  Ducking ì‹¤íŒ¨, voiceë§Œ ì‚¬ìš©")
                shutil.move(mastered_voice, output)
        else:
            shutil.move(mastered_voice, output)
            print(f"  âœ… Voice ë§ˆìŠ¤í„°ë§ ì™„ë£Œ (BGM ì—†ìŒ)")

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for tmp in [raw_voice, mastered_voice,
                     os.path.join(work_dir, "bgm.mp3"),
                     os.path.join(work_dir, "final_mix.mp3")]:
            if os.path.exists(tmp) and tmp != output:
                try:
                    os.remove(tmp)
                except OSError:
                    pass

    def _assemble_simple_fallback(self, audio: str, duration: float,
                                   chunks: list, output: str,
                                   work_dir: str) -> str:
        """í”„ë ˆì„ ë Œë”ë§ ì‹¤íŒ¨ ì‹œ ASS ìë§‰ í´ë°±"""
        print(f"  ğŸ”„ ASS ìë§‰ í´ë°± ëª¨ë“œ...")
        ass_file = os.path.join(work_dir, "subs.ass")
        self._generate_ass_fallback(chunks, ass_file)

        # ASS íŒŒì¼ ê²½ë¡œì—ì„œ Windows ë°±ìŠ¬ë˜ì‹œë¥¼ ì´ìŠ¤ì¼€ì´í”„
        ass_escaped = ass_file.replace("\\", "/").replace(":", "\\\\:")
        cmd = [
            FFMPEG_PATH, "-y",
            "-f", "lavfi",
            "-i", f"color=c=0x1a1a1a:s={self.w}x{self.h}:d={duration:.2f}:r={self.config.fps}",
            "-i", audio,
            "-vf", f"ass={ass_escaped}",
            "-c:v", "libx264", "-preset", "fast",
            "-b:v", "2000k", "-minrate", "1500k", "-maxrate", "5000k", "-bufsize", "4000k",
            "-c:a", "aac", "-b:a", "256k", "-ar", "44100",
            "-shortest", "-pix_fmt", "yuv420p",
            output,
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, encoding="utf-8", errors="replace")
        if result.returncode != 0:
            print(f"  âš ï¸  ASS í´ë°±ë„ ì‹¤íŒ¨, ìë§‰ ì—†ì´ ì¬ì‹œë„...")
            cmd_simple = [
                FFMPEG_PATH, "-y",
                "-f", "lavfi",
                "-i", f"color=c=0x1a1a1a:s={self.w}x{self.h}:d={duration:.2f}:r={self.config.fps}",
                "-i", audio,
                "-c:v", "libx264", "-preset", "fast",
                "-b:v", "2000k", "-minrate", "1500k", "-maxrate", "5000k", "-bufsize", "4000k",
                "-c:a", "aac", "-b:a", "256k", "-ar", "44100",
                "-shortest", "-pix_fmt", "yuv420p",
                output,
            ]
            subprocess.run(cmd_simple, capture_output=True)
        return output

    def _generate_ass_fallback(self, chunks: list, output: str):
        """ASS ìë§‰ í´ë°± ìƒì„±"""
        ass = f"""[Script Info]
Title: Shorts
ScriptType: v4.00+
PlayResX: {self.w}
PlayResY: {self.h}

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,NanumSquareRound,58,&H00FFFFFF,&H000000FF,&H00000000,&HC0000000,-1,0,0,0,100,100,0,0,1,3,2,2,60,60,400,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""
        for c in chunks:
            s = self._ms_to_ass(c["start_ms"])
            e = self._ms_to_ass(c["end_ms"])
            ass += f"Dialogue: 0,{s},{e},Default,,0,0,0,,{c['text']}\n"

        with open(output, "w", encoding="utf-8") as f:
            f.write(ass)

    @staticmethod
    def _ms_to_ass(ms: int) -> str:
        t = ms / 1000
        h = int(t // 3600)
        m = int((t % 3600) // 60)
        s = int(t % 60)
        cs = int((t % 1) * 100)
        return f"{h}:{m:02d}:{s:02d}.{cs:02d}"


# ============================================================
# ğŸ­ ë©”ì¸ íŒŒì´í”„ë¼ì¸
# ============================================================
class ShortsFactory:
    def __init__(self, config: Config):
        self.config = config
        self.scraper = CommunityScraper(config)
        self.scriptgen = ScriptGenerator(config)
        self.tts = TTSEngine(config)
        self.assembler = VideoAssembler(config)

    async def run(self) -> list[str]:
        start_time = time.time()
        output_files = []

        print("\n" + "ğŸ¬" * 30)
        print("  YouTube Shorts íŒ©í† ë¦¬ v5.0 'The Viral Machine'")
        print("  ğŸŒ ë©€í‹°í”Œë«í¼ + ğŸ”¥ ë°”ì´ëŸ´ í”„ë¡¬í”„íŠ¸ + ğŸµ ë“œë¡  BGM + âš¡ ë°”ì´ëŸ´ ê°€ì‚°ì  ì •ë ¬")
        print("ğŸ¬" * 30)

        # Stage 1: í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ·
        if self.config.skip_crawl and self.config.manual_topic:
            posts = [{
                "title": self.config.manual_topic,
                "content": self.config.manual_topic,
                "source": "manual",
                "screenshots": [],
            }]
        else:
            posts = self.scraper.scrape_with_screenshots()

        if not posts:
            print("âŒ í¬ë¡¤ë§ ê²°ê³¼ ì—†ìŒ!")
            return []

        # ê° ê¸€ë§ˆë‹¤ ì˜ìƒ ìƒì„±
        for idx, post in enumerate(posts):
            print(f"\n{'ğŸ¬'*20}")
            print(f"  [{idx+1}/{len(posts)}] {post['title'][:40]}")
            print(f"{'ğŸ¬'*20}")

            work_dir = os.path.join(
                self.config.output_dir,
                f"_work_{idx}_{datetime.now().strftime('%H%M%S')}"
            )
            os.makedirs(work_dir, exist_ok=True)

            try:
                # Stage 2: ëŒ€ë³¸
                if self.config.skip_crawl and self.config.manual_topic:
                    script_data = self.scriptgen.generate_from_topic(
                        self.config.manual_topic
                    )
                else:
                    script_data = self.scriptgen.generate(post)

                if script_data is None:
                    print(f"  â­ï¸  ì†ŒìŠ¤ í’ˆì§ˆ ë¶€ì¡±, ê±´ë„ˆëœ€")
                    continue

                # ëŒ€ë³¸ ì €ì¥
                with open(os.path.join(work_dir, "script.json"), "w",
                          encoding="utf-8") as f:
                    json.dump(script_data, f, ensure_ascii=False, indent=2)

                # ìŠ¤í¬ë¦°ìƒ· ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ìƒì„±
                screenshots = post.get("screenshots", [])
                if not screenshots:
                    screenshots = self.scraper._generate_text_screenshots(post)

                # Stage 3: TTS
                chunks = await self.tts.generate(script_data, work_dir)
                if not chunks:
                    print("  âš ï¸  TTS ì‹¤íŒ¨, ê±´ë„ˆëœ€")
                    continue

                # Stage 4: ì˜ìƒ ì¡°ë¦½
                output_path = self.assembler.assemble(
                    script_data, chunks, screenshots, work_dir
                )
                output_files.append(output_path)

                # ë©”íƒ€ ì €ì¥
                duration_sec = max(c["end_ms"] for c in chunks) / 1000
                meta = {
                    "video": output_path,
                    "script": script_data,
                    "chunks": len(chunks),
                    "duration_sec": duration_sec,
                    "screenshots": screenshots,
                    "created": datetime.now().isoformat(),
                }
                with open(output_path.replace(".mp4", "_meta.json"), "w",
                          encoding="utf-8") as f:
                    json.dump(meta, f, ensure_ascii=False, indent=2)

                # v4.0: upload_info.json (ì—…ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ)
                upload_info = {
                    "title": script_data.get("title", "ìˆì¸ "),
                    "description": script_data.get("description",
                        f"{script_data.get('title', '')} #ìˆì¸  #ì° #ë ˆì „ë“œ"),
                    "tags": [t.replace("#", "") for t in
                             script_data.get("tags", ["ìˆì¸ ", "ì°", "ë ˆì „ë“œ"])],
                    "thumbnail_text": script_data.get("thumbnail_text", ""),
                    "category": "22",  # People & Blogs
                    "privacy": "public",
                    "shorts": True,
                    "duration_sec": round(duration_sec, 1),
                    "video_file": os.path.basename(output_path),
                    "created": datetime.now().isoformat(),
                }
                upload_path = output_path.replace(".mp4", "_upload_info.json")
                with open(upload_path, "w", encoding="utf-8") as f:
                    json.dump(upload_info, f, ensure_ascii=False, indent=2)
                print(f"  ğŸ“‹ upload_info.json ìƒì„± ì™„ë£Œ")

            except Exception as e:
                print(f"  âŒ ì—ëŸ¬: {e}")
                import traceback
                traceback.print_exc()

        # ë¦¬í¬íŠ¸
        elapsed = time.time() - start_time
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ìµœì¢… ë¦¬í¬íŠ¸")
        print(f"{'='*60}")
        print(f"  â±ï¸  ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ")
        print(f"  ğŸ¬ ìƒì„± ì˜ìƒ: {len(output_files)}ê°œ")
        for f in output_files:
            if os.path.exists(f):
                sz = os.path.getsize(f) / (1024*1024)
                print(f"     ğŸ“ {f} ({sz:.1f}MB)")
            else:
                print(f"     âš ï¸  {f} (íŒŒì¼ ë¯¸ìƒì„±)")
        print(f"{'='*60}\n")

        return output_files


# ============================================================
# ğŸš€ CLI
# ============================================================
def parse_args():
    p = argparse.ArgumentParser(
        description="ğŸ¬ YouTube Shorts íŒ©í† ë¦¬ v5.0 'The Viral Machine'",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python main.py --source dcinside --gallery humor --count 3
  python main.py --source natepann --count 5
  python main.py --url "https://gall.dcinside.com/board/view/..."
  python main.py --topic "ìƒê²¬ë¡€ íŒŒí†  ì°" --skip-crawl
  python main.py --source natepann --voice ko-KR-InJoonNeural

í™˜ê²½ë³€ìˆ˜:
  ANTHROPIC_API_KEY   Claude API í‚¤ (í•„ìˆ˜)
  APIFY_API_TOKEN     Apify API í† í° (ì„ íƒ)
        """
    )

    src = p.add_argument_group("ğŸ“¡ í¬ë¡¤ë§")
    src.add_argument("--source",
                     choices=["natepann", "dcinside",
                              "dcinside_realtime_best", "dcinside_hit",
                              "fmkorea", "ruliweb", "instiz", "theqoo"],
                     default="dcinside_realtime_best")
    src.add_argument("--gallery", default="humor")
    src.add_argument("--count", type=int, default=3)
    src.add_argument("--url", default="")

    scr = p.add_argument_group("ğŸ“ ëŒ€ë³¸")
    scr.add_argument("--topic", default="")
    scr.add_argument("--skip-crawl", action="store_true")

    tts = p.add_argument_group("ğŸ”Š TTS")
    tts.add_argument("--voice", default="ko-KR-HyunsuNeural")
    tts.add_argument("--rate", default="+5%")
    tts.add_argument("--pitch", default="-1Hz")

    out = p.add_argument_group("ğŸ“ ì¶œë ¥")
    out.add_argument("--output", default="./output")
    out.add_argument("--quality", type=int, default=80)

    return p.parse_args()


async def main():
    args = parse_args()

    config = Config(
        source=args.source,
        gallery=args.gallery,
        crawl_count=args.count,
        target_url=args.url,
        manual_topic=args.topic,
        skip_crawl=args.skip_crawl or bool(args.topic),
        tts_voice=args.voice,
        tts_rate=args.rate,
        tts_pitch=args.pitch,
        quality=args.quality,
        output_dir=args.output,
    )

    if not config.claude_api_key:
        print("âŒ ANTHROPIC_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”!")
        print("   export ANTHROPIC_API_KEY='sk-ant-...'")
        sys.exit(1)

    if not config.apify_api_token:
        print("âš ï¸  APIFY_API_TOKEN ë¯¸ì„¤ì • â†’ í´ë°± í¬ë¡¤ë§")

    factory = ShortsFactory(config)
    results = await factory.run()

    if results:
        print("ğŸ‰ ì™„ë£Œ!")
    else:
        print("ğŸ˜¢ ìƒì„±ëœ ì˜ìƒ ì—†ìŒ")


if __name__ == "__main__":
    asyncio.run(main())
