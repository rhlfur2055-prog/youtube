#!/usr/bin/env python3
"""
=============================================================
ğŸ¬ YouTube Shorts íŒ©í† ë¦¬ v5.0 'The Viral Machine'
=============================================================
v4.3 â†’ v5.0 ë³€ê²½ì‚¬í•­:
  âœ… ë©€í‹°í”Œë«í¼ í¬ë¡¤ëŸ¬ (ì—í¨ì½”ë¦¬ì•„/ë£¨ë¦¬ì›¹/ì¸ìŠ¤í‹°ì¦ˆ/ë”ì¿ /ë„¤ì´íŠ¸íŒ)
  âœ… í”Œë«í¼ ìë™ ê°ì§€ ë³¸ë¬¸ ì¶”ì¶œ (_fetch_article_by_platform)
  âœ… ê° í”Œë«í¼ë³„ ëŒ“ê¸€ ì¶”ì¶œ
  âœ… requests ìš°ì„  â†’ Apify í´ë°± (ì „ í”Œë«í¼ í†µì¼)
v4.2 â†’ v4.3 ë³€ê²½ì‚¬í•­:
  âœ… ë°”ì´ëŸ´ ì „ë¬¸ í”„ë¡¬í”„íŠ¸ ì ìš© (ì™œ ë² ìŠ¤íŠ¸ì¸ì§€ ë¶„ì„ â†’ ëŒ€ë³¸)
  âœ… ê°ì • íƒœê·¸ í™•ì¥ (excited/shocked/warm/whisper/funny ë“±)
  âœ… ë°”ì´ëŸ´ ê°€ì‚°ì  URL ì •ë ¬ (ã…‹ã…‹/ë ˆì „ë“œ/ì†Œë¦„/ì‹¤í™”/ëŒ€ë°• ìš°ì„ )
  âœ… pause_ms ë²”ìœ„ í™•ëŒ€ (ë°˜ì „ 800~1200ms, í‰ì†Œ 200~400ms)
  âœ… viral_reason í•„ë“œ ì¶”ê°€ (ì™œ ë² ìŠ¤íŠ¸ì¸ì§€ í•œì¤„)
v4.1 â†’ v4.2 ë³€ê²½ì‚¬í•­:
  âœ… í¬ë¡¤ëŸ¬ 2ë‹¨ê³„ ë¶„ë¦¬ (ëª©ë¡â†’ê°œë³„ URL) + UI í‚¤ì›Œë“œ í•„í„°ë§
  âœ… ëŒ€ë³¸ ì†ŒìŠ¤ í’ˆì§ˆ ê²€ì¦ (200ì ë¯¸ë§Œ/ìŠ¤íŒ¸ â†’ None)
  âœ… TTS ë¬¸ì¥ë³„ ê°œë³„ ìƒì„± (ì™„ë²½ ìŒì„±-ìë§‰ ì‹±í¬)
  âœ… Pillow stroke_width ë‚´ì¥ ì‚¬ìš© (ë Œë”ë§ 20ë°° ê°€ì†)
  âœ… ì‚¬ì¸íŒŒ ì•°ë¹„ì–¸íŠ¸ ë“œë¡  BGM (í•‘í¬ë…¸ì´ì¦ˆ â†’ 220+330+440Hz)
  âœ… ë””ì‹œ ì‹¤ì‹œê°„ë² ìŠ¤íŠ¸/ê°œë…ê¸€ ì†ŒìŠ¤ ì¶”ê°€
v4.0 â†’ v4.1 ë³€ê²½ì‚¬í•­:
  âœ… 3ë‹¨ ë¹„ì£¼ì–¼ ë ˆì´ì•„ì›ƒ (ë¸”ëŸ¬ë°°ê²½ + ì„ ëª…ìŠ¤í¬ë¦°ìƒ· + íƒ€ì´í‹€ë°”)
  âœ… ë¶„ìœ„ê¸°ë³„ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ (Pillow, ë¬´ë£Œ)
  âœ… ë‹¨ì–´ë³„ í•˜ì´ë¼ì´íŠ¸ Pop + 4px ì™¸ê³½ì„  + 5px ê·¸ë¦¼ì
  âœ… Sidechain Ducking -20dB + ê³µë°± 80ms
  âœ… Ken Burns + Dynamic Blur + Voice ë§ˆìŠ¤í„°ë§
  âœ… 3ì´ˆ í›„í‚¹ ëŒ€ë³¸ + êµ¬ë… ìœ ë„ CTA ì—”ë”©
  âœ… upload_info.json ìë™ ìƒì„±

íŒŒì´í”„ë¼ì¸:
  [ë°”ì´ëŸ´ ì†ŒìŠ¤] YouTube Trending + Google Trends + HN + Wikipedia (ë¬´ë£Œ)
      â†“  (í´ë°±: ì»¤ë®¤ë‹ˆí‹° í¬ë¡¤ë§ Apify/requests)
  [ëŒ€ë³¸ìƒì„±] Gemini 2.0 Flash â†’ 100ë§Œë·° í›„í‚¹ ëŒ€ë³¸ + SEO íƒœê·¸ (ë¬´ë£Œ)
      â†“
  [TTS+ìë§‰] edge-tts â†’ ê°ì •ë³„ prosody + WordBoundary íƒ€ì´ë°
      â†“
  [ë°°ê²½ìƒì„±] Pillow ê·¸ë¼ë°ì´ì…˜ â†’ ë¶„ìœ„ê¸°ë³„ ë°°ê²½ ì´ë¯¸ì§€ (ë¬´ë£Œ)
      â†“
  [ì˜ìƒì¡°ë¦½] FFmpeg â†’ Dynamic Blur + Ken Burns + ìë§‰ + BGM Ducking
      â†“
  [ì¶œë ¥] shorts_ì œëª©_ë‚ ì§œ.mp4 + upload_info.json

ì‚¬ìš©ë²•:
  python main.py                                       # ë°”ì´ëŸ´ ì†ŒìŠ¤ (ê¸°ë³¸ê°’)
  python main.py --source viral --count 5              # ë°”ì´ëŸ´ ì†ŒìŠ¤ 5ê°œ
  python main.py --source dcinside_realtime_best --count 1
  python main.py --source fmkorea --count 3
  python main.py --source natepann --count 5
  python main.py --url "https://gall.dcinside.com/..."
  python main.py --topic "ìƒê²¬ë¡€ íŒŒí† " --skip-crawl
=============================================================
"""

import argparse
import asyncio
import io
import json
import os
import re
import subprocess
import sys
import time
import math
import textwrap
import shutil
import random
from datetime import datetime
from pathlib import Path
from dataclasses import dataclass
from typing import Optional

# Windows cp949 ì½˜ì†”ì—ì„œ ì´ëª¨ì§€/í•œê¸€ ì¶œë ¥ ê¹¨ì§ ë°©ì§€
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding="utf-8", errors="replace")

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    _env_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), ".env")
    if os.path.exists(_env_path):
        load_dotenv(_env_path, override=True)
except ImportError:
    pass  # dotenv ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì§ì ‘ ì½ìŒ

# ============================================================
# ğŸ“¦ ì˜ì¡´ì„± ì²´í¬ & ì„¤ì¹˜
# ============================================================
def _get_ffmpeg_path() -> str:
    """FFmpeg ì‹¤í–‰ íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤ (imageio_ffmpeg ìš°ì„ )."""
    # 1ì°¨: imageio_ffmpeg ë²ˆë“¤
    try:
        import imageio_ffmpeg
        path = imageio_ffmpeg.get_ffmpeg_exe()
        if path and os.path.exists(path):
            return path
    except ImportError:
        pass

    # 2ì°¨: PATHì—ì„œ ê²€ìƒ‰
    ffmpeg_cmd = "where" if sys.platform == "win32" else "which"
    result = subprocess.run([ffmpeg_cmd, "ffmpeg"], capture_output=True, text=True, encoding="utf-8", errors="replace")
    if result.returncode == 0:
        return result.stdout.strip().split("\n")[0].strip()

    return ""


# ì „ì—­ FFmpeg ê²½ë¡œ (check_dependencies í›„ ì„¤ì •)
FFMPEG_PATH = ""
FFPROBE_PATH = ""


def check_dependencies():
    """í•„ìš”í•œ íŒ¨í‚¤ì§€ ìë™ ì„¤ì¹˜"""
    global FFMPEG_PATH, FFPROBE_PATH

    required = {
        "edge_tts": "edge-tts",
        "requests": "requests",
        "apify_client": "apify-client",
        "PIL": "Pillow",
        "imageio_ffmpeg": "imageio-ffmpeg",
        "google.generativeai": "google-generativeai",
        "anthropic": "anthropic",  # ëŒ€ë³¸ ìƒì„± (Claude)
    }
    for module, package in required.items():
        try:
            __import__(module)
        except ImportError:
            print(f"[+] {package} ì„¤ì¹˜ ì¤‘...")
            subprocess.check_call([
                sys.executable, "-m", "pip", "install",
                package, "--break-system-packages", "-q"
            ])

    # FFmpeg ê²½ë¡œ í™•ë³´
    FFMPEG_PATH = _get_ffmpeg_path()
    if not FFMPEG_PATH:
        if sys.platform == "win32":
            print("[!] FFmpegê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install imageio-ffmpeg")
        else:
            print("[!] FFmpegê°€ í•„ìš”í•©ë‹ˆë‹¤: sudo apt install ffmpeg")
        sys.exit(1)

    # ffprobe ê²½ë¡œ (ê°™ì€ ë””ë ‰í† ë¦¬ì—ì„œ íƒìƒ‰)
    ffmpeg_dir = os.path.dirname(FFMPEG_PATH)
    for name in ["ffprobe", "ffprobe.exe"]:
        probe = os.path.join(ffmpeg_dir, name)
        if os.path.exists(probe):
            FFPROBE_PATH = probe
            break
    if not FFPROBE_PATH:
        # PATHì—ì„œ ì‹œë„
        probe_cmd = "where" if sys.platform == "win32" else "which"
        r = subprocess.run([probe_cmd, "ffprobe"], capture_output=True, text=True, encoding="utf-8", errors="replace")
        if r.returncode == 0:
            FFPROBE_PATH = r.stdout.strip().split("\n")[0].strip()

    # pydub ë“± ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ffmpegë¥¼ ì°¾ì„ ìˆ˜ ìˆë„ë¡ PATHì— ì¶”ê°€
    ffmpeg_dir = os.path.dirname(FFMPEG_PATH)
    if ffmpeg_dir and ffmpeg_dir not in os.environ.get("PATH", ""):
        os.environ["PATH"] = ffmpeg_dir + os.pathsep + os.environ.get("PATH", "")

    print(f"  FFmpeg: {FFMPEG_PATH}")
    if FFPROBE_PATH:
        print(f"  FFprobe: {FFPROBE_PATH}")

check_dependencies()

import edge_tts
import requests
import google.generativeai as genai_flash
try:
    import anthropic as _anthropic_module
except ImportError:
    _anthropic_module = None
from apify_client import ApifyClient
from PIL import Image, ImageDraw, ImageFont, ImageFilter, ImageEnhance


# ============================================================
# âš™ï¸ ì„¤ì •ê°’
# ============================================================
@dataclass
class Config:
    # API í‚¤
    google_api_key: str = ""
    anthropic_api_key: str = ""  # ëŒ€ë³¸ ìƒì„±ìš© Claude (claude-sonnet-4-6)
    apify_api_token: str = ""

    # í¬ë¡¤ë§
    source: str = "dcinside"
    gallery: str = "humor"
    crawl_count: int = 3
    target_url: str = ""

    # ëŒ€ë³¸
    script_style: str = "storytelling"
    max_duration: int = 58
    skip_crawl: bool = False
    manual_topic: str = ""
    theme: str = "auto"  # "gossip" | "life_hack" | "empathy" | "mystery" | "auto"

    # TTS (v6.0: ElevenLabs â†’ OpenAI â†’ edge-tts í´ë°±)
    tts_engine: str = "auto"  # "elevenlabs" | "openai" | "edge" | "auto"
    tts_voice: str = "ko-KR-HyunsuNeural"  # edge-tts ì „ìš©
    tts_rate: str = "+5%"
    tts_pitch: str = "-1Hz"
    elevenlabs_api_key: str = ""
    elevenlabs_voice_id: str = ""  # ê¸°ë³¸ voice_id (ê°ì •ë³„ ìë™ ì „í™˜)

    # ì˜ìƒ
    width: int = 1080
    height: int = 1920
    fps: int = 30
    quality: int = 80

    # í°íŠ¸ (ìì—°ìŠ¤ëŸ¬ìš´ í•œê¸€)
    font_name: str = "NanumSquareRound"
    font_size: int = 56
    font_size_highlight: int = 67

    # v4.0: ë¹„ì£¼ì–¼/ì˜¤ë””ì˜¤ ì„¤ì •
    use_ai_bg: bool = False        # Imagen ì œê±° â€” ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ ì‚¬ìš© (ë¬´ë£Œ)
    use_stock_video: bool = True   # v5.1: Pexels ìŠ¤í†¡ ë¹„ë””ì˜¤ ë°°ê²½ (ë¬´ë£Œ)
    bgm_enabled: bool = True       # BGM + Auto-Ducking

    # ì¶œë ¥
    output_dir: str = "./output"

    def __post_init__(self):
        self.google_api_key = os.getenv("GOOGLE_API_KEY", self.google_api_key)
        self.anthropic_api_key = os.getenv("ANTHROPIC_API_KEY", self.anthropic_api_key)
        self.apify_api_token = os.getenv("APIFY_API_TOKEN", self.apify_api_token)
        # v6.0: ë©€í‹°ì—”ì§„ TTS + GoAPI
        self.elevenlabs_api_key = os.getenv("ELEVENLABS_API_KEY", self.elevenlabs_api_key)
        self.elevenlabs_voice_id = os.getenv("ELEVENLABS_VOICE_ID", self.elevenlabs_voice_id)
        os.makedirs(self.output_dir, exist_ok=True)


# ============================================================
# ğŸ”¤ í°íŠ¸ ë§¤ë‹ˆì € (ìì—°ìŠ¤ëŸ¬ìš´ í•œê¸€ í°íŠ¸ ìë™ ì„¤ì¹˜)
# ============================================================
class FontManager:
    """ì‹œìŠ¤í…œì— ìì—°ìŠ¤ëŸ¬ìš´ í•œê¸€ í°íŠ¸ í™•ë³´"""

    # ìš°ì„ ìˆœìœ„ í°íŠ¸ ëª©ë¡
    FONT_PRIORITY = [
        # aptë¡œ ì„¤ì¹˜ ê°€ëŠ¥í•œ í°íŠ¸
        ("NanumSquareRound", "fonts-nanum"),
        ("NanumGothic", "fonts-nanum"),
        ("NanumGothicBold", "fonts-nanum"),
        # ê¸°ë³¸ ë‚´ì¥ ê°€ëŠ¥ì„±
        ("NotoSansCJK-Bold", None),
        ("NotoSansKR-Bold", None),
        ("DejaVuSans", None),
    ]

    # v6.0: ë‘ê»ê³  ê·€ì—¬ìš´ í°íŠ¸ (Satisfying ìŠ¤íƒ€ì¼ìš©)
    _shorts_font_cache: dict = {}

    @staticmethod
    def get_shorts_font(size: int) -> ImageFont.FreeTypeFont:
        """
        v6.0: ì‡¼ì¸  ì „ìš© ë‘êº¼ìš´ í°íŠ¸ ë°˜í™˜ (GmarketSans Bold ìš°ì„ )
        ì—†ìœ¼ë©´ ìë™ ë‹¤ìš´ë¡œë“œ â†’ ë¡œì»¬ fonts/ ë””ë ‰í† ë¦¬ì— ìºì‹œ
        """
        cache_key = f"shorts_{size}"
        if cache_key in FontManager._shorts_font_cache:
            return FontManager._shorts_font_cache[cache_key]

        # 1) ë¡œì»¬ fonts/ ë””ë ‰í† ë¦¬ ì²´í¬
        local_fonts_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), "fonts")
        os.makedirs(local_fonts_dir, exist_ok=True)

        gmarket_path = os.path.join(local_fonts_dir, "GmarketSansTTFBold.ttf")
        if os.path.exists(gmarket_path):
            font = ImageFont.truetype(gmarket_path, size)
            FontManager._shorts_font_cache[cache_key] = font
            return font

        # 2) Windows í°íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ GmarketSans / CookieRun ê²€ìƒ‰
        if sys.platform == "win32":
            font_dirs = [
                os.path.join(os.environ.get("WINDIR", "C:\\Windows"), "Fonts"),
                os.path.join(os.environ.get("LOCALAPPDATA", ""), "Microsoft", "Windows", "Fonts"),
            ]
            for font_dir in font_dirs:
                if not os.path.isdir(font_dir):
                    continue
                for fname in ["GmarketSansTTFBold.ttf", "GmarketSansBold.ttf",
                              "CookieRun Bold.ttf", "CookieRunOTF-Bold.otf"]:
                    path = os.path.join(font_dir, fname)
                    if os.path.exists(path):
                        font = ImageFont.truetype(path, size)
                        FontManager._shorts_font_cache[cache_key] = font
                        return font

        # 3) ìë™ ë‹¤ìš´ë¡œë“œ (GmarketSans Bold â€” ë¬´ë£Œ ë°°í¬ í°íŠ¸)
        download_urls = [
            "https://cdn.jsdelivr.net/gh/nicesharp/gmarket-sans@main/GmarketSansTTFBold.ttf",
            "https://raw.githubusercontent.com/nicesharp/gmarket-sans/main/GmarketSansTTFBold.ttf",
        ]
        for download_url in download_urls:
            print(f"  ğŸ“¥ GmarketSans Bold í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            try:
                resp = requests.get(download_url, timeout=30)
                if resp.status_code == 200 and len(resp.content) > 10000:
                    with open(gmarket_path, "wb") as f:
                        f.write(resp.content)
                    print(f"  âœ… GmarketSans Bold ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ({len(resp.content)//1024}KB)")
                    font = ImageFont.truetype(gmarket_path, size)
                    FontManager._shorts_font_cache[cache_key] = font
                    return font
            except Exception as e:
                print(f"  âš ï¸  GmarketSans ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
                continue

        # 4) í´ë°±: ë§‘ì€ê³ ë”• Bold â†’ ê¸°ë³¸ Bold
        fallback = FontManager.get_font(size, bold=True)
        FontManager._shorts_font_cache[cache_key] = fallback
        return fallback

    @staticmethod
    def get_font(size: int, bold: bool = False) -> ImageFont.FreeTypeFont:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ê°€ì¥ ì¢‹ì€ í•œê¸€ í°íŠ¸ ë°˜í™˜"""
        # 1ì°¨: Windows í°íŠ¸ ë””ë ‰í† ë¦¬ ê²€ìƒ‰
        if sys.platform == "win32":
            font_path = FontManager._find_windows_font(bold)
            if font_path:
                return ImageFont.truetype(font_path, size)

        # 2ì°¨: fc-listë¡œ ì‹œìŠ¤í…œ í•œê¸€ í°íŠ¸ ê²€ìƒ‰ (Linux/macOS)
        font_path = FontManager._find_system_font(bold)
        if font_path:
            return ImageFont.truetype(font_path, size)

        # 3ì°¨: aptë¡œ ë‚˜ëˆ” í°íŠ¸ ì„¤ì¹˜ ì‹œë„ (Linux)
        FontManager._install_nanum_fonts()
        font_path = FontManager._find_system_font(bold)
        if font_path:
            return ImageFont.truetype(font_path, size)

        # 4ì°¨: ì›¹ì—ì„œ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì‹œë„
        font_path = FontManager._download_font()
        if font_path:
            return ImageFont.truetype(font_path, size)

        # ìµœí›„: ê¸°ë³¸ í°íŠ¸
        print("  [!] í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©")
        return ImageFont.load_default()

    @staticmethod
    def _find_windows_font(bold: bool = False) -> Optional[str]:
        """Windows í°íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ í•œê¸€ í°íŠ¸ ê²€ìƒ‰"""
        font_dirs = [
            os.path.join(os.environ.get("WINDIR", "C:\\Windows"), "Fonts"),
            os.path.join(os.environ.get("LOCALAPPDATA", ""), "Microsoft", "Windows", "Fonts"),
        ]
        if bold:
            filenames = [
                "NanumSquareRoundB.ttf", "NanumSquareRoundEB.ttf",
                "NanumGothicBold.ttf", "malgunbd.ttf",
            ]
        else:
            filenames = [
                "NanumSquareRoundR.ttf", "NanumSquareRound.ttf",
                "NanumGothic.ttf", "malgun.ttf", "malgunbd.ttf",
            ]
        for font_dir in font_dirs:
            if not os.path.isdir(font_dir):
                continue
            for filename in filenames:
                path = os.path.join(font_dir, filename)
                if os.path.exists(path):
                    return path
        return None

    @staticmethod
    def _find_system_font(bold: bool = False) -> Optional[str]:
        """fc-listë¡œ í•œê¸€ í°íŠ¸ ê²½ë¡œ ì°¾ê¸° (Linux/macOS)"""
        if sys.platform == "win32":
            return None
        try:
            preferred = [
                "NanumSquareRoundB" if bold else "NanumSquareRoundR",
                "NanumSquareRound",
                "NanumGothicBold" if bold else "NanumGothic",
                "NanumGothic",
                "NotoSansCJK",
                "NotoSansKR",
                "Pretendard",
                "D2Coding",
            ]
            result = subprocess.run(
                ["fc-list", ":lang=ko", "file"],
                capture_output=True, text=True, encoding="utf-8", errors="replace", timeout=5
            )
            font_lines = result.stdout.strip().split("\n")

            for pref in preferred:
                for line in font_lines:
                    path = line.split(":")[0].strip()
                    if pref.lower() in path.lower() and os.path.exists(path):
                        return path

            # ì•„ë¬´ í•œê¸€ í°íŠ¸ë¼ë„
            for line in font_lines:
                path = line.split(":")[0].strip()
                if os.path.exists(path) and path.endswith((".ttf", ".otf")):
                    return path

        except Exception:
            pass
        return None

    @staticmethod
    def _install_nanum_fonts():
        """aptë¡œ ë‚˜ëˆ” í°íŠ¸ ì„¤ì¹˜"""
        try:
            print("  ğŸ“¦ í•œê¸€ í°íŠ¸ ì„¤ì¹˜ ì¤‘ (NanumSquareRound)...")
            subprocess.run(
                ["apt-get", "install", "-y", "-qq",
                 "fonts-nanum", "fonts-nanum-extra"],
                capture_output=True, timeout=30
            )
            subprocess.run(["fc-cache", "-f"], capture_output=True, timeout=10)
        except Exception:
            pass

    @staticmethod
    def _download_font() -> Optional[str]:
        """ë‚˜ëˆ”ìŠ¤í€˜ì–´ë¼ìš´ë“œ í°íŠ¸ ë‹¤ìš´ë¡œë“œ"""
        font_dir = os.path.expanduser("~/.local/share/fonts")
        os.makedirs(font_dir, exist_ok=True)
        font_path = os.path.join(font_dir, "NanumSquareRoundR.ttf")

        if os.path.exists(font_path):
            return font_path

        try:
            # ë‚˜ëˆ”ìŠ¤í€˜ì–´ë¼ìš´ë“œ ë‹¤ìš´ë¡œë“œ URL
            url = ("https://github.com/nicedoctor/NanumSquareRound/raw/"
                   "master/NanumSquareRoundR.ttf")
            print(f"  ğŸ“¥ í°íŠ¸ ë‹¤ìš´ë¡œë“œ ì¤‘...")
            resp = requests.get(url, timeout=15)
            if resp.status_code == 200:
                with open(font_path, "wb") as f:
                    f.write(resp.content)
                subprocess.run(["fc-cache", "-f"], capture_output=True)
                return font_path
        except Exception:
            pass
        return None


# ============================================================
# ğŸ¨ ê°ì • ìŠ¤íƒ€ì¼ (v3: ë” ìì—°ìŠ¤ëŸ¬ìš´ ìƒ‰ìƒ)
# ============================================================
EMOTION_STYLES = {
    "anger": {
        "text_color": (255, 80, 80),       # ë¹¨ê°• (ë¶€ë“œëŸ½ê²Œ)
        "bg_color": (40, 10, 10, 200),      # ì–´ë‘ìš´ ë¹¨ê°• ë°°ê²½
        "border_color": (255, 60, 60),
    },
    "fun": {
        "text_color": (255, 220, 50),       # ê³¨ë“œ (ë°ê²Œ)
        "bg_color": (40, 35, 5, 200),
        "border_color": (255, 200, 0),
    },
    "surprise": {
        "text_color": (100, 230, 255),      # í•˜ëŠ˜ìƒ‰
        "bg_color": (5, 30, 40, 200),
        "border_color": (0, 200, 255),
    },
    "sad": {
        "text_color": (200, 160, 255),      # ë¼ë²¤ë”
        "bg_color": (25, 15, 40, 200),
        "border_color": (180, 130, 255),
    },
    "neutral": {
        "text_color": (255, 255, 255),      # í°ìƒ‰
        "bg_color": (20, 20, 20, 190),
        "border_color": (100, 100, 100),
    },
    "tension": {
        "text_color": (255, 130, 100),      # ì½”ë„
        "bg_color": (40, 15, 10, 200),
        "border_color": (255, 100, 70),
    },
    "relief": {
        "text_color": (130, 255, 190),      # ë¯¼íŠ¸
        "bg_color": (10, 35, 20, 200),
        "border_color": (100, 230, 160),
    },
    "shock": {
        "text_color": (255, 180, 50),       # ì£¼í™©
        "bg_color": (40, 25, 5, 200),
        "border_color": (255, 150, 0),
    },
}


# ============================================================
# ğŸ¥ Satisfying Video í˜ì²˜ (ëŒ€ë³¸ ë¬´ê´€ â†’ ì‹œê°ì  ë§Œì¡±ê° ì˜ìƒ 1ê°œ)
# ============================================================
class StockVideoFetcher:
    """
    v6.0: Satisfying Video ì „ëµ
    - ëŒ€ë³¸ ë‚´ìš©ê³¼ ë¬´ê´€í•˜ê²Œ Oddly Satisfying ê³ í™”ì§ˆ ì„¸ë¡œ ì˜ìƒ 1ê°œ ë‹¤ìš´ë¡œë“œ
    - ì „ì²´ ë°°ê²½ìœ¼ë¡œ ë£¨í”„ ì‚¬ìš© (ë¬¸ì¥ë³„ ì»· ì „í™˜ ì œê±°)
    - API ë¹„ìš©: $0 (Pexels ë¬´ë£Œ API)
    """

    PEXELS_API_URL = "https://api.pexels.com/videos/search"

    # v6.2: ê°ì •(mood) â†’ ì‹œë„¤ë§ˆí‹± 4K ë°°ê²½ í‚¤ì›Œë“œ ë§¤í•‘
    # ì‚¬ëŒ ì—°ê¸° ì˜ìƒ ì ˆëŒ€ ê¸ˆì§€ â€” ì§ˆê°/ë°°ê²½/ì¶”ìƒ ì˜ìƒë§Œ
    MOOD_KEYWORDS = {
        "funny": [
            "glitch art abstract",
            "pop art animation",
            "fast motion clouds timelapse",
            "colorful liquid abstract",
            "neon lights abstract",
            "candy factory machine",
        ],
        "angry": [
            "breaking glass slow motion",
            "fire flames close up",
            "lightning storm 4k",
            "hydraulic press crushing",
            "volcanic eruption lava",
            "shredding machine metal",
        ],
        "sad": [
            "rain on window close up",
            "ink in water dark",
            "lonely night city lights",
            "autumn leaves falling",
            "ocean waves dark moody",
            "candle flame dark room",
        ],
        "touching": [
            "sunrise golden hour nature",
            "cherry blossom petals falling",
            "sand art satisfying",
            "calligraphy ink writing",
            "warm fireplace close up",
            "golden wheat field wind",
        ],
        "scary": [
            "dark forest fog",
            "old tv static noise",
            "smoke dark background",
            "abandoned hallway dark",
            "flickering light horror",
            "deep ocean dark water",
        ],
        "satisfying": [
            "soap cutting asmr",
            "kinetic sand satisfying",
            "epoxy resin art pour",
            "paint pouring abstract",
            "pressure washing satisfying",
            "slime mixing colorful",
        ],
        "shocking": [
            "explosion slow motion",
            "lightning strike close up",
            "chemical reaction colorful",
            "hydraulic press crushing",
            "glass shattering slow motion",
            "liquid metal melting pour",
        ],
    }

    # í´ë°±: mood ë¯¸ì§€ì • ì‹œ ë²”ìš© í’€
    SATISFYING_KEYWORDS = [
        "abstract liquid motion",
        "kinetic sand satisfying",
        "soap cutting asmr",
        "ink in water dark",
        "paint pouring abstract",
        "fire flames close up",
        "rain on window",
        "neon lights abstract",
        "smoke dark background",
        "ocean waves dark moody",
    ]

    def __init__(self):
        self.api_key = os.getenv("PEXELS_API_KEY", "")
        self._download_count = 0

    def search_satisfying_video(self, mood: str = "") -> Optional[dict]:
        """ê°ì •(mood) ê¸°ë°˜ Satisfying í‚¤ì›Œë“œ ë§¤ì¹­ â†’ Pexels ì„¸ë¡œ ì˜ìƒ ê²€ìƒ‰"""
        if not self.api_key:
            return None

        # moodê°€ ìˆìœ¼ë©´ í•´ë‹¹ ê°ì • í‚¤ì›Œë“œ ìš°ì„ , ì—†ìœ¼ë©´ í´ë°± í’€
        if mood and mood.lower() in self.MOOD_KEYWORDS:
            keywords = self.MOOD_KEYWORDS[mood.lower()].copy()
            print(f"    ğŸ­ ê°ì • ë§¤ì¹­: [{mood}] â†’ {keywords[:3]}...")
            # í´ë°±ìœ¼ë¡œ ê¸°ë³¸ í’€ ì¶”ê°€
            fallback = [k for k in self.SATISFYING_KEYWORDS if k not in keywords]
            random.shuffle(fallback)
            keywords += fallback[:3]
        else:
            keywords = self.SATISFYING_KEYWORDS.copy()
        random.shuffle(keywords)

        for keyword in keywords:
            try:
                headers = {"Authorization": self.api_key}
                params = {
                    "query": keyword,
                    "orientation": "portrait",
                    "size": "medium",
                    "per_page": 15,
                    "min_duration": 15,
                }
                resp = requests.get(self.PEXELS_API_URL, headers=headers,
                                    params=params, timeout=15)
                if resp.status_code != 200:
                    print(f"    âš ï¸  Pexels API ì˜¤ë¥˜ ({keyword}): {resp.status_code}")
                    continue

                data = resp.json()
                videos = data.get("videos", [])

                # 15ì´ˆ ì´ìƒ + ì„¸ë¡œ ì˜ìƒ í•„í„°
                candidates = []
                for v in videos:
                    dur = v.get("duration", 0)
                    if dur >= 15:
                        candidates.append(v)

                if not candidates:
                    # orientation ì—†ì´ ì¬ì‹œë„
                    params.pop("orientation", None)
                    resp = requests.get(self.PEXELS_API_URL, headers=headers,
                                        params=params, timeout=15)
                    data = resp.json()
                    for v in data.get("videos", []):
                        if v.get("duration", 0) >= 15:
                            candidates.append(v)

                if not candidates:
                    continue

                # ëœë¤ ì„ íƒ (ê°™ì€ ì˜ìƒ ë°˜ë³µ ë°©ì§€)
                video = random.choice(candidates)
                video_files = video.get("video_files", [])

                # ì„¸ë¡œ + ì ì ˆ í•´ìƒë„ íŒŒì¼ ì„ íƒ
                best_file = None
                for vf in video_files:
                    w = vf.get("width", 0)
                    h = vf.get("height", 0)
                    if 480 <= min(w, h) <= 1920:
                        if best_file is None:
                            best_file = vf
                        elif h > w and (best_file.get("height", 0) <= best_file.get("width", 0)):
                            best_file = vf  # ì„¸ë¡œ ìš°ì„ 

                if not best_file and video_files:
                    best_file = video_files[0]

                url = best_file.get("link", "") if best_file else ""
                if url:
                    print(f"    ğŸ¯ Satisfying ì˜ìƒ ë°œê²¬! [{keyword}] (ê¸¸ì´: {video.get('duration', 0)}ì´ˆ)")
                    return {"url": url, "keyword": keyword,
                            "duration": video.get("duration", 0)}

            except Exception as e:
                print(f"    âš ï¸  Pexels ê²€ìƒ‰ ì‹¤íŒ¨ ({keyword}): {e}")
            time.sleep(0.3)

        return None

    def download_video(self, url: str, save_path: str) -> bool:
        """ë¹„ë””ì˜¤ URL â†’ ë¡œì»¬ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
        try:
            resp = requests.get(url, timeout=60, stream=True)
            if resp.status_code == 200:
                with open(save_path, "wb") as f:
                    for chunk in resp.iter_content(chunk_size=8192):
                        f.write(chunk)
                self._download_count += 1
                return True
        except Exception as e:
            print(f"    âš ï¸  ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False

    def fetch_satisfying_background(self, work_dir: str, mood: str = "") -> Optional[str]:
        """
        v6.1: ê°ì • ê¸°ë°˜ Satisfying ë°°ê²½ ì˜ìƒ 1ê°œ ë‹¤ìš´ë¡œë“œ.
        mood â†’ MOOD_KEYWORDS ë§¤í•‘ìœ¼ë¡œ ì½˜í…ì¸  í†¤ì— ë§ëŠ” ë°°ê²½ ì„ íƒ
        Returns: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ or None
        """
        if not self.api_key:
            print("  âš ï¸  PEXELS_API_KEY ì—†ìŒ â€” ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ í´ë°±")
            return None

        os.makedirs(work_dir, exist_ok=True)

        mood_display = f" [ê°ì •: {mood}]" if mood else ""
        print(f"  ğŸ¥ Satisfying ë°°ê²½ ì˜ìƒ ê²€ìƒ‰ ì¤‘...{mood_display}")

        result = self.search_satisfying_video(mood=mood)
        if not result:
            print("  âš ï¸  Satisfying ì˜ìƒ ê²€ìƒ‰ ì‹¤íŒ¨ â€” ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ í´ë°±")
            return None

        video_path = os.path.join(work_dir, "satisfying_bg.mp4")
        if self.download_video(result["url"], video_path):
            size_mb = os.path.getsize(video_path) / (1024 * 1024)
            print(f"  âœ… Satisfying ë°°ê²½ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {result['keyword']} ({size_mb:.1f}MB, {result['duration']}ì´ˆ)")
            return video_path

        return None

    # í•˜ìœ„ í˜¸í™˜: ê¸°ì¡´ fetch_scene_videos í˜¸ì¶œ ì‹œ ìƒˆ ë°©ì‹ìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
    def fetch_scene_videos(self, script_data: dict, work_dir: str) -> list[dict]:
        """í•˜ìœ„ í˜¸í™˜ ë˜í¼ â€” v6.1ì—ì„œëŠ” fetch_satisfying_background(mood=) ì‚¬ìš© ê¶Œì¥"""
        mood = script_data.get("mood", "")
        bg_path = self.fetch_satisfying_background(work_dir, mood=mood)
        if bg_path:
            return [{"chunk_idx": -1, "video_path": bg_path, "scene_hint": "satisfying"}]
        return []


# ============================================================
# ğŸ¬ Kling AI Image-to-Video (ì²«/ë§ˆì§€ë§‰ ì¥ë©´ ë™ì˜ìƒí™”)
# ============================================================
class KlingVideoGenerator:
    """Kling AI API: ì •ì  ì´ë¯¸ì§€ â†’ 5ì´ˆ ë™ì˜ìƒ ë³€í™˜ (JWT ì¸ì¦)"""
    BASE_URL = "https://api.klingai.com"

    def __init__(self):
        self.access_key = os.getenv("KLING_ACCESS_KEY", "")
        self.secret_key = os.getenv("KLING_SECRET_KEY", "")
        self._token = None
        self._token_exp = 0

    @property
    def available(self) -> bool:
        return bool(self.access_key and self.secret_key)

    def _get_token(self) -> str:
        """JWT í† í° ìƒì„± (HS256, 1800ì´ˆ ìœ íš¨)"""
        import jwt as pyjwt
        now = time.time()
        if self._token and now < self._token_exp - 60:
            return self._token
        payload = {
            "iss": self.access_key,
            "exp": int(now + 1800),
            "nbf": int(now - 5),
            "iat": int(now),
        }
        self._token = pyjwt.encode(payload, self.secret_key, algorithm="HS256")
        self._token_exp = now + 1800
        return self._token

    def _upload_temp_image(self, image_path: str) -> str:
        """ì´ë¯¸ì§€ë¥¼ ì„ì‹œ í˜¸ìŠ¤íŒ…ì— ì—…ë¡œë“œ â†’ URL ë°˜í™˜"""
        try:
            with open(image_path, "rb") as f:
                resp = requests.post(
                    "https://0x0.st",
                    files={"file": (os.path.basename(image_path), f)},
                    timeout=30,
                )
            if resp.status_code == 200:
                url = resp.text.strip()
                print(f"    ğŸ“¤ ì´ë¯¸ì§€ ì—…ë¡œë“œ: {url}")
                return url
        except Exception as e:
            print(f"    âš ï¸  ì´ë¯¸ì§€ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
        return ""

    def generate_video(self, image_path: str, prompt: str,
                       output_path: str, duration: int = 5) -> bool:
        """ì´ë¯¸ì§€ â†’ ë™ì˜ìƒ ë³€í™˜ (ë™ê¸° í´ë§, ìµœëŒ€ 5ë¶„ ëŒ€ê¸°)"""
        if not self.available:
            return False
        try:
            # ì´ë¯¸ì§€ë¥¼ ì„ì‹œ í˜¸ìŠ¤íŒ…ì— ì—…ë¡œë“œí•˜ì—¬ URL íšë“
            image_url = self._upload_temp_image(image_path)
            if not image_url:
                print(f"    âš ï¸  Kling: ì´ë¯¸ì§€ URL ìƒì„± ì‹¤íŒ¨")
                return False

            token = self._get_token()
            headers = {
                "Authorization": f"Bearer {token}",
                "Content-Type": "application/json",
            }
            # íƒœìŠ¤í¬ ìƒì„±
            body = {
                "model_name": "kling-v1",
                "image": image_url,
                "prompt": prompt[:200],
                "mode": "std",
                "duration": str(duration),
                "cfg_scale": 0.5,
            }
            resp = requests.post(
                f"{self.BASE_URL}/v1/videos/image2video",
                json=body, headers=headers, timeout=30,
            )
            if resp.status_code != 200:
                print(f"    âš ï¸  Kling API {resp.status_code}: {resp.text[:200]}")
                return False
            result = resp.json()
            task_id = result.get("data", {}).get("task_id")
            if not task_id:
                print(f"    âš ï¸  Kling íƒœìŠ¤í¬ ìƒì„± ì‹¤íŒ¨: {result}")
                return False

            print(f"    ğŸ¬ Kling íƒœìŠ¤í¬ ìƒì„±: {task_id}")

            # í´ë§ (ìµœëŒ€ 300ì´ˆ)
            for _ in range(60):
                time.sleep(5)
                token = self._get_token()
                headers["Authorization"] = f"Bearer {token}"
                qr = requests.get(
                    f"{self.BASE_URL}/v1/videos/image2video/{task_id}",
                    headers=headers, timeout=15,
                )
                qr.raise_for_status()
                status_data = qr.json().get("data", {})
                task_status = status_data.get("task_status", "")

                if task_status == "succeed":
                    videos = status_data.get("task_result", {}).get("videos", [])
                    if videos:
                        video_url = videos[0].get("url", "")
                        if video_url:
                            vr = requests.get(video_url, timeout=60)
                            vr.raise_for_status()
                            with open(output_path, "wb") as f:
                                f.write(vr.content)
                            print(f"    âœ… Kling ë™ì˜ìƒ ì™„ë£Œ: {output_path}")
                            return True
                    return False
                elif task_status == "failed":
                    err = status_data.get("task_status_msg", "unknown")
                    print(f"    âš ï¸  Kling ì‹¤íŒ¨: {err}")
                    return False
            print(f"    âš ï¸  Kling íƒ€ì„ì•„ì›ƒ (300ì´ˆ)")
            return False
        except Exception as e:
            print(f"    âš ï¸  Kling ì˜ˆì™¸: {str(e)[:100]}")
            return False


# ============================================================
# ğŸ–¼ï¸ AI ì´ë¯¸ì§€ ìƒì„±ê¸° (Pollinations.ai ë¬´ë£Œ + DALL-E í´ë°±)
# ============================================================
class ImageGenerator:
    """
    v7.2: ì›¹íˆ°í˜• ì‡¼ì¸ ìš© ì¥ë©´ë³„ ì´ë¯¸ì§€ ìƒì„±ê¸°
    â”€ 1ìˆœìœ„: Replicate FLUX-schnell (ì›¹íˆ°/ë§Œí™” ìŠ¤íƒ€ì¼, go_fast, 9:16)
    â”€ 2ìˆœìœ„: Pexels ìŠ¤í†¡ ì´ë¯¸ì§€ (ë¬´ë£Œ í´ë°±, ê³ í’ˆì§ˆ)
    â”€ ì¶œë ¥: 1080x1920 (9:16 ì„¸ë¡œ)
    â”€ ìš©ë„: ëŒ€ë³¸ ë¬¸ì¥ë³„ ì‹œê°í™” ì´ë¯¸ì§€ â†’ Ken Burns íš¨ê³¼ ì ìš©
    """

    # â”€â”€ ì›¹íˆ° í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ (â˜… í•œêµ­ Bê¸‰ ì›¹íˆ° íŠ¹í™”) â”€â”€
    WEBTOON_PREFIX = (
        "Korean Naver webtoon realistic slice-of-life illustration, "
        "thick clean ink outlines, muted warm realistic color palette, "
        "realistic human proportions, detailed Korean facial features, "
        "realistic detailed Korean everyday background setting, "
        "warm dim natural lighting, moody cinematic tone, "
        "consistent character design throughout, "
        "absolutely NO text NO letters NO words NO writing NO watermark on the image, "
        "AVOID Japanese anime, AVOID big round eyes, AVOID chibi proportions, "
    )
    WEBTOON_NEGATIVE = (
        "Japanese anime, anime eyes, chibi, kawaii, moe, manga, "
        "pastel colors, sparkly eyes, "
        "photorealistic, photograph, 3d render, "
        "text, letters, words, writing, caption, subtitle, "
        "watermark, signature, logo, blurry, low quality, "
        "Japanese text, kanji, hiragana, katakana, Chinese characters"
    )

    # ë¬´ë“œë³„ ìŠ¤íƒ€ì¼ ë³´ê°• (â˜… í•œêµ­ í˜„ì‹¤ ê³ ì¦ / ê³ ë… / ë¬´ê±°ìš´ í†¤)
    MOOD_STYLE = {
        "angry": "dark red shadows, character gritting teeth in dim smoky room, oppressive tense atmosphere, ",
        "funny": "dim warm lighting, character with exhausted bitter smirk, dark humor irony, not cheerful, ",
        "sad": "cold blue darkness, character alone staring at empty soju glass, heavy lonely silence, ",
        "touching": "faint warm light in darkness, character with weary but relieved eyes, bittersweet moment, ",
        "scary": "pitch dark shadows, character pale with cold sweat, dread and isolation, ",
        "shocking": "harsh single spotlight in darkness, character frozen with hollow stare, devastating realization, ",
        "satisfying": "dim moody lighting, character with tired but defiant smirk, quiet victory alone, ",
    }

    # Pexels í´ë°±ìš© í‚¤ì›Œë“œ ë§¤í•‘
    PEXELS_KEYWORD_MAP = {
        "í˜„ê´€ë¬¸": "door lock", "ë„ì–´ë½": "smart door lock", "ë¹„ë²ˆ": "door keypad",
        "ëƒ‰ì¥ê³ ": "refrigerator food", "ë°˜ì°¬": "korean side dishes", "ì£¼ë°©": "kitchen",
        "ì•„íŒŒíŠ¸": "apartment building", "ì‹ í˜¼ì§‘": "modern apartment interior",
        "CCTV": "security camera", "ì§€ë¬¸": "fingerprint scanner",
        "ì‹œì–´ë¨¸ë‹ˆ": "angry woman phone", "ë‚¨í¸": "man worried", "ê²½ì°°": "police",
        "ì „í™”": "phone call", "íƒë°°": "delivery package box", "ì—ì–´íŒŸ": "airpods white",
        "ì½©ë‚˜ë¬¼": "bean sprouts", "ì¤‘ê³ ê±°ë˜": "online shopping phone", "ì‚¬ê¸°": "fraud scam",
    }

    MOOD_PEXELS = {
        "angry": ["dramatic red", "breaking glass", "fire close up"],
        "funny": ["colorful abstract", "pop art", "bright neon"],
        "sad": ["rain window", "dark ocean", "lonely night"],
        "touching": ["sunset warm", "golden light", "flowers bloom"],
        "scary": ["dark forest", "fog horror", "abandoned building"],
        "shocking": ["lightning storm", "dramatic sky", "broken mirror"],
        "satisfying": ["marble texture", "geometric pattern", "water drop"],
    }

    def __init__(self):
        self.replicate_token = os.getenv("REPLICATE_API_TOKEN", "")
        self.pexels_key = os.getenv("PEXELS_API_KEY", "")
        self.openai_key = os.getenv("OPENAI_API_KEY", "")
        self._gen_count = 0
        self._used_photo_ids = set()
        self._bing_creator = None  # Bing DALL-E 3 (lazy init)
        self._bing_failed = False  # Bing ì „ì²´ ì‹¤íŒ¨ í”Œë˜ê·¸
        # v6.0: GoAPI Midjourney (0ìˆœìœ„)
        self._goapi = None
        self._goapi_failed = False
        # v10.0: Kling AI image-to-video (ì²«/ë§ˆì§€ë§‰ ì¥ë©´)
        self._kling = KlingVideoGenerator()
        if self._kling.available:
            print(f"  ğŸ¬ Kling AI ì—°ë™ ì™„ë£Œ (ì²«/ë§ˆì§€ë§‰ ì¥ë©´ ë™ì˜ìƒí™”)")

    def _get_bing_creator(self):
        """Bing Image Creator ì¸ìŠ¤í„´ìŠ¤ (lazy init, ë¸Œë¼ìš°ì € 1ê°œ ì¬ì‚¬ìš©)"""
        if self._bing_creator is None and not self._bing_failed:
            try:
                from bing_generator import BingImageCreator
                self._bing_creator = BingImageCreator()
            except Exception as e:
                print(f"    âš ï¸  Bing Creator ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)[:80]}")
                self._bing_failed = True
        return self._bing_creator

    def generate_scene_images(self, script_data: dict, work_dir: str) -> list[dict]:
        """
        v6.0: ëŒ€ë³¸ì˜ ê° ì¥ë©´ì— ëŒ€í•´ ì›¹íˆ° ì´ë¯¸ì§€ ìƒì„±.
        ìš°ì„ ìˆœìœ„: GoAPI Midjourney â†’ Replicate FLUX â†’ Bing DALL-E 3 â†’ ì¬ì‚¬ìš©
        Returns: [{"chunk_idx": 0, "end_idx": 2, "image_path": "...", "prompt": "..."}]
        """
        # â˜… ìºë¦­í„° ì¼ê´€ì„±: ìƒˆ ì˜ìƒ ì‹œì‘ ì‹œ ìºë¦­í„° ê¸°ì–µ ë¦¬ì…‹
        self._character_desc = ""
        if self._goapi:
            self._goapi.reset_session()

        script_lines = script_data.get("script", [])
        mood = script_data.get("mood", "")

        images_dir = os.path.join(work_dir, "_scene_images")
        os.makedirs(images_dir, exist_ok=True)

        results = []
        scene_groups = self._group_sentences(script_lines)

        # ì—”ì§„ ìš°ì„ ìˆœìœ„ í‘œì‹œ
        engines = []
        if self._goapi and not self._goapi_failed:
            engines.append("Midjourney (GoAPI)")
        if self.replicate_token:
            engines.append("Replicate FLUX")
        engines.append("Bing DALL-E 3")
        print(f"\n  ğŸ–¼ï¸  ì¥ë©´ ì´ë¯¸ì§€ ìƒì„± ì¤‘... ({len(scene_groups)}ì¥, mood={mood})")
        print(f"    ì—”ì§„ ìš°ì„ ìˆœìœ„: {' â†’ '.join(engines)}")

        bing_consecutive_fail = 0
        goapi_consecutive_fail = 0
        last_success_path = ""  # â˜… ì§ì „ ì„±ê³µ ì´ë¯¸ì§€ ê²½ë¡œ (Pexels ëŒ€ì‹  ì¬ì‚¬ìš©)

        for gi, group in enumerate(scene_groups):
            raw_prompt = group.get("image_prompt", "")
            image_path = os.path.join(images_dir, f"scene_{gi:03d}.jpg")
            success = False

            # â”€â”€ 0ìˆœìœ„: GoAPI Midjourney (--sref/--cref ìºë¦­í„° ì¼ê´€ì„±) â”€â”€
            if self._goapi and not self._goapi_failed and goapi_consecutive_fail < 3:
                try:
                    mj_prompt = self._build_mj_prompt_for_goapi(
                        raw_prompt, group["texts"], mood
                    )
                    # ì²« ì´ë¯¸ì§€: sref/cref ì—†ìŒ â†’ ì´í›„: ìë™ ì£¼ì…
                    sref = self._goapi.first_image_url if gi > 0 else None
                    cref = self._goapi.first_image_url if gi > 0 else None
                    success = self._goapi.generate_image(
                        mj_prompt, image_path,
                        style_ref=sref, char_ref=cref,
                    )
                    if success:
                        goapi_consecutive_fail = 0
                        print(f"    âœ… [{gi+1}/{len(scene_groups)}] ğŸ¨ Midjourney: "
                              f"{raw_prompt[:45]}...")
                    else:
                        goapi_consecutive_fail += 1
                        if goapi_consecutive_fail >= 3:
                            print(f"    âš ï¸  GoAPI 3íšŒ ì—°ì† ì‹¤íŒ¨ â†’ í´ë°± ì „í™˜")
                            self._goapi_failed = True
                except Exception as e:
                    goapi_consecutive_fail += 1
                    print(f"    âš ï¸  GoAPI ì˜ˆì™¸: {e}")
                    if goapi_consecutive_fail >= 3:
                        self._goapi_failed = True

            # â”€â”€ 1ìˆœìœ„: Replicate FLUX-schnell â”€â”€
            if not success and self.replicate_token:
                webtoon_prompt = self._build_webtoon_prompt(raw_prompt, group["texts"], mood)
                webp_path = image_path.replace(".jpg", ".webp")
                success = self._generate_replicate(webtoon_prompt, webp_path)
                if success:
                    image_path = webp_path
                    print(f"    âœ… [{gi+1}/{len(scene_groups)}] ğŸ¤– FLUX: {raw_prompt[:45]}...")
                else:
                    # â˜… NSFW ì°¨ë‹¨ ì‹œ safe-for-work í”„ë¡¬í”„íŠ¸ë¡œ 1íšŒ ì¬ì‹œë„
                    safe_prompt = (
                        "safe for work, cartoon illustration, "
                        + webtoon_prompt.replace("sexy", "").replace("nude", "")
                        .replace("violence", "action").replace("blood", "red")
                    )
                    success = self._generate_replicate(safe_prompt, webp_path)
                    if success:
                        image_path = webp_path
                        print(f"    âœ… [{gi+1}/{len(scene_groups)}] ğŸ¤– FLUX (SFW ì¬ì‹œë„): {raw_prompt[:35]}...")

            # â”€â”€ 2ìˆœìœ„: Bing Image Creator (DALL-E 3 ì›¹íˆ°) â”€â”€
            if not success and not self._bing_failed and bing_consecutive_fail < 3:
                webtoon_prompt = self._build_webtoon_prompt(raw_prompt, group["texts"], mood)
                bing = self._get_bing_creator()
                if bing:
                    success = bing.generate_image(webtoon_prompt, image_path)
                    if success:
                        bing_consecutive_fail = 0
                        print(f"    âœ… [{gi+1}/{len(scene_groups)}] ğŸ¨ Bing: {raw_prompt[:45] or webtoon_prompt[80:125]}...")
                    else:
                        bing_consecutive_fail += 1
                        if bing_consecutive_fail >= 3:
                            print(f"    âš ï¸  Bing 3íšŒ ì—°ì† ì‹¤íŒ¨ â†’ í´ë°± ì „í™˜")
                            self._bing_failed = True

            # â”€â”€ 3ìˆœìœ„: ì§ì „ ì„±ê³µ ì´ë¯¸ì§€ ì¬ì‚¬ìš© (Pexels ìŠ¤í†¡ì‚¬ì§„ â†’ í™”í’ ê¹¨ì§ ë°©ì§€) â”€â”€
            if not success and last_success_path and os.path.exists(last_success_path):
                import shutil as _shutil
                _shutil.copy2(last_success_path, image_path)
                success = True
                print(f"    â™»ï¸  [{gi+1}/{len(scene_groups)}] ì§ì „ ì´ë¯¸ì§€ ì¬ì‚¬ìš© (í™”í’ ì¼ê´€ì„± ìœ ì§€)")

            if success:
                self._gen_count += 1
                last_success_path = image_path  # â˜… ì„±ê³µí•œ ì´ë¯¸ì§€ ê²½ë¡œ ê¸°ì–µ
                results.append({
                    "chunk_idx": group["start_idx"],
                    "end_idx": group["end_idx"],
                    "image_path": image_path,
                    "prompt": raw_prompt or "auto",
                })
            else:
                print(f"    âš ï¸  [{gi+1}] ì´ë¯¸ì§€ ì‹¤íŒ¨ â†’ ê·¸ë¼ë°ì´ì…˜ í´ë°±")
                results.append({
                    "chunk_idx": group["start_idx"],
                    "end_idx": group["end_idx"],
                    "image_path": None,
                    "prompt": raw_prompt or "auto",
                })

            # ì†ë„ ì¡°ì ˆ (Replicate 429 ë°©ì§€: 3ì´ˆ ë”œë ˆì´)
            if gi < len(scene_groups) - 1:
                time.sleep(3)

        # Bing ë¸Œë¼ìš°ì € ì¢…ë£Œ
        if self._bing_creator:
            try:
                self._bing_creator.close()
            except Exception:
                pass

        ok_count = sum(1 for r in results if r["image_path"])
        print(f"  âœ… ì¥ë©´ ì´ë¯¸ì§€ ì™„ë£Œ: {ok_count}/{len(scene_groups)}ì¥ ìƒì„±")

        # â˜… v10.0: Kling AI â€” ì²«/ë§ˆì§€ë§‰ ì¥ë©´ë§Œ image-to-video ë³€í™˜
        if self._kling.available and results:
            kling_targets = []
            if results[0].get("image_path"):
                kling_targets.append((0, results[0]))
            if len(results) > 1 and results[-1].get("image_path"):
                kling_targets.append((len(results) - 1, results[-1]))

            for idx, r in kling_targets:
                img_path = r["image_path"]
                vid_path = img_path.rsplit(".", 1)[0] + "_kling.mp4"
                prompt_text = r.get("prompt", "cinematic slow motion")
                print(f"  ğŸ¬ Kling AI ë™ì˜ìƒ ë³€í™˜ [{idx+1}/{len(results)}]...")
                ok = self._kling.generate_video(img_path, prompt_text, vid_path)
                if ok:
                    r["kling_video"] = vid_path
                else:
                    print(f"    âš ï¸  Kling ì‹¤íŒ¨ â†’ Bing ì´ë¯¸ì§€ ìœ ì§€ (í´ë°±)")

        return results

    # â”€â”€ ë¬¸ì¥ ê·¸ë£¨í•‘ â”€â”€
    def _group_sentences(self, script_lines: list) -> list[dict]:
        """2~3ë¬¸ì¥ì”© ê·¸ë£¨í•‘ â†’ ì¥ë©´ ë‹¨ìœ„ë¡œ ì´ë¯¸ì§€ 1ì¥"""
        groups = []
        i = 0
        while i < len(script_lines):
            if script_lines[i].get("highlight"):
                groups.append({
                    "start_idx": i, "end_idx": i,
                    "texts": [script_lines[i]["text"]],
                    "image_prompt": script_lines[i].get("image_prompt", ""),
                })
                i += 1
            else:
                end = min(i + 3, len(script_lines))
                for j in range(i + 1, end):
                    if script_lines[j].get("highlight"):
                        end = j
                        break
                texts = [script_lines[k]["text"] for k in range(i, end)]
                img_prompt = script_lines[i].get("image_prompt", "")
                groups.append({
                    "start_idx": i, "end_idx": end - 1,
                    "texts": texts, "image_prompt": img_prompt,
                })
                i = end
        return groups

    # â”€â”€ ì›¹íˆ° í”„ë¡¬í”„íŠ¸ ë¹Œë“œ â”€â”€
    # â”€â”€ ìºë¦­í„° ì¼ê´€ì„±: ì²« ì¥ë©´ì—ì„œ ì„¤ì •í•œ ìºë¦­í„° ë¬˜ì‚¬ë¥¼ ì´í›„ì—ë„ ìœ ì§€ â”€â”€
    _character_desc = ""  # í´ë˜ìŠ¤ ë ˆë²¨ ìºë¦­í„° ê¸°ì–µ

    def _build_webtoon_prompt(self, image_prompt: str, texts: list[str],
                               mood: str) -> str:
        """image_prompt â†’ Bê¸‰ í•œêµ­ ì›¹íˆ° ìŠ¤íƒ€ì¼ FLUX í”„ë¡¬í”„íŠ¸ ë¹Œë“œ
        â˜… ìºë¦­í„° ì¼ê´€ì„±: ì²« ì¥ë©´ ìºë¦­í„° ë¬˜ì‚¬ë¥¼ ì´í›„ ì¥ë©´ì— ìë™ ì‚½ì…
        """
        mood_style = self.MOOD_STYLE.get(mood, "")
        # â˜… ìºë¦­í„° ìœ ì§€ ì ‘ë¯¸ì‚¬
        char_suffix = ""
        if self._character_desc:
            char_suffix = f", same character as before: {self._character_desc}"

        if image_prompt:
            # image_prompt â†’ ì˜ì–´ í™•ì¸/ë³€í™˜ (v10: Geminiê°€ ì˜ì–´ë¡œ ì¶œë ¥í•˜ë©´ ë°”ë¡œ í†µê³¼)
            en_prompt = self._auto_en_prompt_from_kr(image_prompt, mood)
            full = f"{self.WEBTOON_PREFIX}{mood_style}{en_prompt}{char_suffix}"
            # ì²« ì¥ë©´ì´ë©´ ìºë¦­í„° ë¬˜ì‚¬ ê¸°ì–µ
            if not self._character_desc and en_prompt:
                self._character_desc = en_prompt[:120]
            return full

        # í•œê¸€ í…ìŠ¤íŠ¸ â†’ ìë™ ì˜ì–´ ë³€í™˜
        en_prompt = self._auto_en_prompt(texts, mood)
        full = f"{self.WEBTOON_PREFIX}{mood_style}{en_prompt}{char_suffix}"
        if not self._character_desc and en_prompt:
            self._character_desc = en_prompt[:120]
        return full

    def _build_mj_prompt_for_goapi(self, image_prompt: str,
                                     texts: list[str], mood: str) -> str:
        """Midjourney ìµœì í™” í”„ë¡¬í”„íŠ¸ ë¹Œë“œ (GoAPIìš©).

        â˜… MidjourneyëŠ” í”„ë¡¬í”„íŠ¸ê°€ ì§§ì„ìˆ˜ë¡ ì˜ ë™ì‘í•¨ (200ì ì´ë‚´ ê¶Œì¥).
        â˜… --sref/--cref íŒŒë¼ë¯¸í„°ëŠ” goapi_midjourney.pyì—ì„œ ê°€ì¥ ë§ˆì§€ë§‰ì— ë¶™ì„.
        """
        mood_style = self.MOOD_STYLE.get(mood, "")
        if image_prompt:
            en_prompt = self._auto_en_prompt_from_kr(image_prompt, mood)
        else:
            en_prompt = self._auto_en_prompt(texts, mood)

        prefix = ("Korean B-grade webtoon manhwa style, bold outlines, "
                   "exaggerated comedic expressions")
        prompt = f"{prefix}, {mood_style}{en_prompt}"

        # Midjourney í”„ë¡¬í”„íŠ¸ 200ì ì œí•œ (íŒŒë¼ë¯¸í„° ì”¹í˜ ë°©ì§€)
        if len(prompt) > 200:
            prompt = prompt[:200].rstrip(", ")

        return prompt

    def _auto_en_prompt_from_kr(self, kr_prompt: str, mood: str) -> str:
        """í•œêµ­ì–´ image_promptë¥¼ ì˜ì–´ë¡œ ë³€í™˜ (Gemini ë²ˆì—­ â†’ í‚¤ì›Œë“œ í´ë°±)
        â˜… v10.0: Geminiê°€ ì§ì ‘ ì˜ì–´ë¡œ ì¶œë ¥í•˜ëŠ” ê²½ìš° â†’ ë°”ë¡œ ë°˜í™˜
        """
        import re
        # â˜… í•œê¸€ì´ ì—†ìœ¼ë©´ ì´ë¯¸ ì˜ì–´ â†’ ê·¸ëŒ€ë¡œ ë°˜í™˜ (ìˆ«ì/íŠ¹ìˆ˜ë¬¸ì í¬í•¨ OK)
        if not re.search(r'[ê°€-í£]', kr_prompt):
            return kr_prompt
        # â˜… Gemini Flashë¡œ ì§ì ‘ ë²ˆì—­ (ë” ì •í™•í•œ ì¥ë©´ ë¬˜ì‚¬)
        try:
            import google.generativeai as _genai
            _m = _genai.GenerativeModel("gemini-2.0-flash")
            resp = _m.generate_content(
                f"Translate this Korean image description to English for an AI image generator. "
                f"Keep it as a visual scene description, comma separated keywords. "
                f"Add 'Korean cultural setting' if relevant. Max 80 words. "
                f"Output ONLY the English translation, nothing else.\n\n{kr_prompt}",
                generation_config=_genai.GenerationConfig(
                    temperature=0.2, max_output_tokens=200,
                ),
            )
            if resp.text and len(resp.text.strip()) > 10:
                en = resp.text.strip().replace('"', '').replace("'", "")
                return en
        except Exception:
            pass
        # í´ë°±: í‚¤ì›Œë“œ ë§¤í•‘
        return self._auto_en_prompt([kr_prompt], mood)

    def _auto_en_prompt(self, texts: list[str], mood: str) -> str:
        """í•œê¸€ í…ìŠ¤íŠ¸ â†’ ì˜ì–´ ì¥ë©´ ë¬˜ì‚¬ ìë™ ìƒì„± (Bê¸‰ ì›¹íˆ° ê³¼ì¥ ìŠ¤íƒ€ì¼)"""
        combined = " ".join(texts)
        kr_en = {
            "ì‹œì–´ë¨¸ë‹ˆ": "angry Korean mother-in-law with exaggerated furious expression",
            "ë‚¨í¸": "young Korean husband with comically shocked face",
            "ì•„ë‚´": "young Korean wife with dramatic expression",
            "ê²°í˜¼": "wedding scene with over-the-top emotions",
            "ì´í˜¼": "divorce papers flying dramatically",
            "ì‹ í˜¼ì§‘": "cozy newlywed apartment interior",
            "ë¹„ë²ˆ": "digital door lock keypad glowing ominously",
            "í˜„ê´€ë¬¸": "apartment front door opening dramatically",
            "ëƒ‰ì¥ê³ ": "refrigerator wide open with food spilling out",
            "ê²½ì°°": "police officer with stern comedic expression at door",
            "ì‚¬ê¸°": "scam victim with jaw dropping to the floor",
            "íƒë°°": "person opening delivery package with extreme surprise",
            "ì—ì–´íŒŸ": "wireless earbuds case close-up",
            "ì½©ë‚˜ë¬¼": "pile of fresh bean sprouts",
            "ì¤‘ê³ ê±°ë˜": "person staring at phone screen in disbelief",
            "ì „í™”": "person holding phone with veins popping from anger",
            "CCTV": "security camera footage on monitor screen",
            "ë„ì–´ë½": "smart digital door lock close-up",
            "ì§€ë¬¸": "fingerprint scanner with blue glow",
            "ì§ì¥": "office scene with comedic drama",
            "ìƒì‚¬": "angry boss character with exaggerated expression",
            "ì‹ ì…": "nervous new employee sweating comically",
            "íšŒì‹": "Korean company dinner party scene",
            "í‡´ì‚¬": "person throwing resignation letter dramatically",
            "ì›”ê¸‰": "paycheck with shocking amount",
            "í•™êµ": "Korean school classroom scene",
            "ì„ ìƒë‹˜": "teacher with dramatic expression",
            "í¸ì˜ì ": "convenience store interior late at night",
            "ëŒ€ë¦¬": "stressed office worker with comedic exhaustion",
            "ì¹´í˜": "trendy Korean cafe interior",
        }
        parts = []
        for kr, en in kr_en.items():
            if kr in combined:
                parts.append(en)
        if not parts:
            parts = ["dramatic Korean webtoon scene with exaggerated comedic expression"]
        return ", ".join(parts[:4])

    # â”€â”€ Replicate FLUX-schnell â”€â”€
    def _generate_replicate(self, prompt: str, save_path: str) -> bool:
        """Replicate FLUX-schnell ì§ì ‘ REST API í˜¸ì¶œ (SDK ìš°íšŒ)"""
        try:
            headers = {
                "Authorization": f"Token {self.replicate_token}",
                "Content-Type": "application/json",
            }

            payload = {
                "input": {
                    "prompt": prompt,
                    "go_fast": True,
                    "num_outputs": 1,
                    "aspect_ratio": "9:16",
                    "output_format": "webp",
                    "output_quality": 90,
                    "num_inference_steps": 4,
                }
            }

            api_url = "https://api.replicate.com/v1/models/black-forest-labs/flux-schnell/predictions"

            # 429 ì¬ì‹œë„ (exponential backoff: 5ì´ˆ, 10ì´ˆ, 20ì´ˆ)
            pred_resp = None
            for retry in range(4):
                pred_resp = requests.post(
                    api_url, headers=headers, json=payload, timeout=30
                )
                if pred_resp.status_code == 429:
                    wait = 5 * (2 ** retry)  # 5, 10, 20, 40ì´ˆ
                    print(f"    â³ Replicate 429 â†’ {wait}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({retry+1}/4)")
                    time.sleep(wait)
                    continue
                break  # 429ê°€ ì•„ë‹ˆë©´ ë£¨í”„ íƒˆì¶œ

            if pred_resp.status_code == 402:
                print(f"    âš ï¸  Replicate í¬ë ˆë”§ ë¶€ì¡±")
                return False
            if pred_resp.status_code == 429:
                print(f"    âš ï¸  Replicate 429 ê³„ì† ë°œìƒ (4íšŒ ì¬ì‹œë„ ì‹¤íŒ¨)")
                return False
            if pred_resp.status_code not in (200, 201):
                print(f"    âš ï¸  Replicate API: {pred_resp.status_code}")
                return False

            pred = pred_resp.json()
            get_url = pred.get("urls", {}).get("get", "")
            if not get_url:
                return False

            # 2. ê²°ê³¼ í´ë§ (ìµœëŒ€ 60ì´ˆ)
            for _ in range(30):
                time.sleep(2)
                result = requests.get(get_url, headers=headers, timeout=10).json()
                status = result.get("status", "")

                if status == "succeeded":
                    outputs = result.get("output", [])
                    if outputs:
                        img_url = outputs[0]
                        img_resp = requests.get(img_url, timeout=60)
                        if img_resp.status_code == 200 and len(img_resp.content) > 5000:
                            from PIL import Image
                            from io import BytesIO
                            img = Image.open(BytesIO(img_resp.content)).convert("RGB")
                            img = img.resize((1080, 1920), Image.LANCZOS)
                            img.save(save_path, "WEBP", quality=92)
                            return True
                    return False
                elif status == "failed":
                    err = result.get("error", "unknown")
                    print(f"    âš ï¸  Replicate ìƒì„± ì‹¤íŒ¨: {str(err)[:80]}")
                    return False

            print(f"    âš ï¸  Replicate íƒ€ì„ì•„ì›ƒ")
            return False

        except Exception as e:
            err_str = str(e)
            if "Unauthenticated" in err_str or "401" in err_str:
                print(f"    âš ï¸  Replicate ì¸ì¦ ì‹¤íŒ¨")
            else:
                print(f"    âš ï¸  Replicate ì‹¤íŒ¨: {err_str[:80]}")
        return False

    # â”€â”€ Pexels í´ë°± â”€â”€
    def _prompt_to_pexels_query(self, image_prompt: str, texts: list[str],
                                 mood: str) -> str:
        """image_prompt â†’ Pexels ê²€ìƒ‰ì–´ ë³€í™˜"""
        if image_prompt:
            stop_words = {
                "a", "an", "the", "with", "and", "of", "in", "on", "at", "to",
                "style", "cinematic", "dramatic", "lighting", "close-up", "shot",
                "atmosphere", "composition", "vertical", "4k", "photorealistic",
                "modern", "korean", "scene", "showing", "from",
            }
            words = image_prompt.lower().replace(",", " ").split()
            keywords = [w for w in words if w not in stop_words and len(w) > 2]
            if keywords:
                return " ".join(keywords[:4])

        combined = " ".join(texts)
        en_parts = []
        for kr, en in self.PEXELS_KEYWORD_MAP.items():
            if kr in combined:
                en_parts.append(en)
        if en_parts:
            return " ".join(en_parts[:3])

        import random
        mood_keys = self.MOOD_PEXELS.get(mood, ["cinematic texture", "abstract dark"])
        return random.choice(mood_keys)

    def _search_pexels(self, query: str, save_path: str) -> bool:
        """Pexelsì—ì„œ ì„¸ë¡œ ì´ë¯¸ì§€ ê²€ìƒ‰ + ë‹¤ìš´ë¡œë“œ"""
        try:
            headers = {"Authorization": self.pexels_key}
            url = (f"https://api.pexels.com/v1/search"
                   f"?query={requests.utils.quote(query)}"
                   f"&per_page=15&orientation=portrait")
            resp = requests.get(url, headers=headers, timeout=15)
            if resp.status_code != 200:
                return False

            photos = resp.json().get("photos", [])
            if not photos:
                short_query = " ".join(query.split()[:2])
                url2 = (f"https://api.pexels.com/v1/search"
                        f"?query={requests.utils.quote(short_query)}"
                        f"&per_page=15&orientation=portrait")
                resp2 = requests.get(url2, headers=headers, timeout=15)
                if resp2.status_code == 200:
                    photos = resp2.json().get("photos", [])
                if not photos:
                    return False

            available = [p for p in photos if p["id"] not in self._used_photo_ids]
            if not available:
                available = photos

            import random
            chosen = random.choice(available[:5])
            self._used_photo_ids.add(chosen["id"])

            img_url = chosen["src"].get("portrait", chosen["src"].get("large2x", ""))
            if not img_url:
                return False

            img_resp = requests.get(img_url, timeout=30)
            if img_resp.status_code == 200 and len(img_resp.content) > 5000:
                from PIL import Image
                from io import BytesIO
                img = Image.open(BytesIO(img_resp.content)).convert("RGB")
                img = img.resize((1080, 1920), Image.LANCZOS)
                img.save(save_path, quality=92)
                return True
        except Exception as e:
            print(f"    âš ï¸  Pexels ì‹¤íŒ¨: {e}")
        return False


# ============================================================
# ğŸ¬ ì˜ìƒ ì†ŒìŠ¤ ìë™ í¸ì§‘ê¸° (yt-dlp + Gemini Vision â†’ ìˆì¸  í¸ì§‘)
# ============================================================
class VideoAutoEditor:
    """
    v5.0: Reddit/YouTube URL â†’ í•˜ì´ë¼ì´íŠ¸ ì¶”ì¶œ â†’ 9:16 ìˆì¸  ìë™ ë³€í™˜
    ë¹„ìš©: $0 (Gemini 2.0 Flash ë¬´ë£Œ ì¿¼í„° + yt-dlp + FFmpeg)

    ì‚¬ìš©:
      python main.py --url "https://www.reddit.com/r/.../comments/..." --video-edit
      python main.py --url "https://www.youtube.com/watch?v=..." --video-edit
    """

    def __init__(self, config):
        self.config = config
        self.download_dir = os.path.join(config.output_dir, "_video_temp")
        os.makedirs(self.download_dir, exist_ok=True)

        # yt-dlp ê²½ë¡œ ìë™ íƒìƒ‰ (PATHì— ì—†ì„ ë•Œ Scripts í´ë”ì—ì„œ ì°¾ê¸°)
        self.ytdlp_cmd = self._find_ytdlp()

        # Gemini Vision ëª¨ë¸ (ì˜ìƒ ë¶„ì„ìš© â€” ë¬´ë£Œ)
        api_key = config.google_api_key
        if not api_key:
            raise ValueError("GOOGLE_API_KEY í•„ìš” (ì˜ìƒ ë¶„ì„ìš©)")
        genai_flash.configure(api_key=api_key)
        self.model = genai_flash.GenerativeModel("gemini-2.0-flash")

    @staticmethod
    def _find_ytdlp() -> list:
        """yt-dlp ì‹¤í–‰ ê²½ë¡œë¥¼ ìë™ íƒìƒ‰"""
        import shutil
        # 1ì°¨: PATHì—ì„œ ì°¾ê¸°
        if shutil.which("yt-dlp"):
            return ["yt-dlp"]
        # 2ì°¨: Python Scripts í´ë”
        scripts_dir = os.path.join(os.path.dirname(sys.executable), "Scripts")
        ytdlp_exe = os.path.join(scripts_dir, "yt-dlp.exe")
        if os.path.exists(ytdlp_exe):
            return [ytdlp_exe]
        # 3ì°¨: python -m yt_dlp
        return [sys.executable, "-m", "yt_dlp"]

    # ê²€ì¦ëœ ëŒ€ë°• ì˜ìƒë§Œ ì†Œì‹± (10ë§Œë·° ë¯¸ë§Œ ì°¨ë‹¨)
    MIN_VIEW_COUNT = 100_000

    def download_video(self, url: str) -> Optional[str]:
        """yt-dlpë¡œ ê²€ì¦ëœ ë°”ì´ëŸ´ ì˜ìƒë§Œ ë‹¤ìš´ë¡œë“œ (view_count >= 100K í•„í„°)"""
        output_template = os.path.join(self.download_dir, "%(id)s.%(ext)s")
        cmd = self.ytdlp_cmd + [
            "-f", "bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best",
            "--merge-output-format", "mp4",
            "-o", output_template,
            "--no-playlist",
            "--max-filesize", "500M",
            # â”€â”€ 10ë§Œë·° ì´ìƒë§Œ ë‹¤ìš´ë¡œë“œ (ê²€ì¦ëœ ëŒ€ë°• ì˜ìƒ) â”€â”€
            "--match-filter", f"view_count >= {self.MIN_VIEW_COUNT}",
            url,
        ]
        try:
            print(f"\n  â¬‡ï¸  ì˜ìƒ ë‹¤ìš´ë¡œë“œ: {url[:60]}...")
            print(f"     ğŸ”¥ ì¡°ê±´: ì¡°íšŒìˆ˜ {self.MIN_VIEW_COUNT:,}íšŒ ì´ìƒë§Œ í—ˆìš©")
            result = subprocess.run(
                cmd, capture_output=True, text=True, timeout=300,
                encoding="utf-8", errors="replace",
            )
            if result.returncode != 0:
                stderr = result.stderr[:300]
                if "filter" in stderr.lower() or "not pass" in stderr.lower():
                    print(f"  ğŸš« ì¡°íšŒìˆ˜ {self.MIN_VIEW_COUNT:,}íšŒ ë¯¸ë‹¬ â†’ ì“°ë ˆê¸° ì˜ìƒ ì°¨ë‹¨ë¨")
                else:
                    print(f"  âŒ yt-dlp ì‹¤íŒ¨: {stderr[:200]}")
                return None

            # ê°€ì¥ ìµœê·¼ mp4 íŒŒì¼ ì°¾ê¸°
            files = [
                os.path.join(self.download_dir, f)
                for f in os.listdir(self.download_dir)
                if f.endswith(".mp4")
            ]
            if not files:
                print("  âŒ ë‹¤ìš´ë¡œë“œëœ MP4 ì—†ìŒ")
                return None

            latest = max(files, key=os.path.getctime)
            size_mb = os.path.getsize(latest) / (1024 * 1024)
            print(f"  âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {os.path.basename(latest)} ({size_mb:.1f}MB)")
            return latest

        except subprocess.TimeoutExpired:
            print("  â° ë‹¤ìš´ë¡œë“œ íƒ€ì„ì•„ì›ƒ (5ë¶„ ì´ˆê³¼)")
            return None
        except FileNotFoundError:
            print("  âŒ yt-dlpê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤!")
            print("     pip install yt-dlp")
            return None
        except Exception as e:
            print(f"  âŒ ë‹¤ìš´ë¡œë“œ ì—ëŸ¬: {e}")
            return None

    def get_highlights(self, video_path: str) -> Optional[dict]:
        """Gemini Visionìœ¼ë¡œ ì˜ìƒ ë¶„ì„ â†’ í•˜ì´ë¼ì´íŠ¸ êµ¬ê°„ ì¶”ì¶œ"""
        print("  ğŸ‘€ AI ì˜ìƒ ë¶„ì„: ë„íŒŒë¯¼ êµ¬ê°„ íƒìƒ‰ ì¤‘...")
        try:
            video_file = genai_flash.upload_file(path=video_path)

            # ì—…ë¡œë“œ ì²˜ë¦¬ ëŒ€ê¸°
            wait_count = 0
            while video_file.state.name == "PROCESSING":
                time.sleep(3)
                video_file = genai_flash.get_file(video_file.name)
                wait_count += 1
                if wait_count > 60:  # 3ë¶„ íƒ€ì„ì•„ì›ƒ
                    print("  â° ì˜ìƒ ì²˜ë¦¬ íƒ€ì„ì•„ì›ƒ")
                    return None

            if video_file.state.name == "FAILED":
                print(f"  âŒ Gemini ì˜ìƒ ì²˜ë¦¬ ì‹¤íŒ¨")
                return None

            prompt = """ì´ ì˜ìƒì—ì„œ ìœ íŠœë¸Œ ìˆì¸ ë¡œ ë§Œë“¤ê¸° ê°€ì¥ ì¢‹ì€ êµ¬ê°„ì„ ì°¾ê³ ,
ê·¸ êµ¬ê°„ì— ë®ì„ í•œêµ­ì–´ ë‚˜ë ˆì´ì…˜ ëŒ€ë³¸ë„ ì¨ì¤˜.

ì¡°ê±´:
- ìµœëŒ€ 60ì´ˆ ì´ë‚´
- ê°€ì¥ ì¶©ê²©ì ì´ê±°ë‚˜, ì›ƒê¸°ê±°ë‚˜, ê°ë™ì ì¸ êµ¬ê°„
- ì‹œì‘/ë íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ
- ë‚˜ë ˆì´ì…˜ì€ í•œêµ­ì–´, ìœ íŠœë¸Œ ìˆì¸  ë§íˆ¬ (êµ¬ì–´ì²´, ë°˜ë§OK, í…ì…˜ ë†’ê²Œ)
- ì²« ë¬¸ì¥ì€ ë°˜ë“œì‹œ "ì´ê±° ì‹¤í™”ëƒ" / "ë¯¸ì³¤ë‹¤ ì§„ì§œ" ê°™ì€ í›„í‚¹ ë©˜íŠ¸
- ê°ì • ì§€ë¬¸ì„ ë°˜ë“œì‹œ í¬í•¨í•´: (ë†€ëŒ), (ì¶©ê²©), (ì†Œë¦„), (ì†ì‚­ì„), (ê°•ì¡°), (ì›ƒìŒ) ë“±
  ì˜ˆ: "(ë†€ëŒ) ì´ê±° ì‹¤í™”ëƒ?! ì´ ì‚¬ëŒì´ ë°©ê¸ˆ í•œ ì§“ ì¢€ ë´."

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•´:
{"start_sec": 0, "end_sec": 60, "reason": "ì´ìœ ë¥¼ í•œì¤„ë¡œ", "narration": "ì—¬ê¸°ì— ë‚˜ë ˆì´ì…˜ ì „ì²´ ëŒ€ë³¸"}"""

            response = self.model.generate_content(
                [video_file, prompt],
                generation_config=genai_flash.GenerationConfig(
                    temperature=0.3,
                    response_mime_type="application/json",
                ),
            )

            result = json.loads(response.text)
            start = result.get("start_sec", 0)
            end = result.get("end_sec", 60)
            reason = result.get("reason", "")
            narration = result.get("narration", "")

            # ìœ íš¨ì„± ì²´í¬
            if end <= start:
                end = start + 60
            if end - start > 60:
                end = start + 60

            print(f"  ğŸ¯ í•˜ì´ë¼ì´íŠ¸: {start}ì´ˆ ~ {end}ì´ˆ ({end - start}ì´ˆ)")
            if reason:
                print(f"     ì´ìœ : {reason}")
            if narration:
                print(f"  ğŸ“ ë‚˜ë ˆì´ì…˜: {narration[:50]}...")

            return {"start_sec": start, "end_sec": end, "reason": reason, "narration": narration}

        except Exception as e:
            print(f"  âŒ ì˜ìƒ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None

    # â”€â”€ ëŒ€ë³¸ ì§€ë¬¸(stage direction) â†’ SSML ë³€í™˜ ë§¤í•‘ â”€â”€
    # (ë†€ëŒ) â†’ ë³¼ë¥¨ UP + ì•½ê°„ ë” ë¹ ë¥´ê²Œ
    # (ì†ì‚­ì„) â†’ ë³¼ë¥¨ DOWN + ëŠë¦¬ê²Œ
    # (ê°•ì¡°) â†’ ë³¼ë¥¨ UP
    STAGE_DIRECTION_MAP = {
        "(ë†€ëŒ)":   ("<prosody volume='+30%' rate='+10%'>",  "</prosody>"),
        "(ì¶©ê²©)":   ("<prosody volume='+30%' rate='+10%'>",  "</prosody>"),
        "(ì†Œë¦„)":   ("<prosody volume='+20%' rate='-5%'>",   "</prosody>"),
        "(ì†ì‚­ì„)": ("<prosody volume='-20%' rate='-10%'>",  "</prosody>"),
        "(ê°•ì¡°)":   ("<prosody volume='+25%'>",              "</prosody>"),
        "(ë¶„ë…¸)":   ("<prosody volume='+35%' rate='+15%'>",  "</prosody>"),
        "(ìŠ¬í””)":   ("<prosody volume='-10%' rate='-15%'>",  "</prosody>"),
        "(ì›ƒìŒ)":   ("<prosody volume='+15%' rate='+5%'>",   "</prosody>"),
    }

    def _convert_stage_directions_to_ssml(self, text: str) -> str:
        """ëŒ€ë³¸ ì§€ë¬¸ íƒœê·¸ë¥¼ SSML prosodyë¡œ ë³€í™˜.
        ì˜ˆ: 'ì´ê±° (ë†€ëŒ) ì‹¤í™”ëƒ?!' â†’ SSMLë¡œ í•´ë‹¹ ë¶€ë¶„ë§Œ ë³¼ë¥¨/ì†ë„ ì¡°ì ˆ
        """
        result = text
        for tag, (open_ssml, close_ssml) in self.STAGE_DIRECTION_MAP.items():
            if tag in result:
                # ì§€ë¬¸ íƒœê·¸ ì œê±°í•˜ê³ , í•´ë‹¹ ì§€ë¬¸ ë’¤ì˜ ë¬¸ì¥ ë(. ! ? ë˜ëŠ” ë‹¤ìŒ ì§€ë¬¸)ê¹Œì§€ë¥¼ SSMLë¡œ ê°ìŒˆ
                parts = result.split(tag)
                converted = parts[0]
                for part in parts[1:]:
                    # ë‹¤ìŒ ë¬¸ì¥ ë ì°¾ê¸°
                    end_idx = -1
                    for punct in [".", "!", "?", "\n"]:
                        idx = part.find(punct)
                        if idx != -1 and (end_idx == -1 or idx < end_idx):
                            end_idx = idx + 1

                    if end_idx > 0:
                        converted += open_ssml + part[:end_idx] + close_ssml + part[end_idx:]
                    else:
                        converted += open_ssml + part + close_ssml
                result = converted
        return result

    async def _generate_narration_tts(self, text: str, output_mp3: str) -> Optional[str]:
        """
        edge-tts SSML ë‚˜ë ˆì´ì…˜ (í‹±í†¡ì»¤ í†¤, ë¬´ë£Œ)
        - ìŒì„±: ko-KR-SunHiNeural ê°•ì œ (ì—¬ì„±, ë°ì€ í…ì…˜)
        - ì†ë„: +15% (ë¹ ë¥´ê²Œ, ìˆì¸  ìµœì )
        - í”¼ì¹˜: +2Hz (ë“¤ëœ¬ í†¤, ë„íŒŒë¯¼)
        - ì§€ë¬¸ ì²˜ë¦¬: (ë†€ëŒ)â†’ë³¼ë¥¨UP, (ì†ì‚­ì„)â†’ë³¼ë¥¨DOWN ë“± SSML ë³€í™˜
        """
        if not text or not text.strip():
            return None

        print(f"  ğŸ—£ï¸  AI ë‚˜ë ˆì´ì…˜ TTS ìƒì„± ì¤‘... ({len(text)}ì)")
        try:
            # â”€â”€ ì§€ë¬¸ íƒœê·¸ë¥¼ SSMLë¡œ ë³€í™˜ â”€â”€
            ssml_body = self._convert_stage_directions_to_ssml(text)

            # â”€â”€ SSML ë˜í•‘: rate +15%, pitch +2Hz (í‹±í†¡ì»¤ í†¤) â”€â”€
            ssml_text = (
                "<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='ko-KR'>"
                "<prosody rate='+15%' pitch='+2Hz'>"
                f"{ssml_body}"
                "</prosody>"
                "</speak>"
            )

            # â”€â”€ SunHi ê°•ì œ ê³ ì • (config ë¬´ì‹œ) â”€â”€
            voice = "ko-KR-SunHiNeural"
            communicate = edge_tts.Communicate(ssml_text, voice)
            await communicate.save(output_mp3)

            if os.path.exists(output_mp3) and os.path.getsize(output_mp3) > 1000:
                size_kb = os.path.getsize(output_mp3) // 1024
                print(f"  âœ… ë‚˜ë ˆì´ì…˜ TTS ì™„ë£Œ: {size_kb}KB (SunHi +15% +2Hz)")
                return output_mp3
            else:
                print("  âš ï¸  TTS ì¶œë ¥ ë¹„ì •ìƒ")
                return None
        except Exception as e:
            print(f"  âš ï¸  ë‚˜ë ˆì´ì…˜ TTS ì‹¤íŒ¨: {e}")
            return None

    def edit_to_shorts(self, input_path: str, start_sec: int,
                       end_sec: int, output_path: str,
                       tts_path: Optional[str] = None) -> Optional[str]:
        """
        FFmpeg í”„ë¡œê¸‰ 9:16 ìˆì¸  í¸ì§‘ (êµ¬ë…ì 1ë§Œ+ ì±„ë„ í€„ë¦¬í‹°)
        - 3ë‹¨ ë ˆì´ì•„ì›ƒ: ë¸”ëŸ¬ ë°°ê²½(ì–´ë‘¡ê²Œ) + ì¤‘ì•™ ì›ë³¸ + ì»¬ëŸ¬ ê·¸ë ˆì´ë”©
        - TTS ë‚˜ë ˆì´ì…˜ ë¯¹ì‹±: ì›ë³¸ 15% BGM + TTS 160% + loudnorm ë§ˆìŠ¤í„°ë§
        - ì¸ì½”ë”©: CRF 20 (ê³ í™”ì§ˆ) + AAC 256k + faststart
        """
        has_tts = tts_path and os.path.exists(tts_path)
        mode = "ğŸ™ï¸ ë‚˜ë ˆì´ì…˜ ë¯¹ì‹±" if has_tts else "ğŸ”Š ì›ë³¸ ì˜¤ë””ì˜¤"
        print(f"  âœ‚ï¸  í”„ë¡œê¸‰ ìˆì¸  í¸ì§‘: {start_sec}s â†’ {end_sec}s ({mode})")

        ffmpeg_path = _get_ffmpeg_path()

        # â”€â”€ ê³µí†µ ë¹„ë””ì˜¤ í•„í„°: 3ë‹¨ ë ˆì´ì•„ì›ƒ + ì‹œë„¤ë§ˆí‹± ì»¬ëŸ¬ â”€â”€
        # Layer 1 (bg): í™•ëŒ€ + ë¸”ëŸ¬(25px) + ì–´ë‘¡ê²Œ(brightness -0.15)
        # Layer 2 (fg): ì›ë³¸ ë¹„ìœ¨ ìœ ì§€ + ì¤‘ì•™ ë°°ì¹˜ + ì–‡ì€ ë¹„ë„¤íŒ…
        # Layer 3: eqë¡œ ë¯¸ì„¸ ì»¬ëŸ¬ ê·¸ë ˆì´ë”© (ëŒ€ë¹„ +10%, ì±„ë„ +15%)
        video_filter_base = (
            f"[0:v]trim=start={start_sec}:end={end_sec},setpts=PTS-STARTPTS[v0];"
            f"[v0]split[bg_src][fg_src];"
            # ë°°ê²½: ê½‰ ì±„ì›€ + ê°•í•œ ë¸”ëŸ¬ + ì–´ë‘¡ê²Œ
            f"[bg_src]scale=1080:1920:force_original_aspect_ratio=increase,"
            f"crop=1080:1920,boxblur=25:15,"
            f"eq=brightness=-0.15:contrast=0.9[bg_dark];"
            # ì „ê²½: ë¹„ìœ¨ ìœ ì§€ + ì¤‘ì•™ íŒ¨ë”©
            f"[fg_src]scale=1080:-2:force_original_aspect_ratio=decrease,"
            f"scale='min(1080,iw)':'min(1440,ih)'[fg_scaled];"
            # í•©ì„± + ì»¬ëŸ¬ ê·¸ë ˆì´ë”© (ëŒ€ë¹„â†‘ ì±„ë„â†‘)
            f"[bg_dark][fg_scaled]overlay=(W-w)/2:(H-h)/2,"
            f"eq=contrast=1.1:saturation=1.15"
        )

        if has_tts:
            # â”€â”€ TTS ë‚˜ë ˆì´ì…˜ + ì›ë³¸ BGM ë¯¹ì‹± + loudnorm ë§ˆìŠ¤í„°ë§ â”€â”€
            filter_complex = (
                f"{video_filter_base}[video];"
                # ì˜¤ë””ì˜¤: ì›ë³¸ 15%(BGM) + TTS 160%(ì£¼ë„) â†’ loudnorm(-14 LUFS)
                f"[0:a]atrim=start={start_sec}:end={end_sec},"
                f"asetpts=PTS-STARTPTS,volume=0.15,"
                f"highpass=f=80,lowpass=f=8000[bgm];"
                f"[1:a]volume=1.6,"
                f"highpass=f=60,acompressor=threshold=-18dB:ratio=3:attack=5:release=50[tts];"
                f"[bgm][tts]amix=inputs=2:duration=longest,"
                f"loudnorm=I=-14:TP=-1.5:LRA=11[audio]"
            )
            cmd = [
                ffmpeg_path, "-y",
                "-i", input_path,
                "-i", tts_path,
                "-filter_complex", filter_complex,
                "-map", "[video]", "-map", "[audio]",
                "-c:v", "libx264", "-preset", "slow", "-crf", "20",
                "-profile:v", "high", "-level", "4.1",
                "-c:a", "aac", "-b:a", "256k", "-ar", "44100",
                "-movflags", "+faststart",
                "-shortest",
                output_path,
            ]
        else:
            # â”€â”€ ì›ë³¸ ì˜¤ë””ì˜¤ + loudnorm â”€â”€
            filter_complex = (
                f"{video_filter_base}[video];"
                f"[0:a]atrim=start={start_sec}:end={end_sec},"
                f"asetpts=PTS-STARTPTS,"
                f"loudnorm=I=-14:TP=-1.5:LRA=11[audio]"
            )
            cmd = [
                ffmpeg_path, "-y",
                "-i", input_path,
                "-filter_complex", filter_complex,
                "-map", "[video]", "-map", "[audio]",
                "-c:v", "libx264", "-preset", "slow", "-crf", "20",
                "-profile:v", "high", "-level", "4.1",
                "-c:a", "aac", "-b:a", "256k", "-ar", "44100",
                "-movflags", "+faststart",
                output_path,
            ]

        try:
            result = subprocess.run(
                cmd, capture_output=True, text=True, timeout=600,
                encoding="utf-8", errors="replace",
            )
            if result.returncode == 0 and os.path.exists(output_path):
                size_mb = os.path.getsize(output_path) / (1024 * 1024)
                print(f"  âœ… í”„ë¡œê¸‰ ìˆì¸  ì™„ë£Œ: {os.path.basename(output_path)} ({size_mb:.1f}MB)")
                return output_path
            else:
                print(f"  âŒ FFmpeg ì‹¤íŒ¨: {result.stderr[:300]}")
                return None
        except Exception as e:
            print(f"  âŒ í¸ì§‘ ì—ëŸ¬: {e}")
            return None

    async def process_url_async(self, url: str) -> Optional[str]:
        """URL â†’ ë‹¤ìš´ë¡œë“œ â†’ ë¶„ì„ â†’ ë‚˜ë ˆì´ì…˜ TTS â†’ ìˆì¸  í¸ì§‘ (ì „ìë™)"""
        print(f"\n{'='*60}")
        print(f"ğŸ¬ VideoAutoEditor: ì˜ìƒ ì†ŒìŠ¤ â†’ ë‚˜ë ˆì´ì…˜ ìˆì¸  ë³€í™˜")
        print(f"{'='*60}")

        tts_path = None

        # Step 1: ë‹¤ìš´ë¡œë“œ
        video_path = self.download_video(url)
        if not video_path:
            return None

        # Step 2: í•˜ì´ë¼ì´íŠ¸ + ë‚˜ë ˆì´ì…˜ ëŒ€ë³¸ ì¶”ì¶œ
        highlights = self.get_highlights(video_path)
        if not highlights:
            print("  âš ï¸  ë¶„ì„ ì‹¤íŒ¨ â†’ ì²« 60ì´ˆ, ë‚˜ë ˆì´ì…˜ ì—†ì´ í¸ì§‘")
            highlights = {"start_sec": 0, "end_sec": 60, "reason": "ê¸°ë³¸ êµ¬ê°„", "narration": ""}

        # Step 3: ë‚˜ë ˆì´ì…˜ TTS ìƒì„± (ìˆì„ ë•Œë§Œ)
        narration = highlights.get("narration", "")
        if narration:
            tts_path = os.path.join(self.download_dir, "narration_tts.mp3")
            tts_path = await self._generate_narration_tts(narration, tts_path)

        # Step 4: ìˆì¸  í¸ì§‘ (ë‚˜ë ˆì´ì…˜ ë¯¹ì‹± í¬í•¨)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(
            self.config.output_dir,
            f"shorts_video_{timestamp}.mp4"
        )
        result = self.edit_to_shorts(
            video_path,
            highlights["start_sec"],
            highlights["end_sec"],
            output_path,
            tts_path=tts_path,
        )

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for temp in [video_path, tts_path]:
            try:
                if temp and os.path.exists(temp):
                    os.remove(temp)
            except OSError:
                pass

        return result

    def process_url(self, url: str) -> Optional[str]:
        """ë™ê¸° ë˜í¼ (asyncio.run ì‚¬ìš©)"""
        return asyncio.run(self.process_url_async(url))


# ============================================================
# ğŸ”¥ Stage 0: ì»¤ë®¤ë‹ˆí‹° ë°”ì´ëŸ´ í¬ë¡¤ëŸ¬ v6.0
# â”€â”€ ë„¤ì´íŠ¸íŒ Â· ì¸ìŠ¤í‹°ì¦ˆ Â· ì—í¨ì½”ë¦¬ì•„ Â· ë””ì‹œ ì‹¤ë²  â”€â”€
# â”€â”€ ëª¨ë°”ì¼ ì›¹ ìš°íšŒ + ë©”íŠ¸ë¦­(ëŒ“ê¸€/ì¶”ì²œ) ê¸°ë°˜ í•„í„°ë§ â”€â”€
# ============================================================
class ViralSourceScraper:
    """v6.0: í•œêµ­ ì»¤ë®¤ë‹ˆí‹° í•«ê¸€ ê¸°ë°˜ ë°”ì´ëŸ´ ì†Œì¬ í¬ë¡¤ëŸ¬

    4ëŒ€ ì†ŒìŠ¤: ë„¤ì´íŠ¸íŒ(ì¸ê°„ê´€ê³„ ì°) â†’ ì¸ìŠ¤í‹°ì¦ˆ(ê³µê°í˜•) â†’ ì—í¨ì½”ë¦¬ì•„(ì‹œì‚¬+ìœ ë¨¸) â†’ ë””ì‹œ ì‹¤ë² (ìê·¹ì )
    ì „ëµ: ëª¨ë°”ì¼ URL â†’ BeautifulSoup â†’ ëŒ“ê¸€ìˆ˜/ì¶”ì²œìˆ˜ ë©”íŠ¸ë¦­ â†’ ìƒìœ„ Nê°œë§Œ ë°˜í™˜
    """

    _MOBILE_UA = (
        "Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) "
        "AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1"
    )
    _DESKTOP_UA = (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
    )
    _MIN_COMMENTS = 30  # ëŒ“ê¸€ ì´ ì´ìƒì¸ ê¸€ë§Œ í›„ë³´

    # â”€â”€ [1ìˆœìœ„] ë„¤ì´íŠ¸íŒ: ì¸ê°„ê´€ê³„ ì°ì˜ ì„±ì§€ â”€â”€

    @classmethod
    def fetch_natepann(cls) -> list[dict]:
        """ë„¤ì´íŠ¸íŒ ëª…ì˜ˆì˜ì „ë‹¹ + ì˜¤ëŠ˜ì˜íŒ (ëª¨ë°”ì¼) â€” ì œëª© + ëŒ“ê¸€ìˆ˜ + ì¡°íšŒìˆ˜ + ì¶”ì²œìˆ˜"""
        results = []
        urls = [
            "https://m.pann.nate.com/talk/ranking",  # ëª…ì˜ˆì˜ ì „ë‹¹
            "https://m.pann.nate.com/talk/today",     # ì˜¤ëŠ˜ì˜ íŒ
        ]
        try:
            from bs4 import BeautifulSoup
            for page_url in urls:
                try:
                    resp = requests.get(page_url, headers={"User-Agent": cls._MOBILE_UA}, timeout=10)
                    if resp.status_code != 200:
                        continue
                    soup = BeautifulSoup(resp.text, "html.parser")

                    for a_tag in soup.select("a"):
                        href = a_tag.get("href", "")
                        if "/talk/" not in href:
                            continue
                        talk_match = re.search(r'/talk/(\d{6,})', href)
                        if not talk_match:
                            continue

                        raw = a_tag.get_text(strip=True)
                        if not raw or len(raw) < 10 or len(raw) > 120:
                            continue

                        # íŒŒì‹±: "1ë™ë‚¨ì•„ë ¨ë“¤ ë‹¤ íƒˆí‡´ì‹œì¼œë¼ ê±(124)ì¡°íšŒ70,846|ì¶”ì²œ373"
                        title_raw = re.sub(r'^\d{1,2}', '', raw)  # ì• ìˆœë²ˆ ì œê±°

                        comments = 0
                        cm = re.search(r'\((\d{1,5})\)', title_raw)
                        if cm:
                            comments = int(cm.group(1))

                        views = 0
                        vm = re.search(r'ì¡°íšŒ([\d,]+)', title_raw)
                        if vm:
                            views = int(vm.group(1).replace(",", ""))

                        recommends = 0
                        rm = re.search(r'ì¶”ì²œ(\d+)', title_raw)
                        if rm:
                            recommends = int(rm.group(1))

                        # ì œëª© í´ë¦¬ë‹: ë©”íŠ¸ë¦­ ë¶€ë¶„ ì œê±°
                        title = title_raw
                        for pat in [r'\(\d{1,5}\)', r'ì¡°íšŒ[\d,]+', r'\|?ì¶”ì²œ\d+']:
                            title = re.sub(pat, '', title)
                        title = title.strip()

                        if not title or len(title) < 3:
                            continue

                        score = comments * 3 + views // 100 + recommends * 2

                        results.append({
                            "title": title,
                            "url": f"https://m.pann.nate.com/talk/{talk_match.group(1)}",
                            "source": "ë„¤ì´íŠ¸íŒ",
                            "score": score,
                            "comments": comments,
                            "views": views,
                            "recommends": recommends,
                            "content": "",
                        })
                except Exception:
                    continue

            # ì¤‘ë³µ ì œê±°
            seen = set()
            deduped = []
            for r in results:
                key = r["title"][:20]
                if key not in seen:
                    seen.add(key)
                    deduped.append(r)
            results = deduped

            print(f"  [OK] ë„¤ì´íŠ¸íŒ: {len(results)}ê°œ")
        except Exception as e:
            print(f"  [WARN] ë„¤ì´íŠ¸íŒ ì‹¤íŒ¨: {e}")
        return results

    # â”€â”€ [2ìˆœìœ„] ì¸ìŠ¤í‹°ì¦ˆ: ì¼ìƒ ê³µê°í˜• ì†Œì¬ â”€â”€

    @classmethod
    def fetch_instiz(cls) -> list[dict]:
        """ì¸ìŠ¤í‹°ì¦ˆ ì¸ê¸°ê¸€ â€” ì œëª© + ëŒ“ê¸€ìˆ˜"""
        results = []
        try:
            resp = requests.get(
                "https://www.instiz.net/pt?page=1",
                headers={"User-Agent": cls._DESKTOP_UA},
                timeout=10,
            )
            if resp.status_code != 200:
                print(f"  [WARN] ì¸ìŠ¤í‹°ì¦ˆ HTTP {resp.status_code}")
                return results

            from bs4 import BeautifulSoup
            soup = BeautifulSoup(resp.text, "html.parser")

            for subj in soup.select(".listsubject"):
                a_tag = subj.select_one("a")
                if not a_tag:
                    continue

                href = a_tag.get("href", "")
                if not href.startswith("http"):
                    href = "https://www.instiz.net" + href

                # â˜… ëŒ“ê¸€ìˆ˜: span.cmt3 ìš”ì†Œì—ì„œ ì •í™•í•˜ê²Œ ì¶”ì¶œ
                comments = 0
                cmt_span = subj.select_one("span.cmt3, span.cmt2, span.cmt1")
                if cmt_span:
                    try:
                        comments = int(cmt_span.get_text(strip=True))
                    except (ValueError, TypeError):
                        pass

                # â˜… ì œëª©: aíƒœê·¸ í…ìŠ¤íŠ¸ì—ì„œ ëŒ“ê¸€ìˆ˜(ë’¤ì— ë¶™ì€ ìˆ«ì) ì œê±°
                raw_text = a_tag.get_text(strip=True)
                if not raw_text or len(raw_text) < 5:
                    continue

                # ëŒ“ê¸€ìˆ˜ ìˆ«ìê°€ ì œëª© ëì— ë¶™ì–´ìˆìœ¼ë©´ ì œê±°
                # â˜… A-1 fix: cmt ìŠ¤íŒ¬ í…ìŠ¤íŠ¸ ìì²´ë¥¼ raw_textì—ì„œ ì œê±° (ìˆ«ì ì”ì¬ ë°©ì§€)
                if cmt_span:
                    cmt_text = cmt_span.get_text(strip=True)
                    # aíƒœê·¸ ë‚´ cmt ìŠ¤íŒ¬ í…ìŠ¤íŠ¸ë¥¼ ì œê±°í•œ ë’¤ ì œëª© ì¶”ì¶œ
                    title = raw_text.replace(cmt_text, '').strip()
                    # í˜¹ì‹œ ëì— ë‚¨ì€ ëŒ“ê¸€ìˆ˜ ìˆ«ì í•œë²ˆ ë” ì œê±°
                    if comments > 0:
                        title = re.sub(rf'\s*{comments}\s*$', '', title).strip()
                else:
                    # cmt ìŠ¤íŒ¬ ì—†ëŠ” ê²½ìš°: ë ìˆ«ìê°€ ëŒ“ê¸€ìˆ˜ì¼ ìˆ˜ ìˆìŒ
                    cm = re.search(r'(\d{2,5})$', raw_text)
                    if cm:
                        comments = int(cm.group(1))
                        title = raw_text[:cm.start()].strip()
                    else:
                        title = raw_text

                # â˜… ì¸ìŠ¤í‹°ì¦ˆ ì”ì¬ ì •ë¦¬: ì‹œê°„(14:27), 'lì¡°íšŒ', 'l', .jpg ë“± ì œê±°
                title = re.sub(r'\d{1,2}:\d{2}[lL]?ì¡°íšŒ.*$', '', title).strip()
                title = re.sub(r'\d{1,2}:\d{2}[lL]?$', '', title).strip()
                title = re.sub(r'[lL]ì¡°íšŒ\s*\d*$', '', title).strip()
                title = re.sub(r'\.jpg\s*\d*$', '', title).strip()
                title = re.sub(r'\.png\s*\d*$', '', title).strip()

                if not title or len(title) < 3:
                    continue

                score = comments * 3

                results.append({
                    "title": title,
                    "url": href,
                    "source": "ì¸ìŠ¤í‹°ì¦ˆ",
                    "score": score,
                    "comments": comments,
                    "views": 0,
                    "content": "",
                })

            print(f"  [OK] ì¸ìŠ¤í‹°ì¦ˆ: {len(results)}ê°œ")
        except Exception as e:
            print(f"  [WARN] ì¸ìŠ¤í‹°ì¦ˆ ì‹¤íŒ¨: {e}")
        return results

    # â”€â”€ [3ìˆœìœ„] ì—í¨ì½”ë¦¬ì•„: ì‹œì‚¬+ìœ ë¨¸ í˜¼í•© â”€â”€

    @classmethod
    def fetch_fmkorea(cls) -> list[dict]:
        """ì—í¨ì½”ë¦¬ì•„ ë² ìŠ¤íŠ¸ (ëª¨ë°”ì¼) â€” ì œëª© + ëŒ“ê¸€ìˆ˜"""
        results = []
        try:
            resp = requests.get(
                "https://m.fmkorea.com/best",
                headers={"User-Agent": cls._MOBILE_UA},
                timeout=10,
            )
            if resp.status_code != 200:
                print(f"  [WARN] ì—í¨ì½”ë¦¬ì•„ HTTP {resp.status_code}")
                return results

            from bs4 import BeautifulSoup
            soup = BeautifulSoup(resp.text, "html.parser")

            for a_tag in soup.select("a"):
                txt = a_tag.get_text(strip=True)
                if not txt or len(txt) < 8 or len(txt) > 80:
                    continue

                # ëŒ“ê¸€ìˆ˜: "[456]" íŒ¨í„´
                comments = 0
                cm = re.search(r'\[(\d{1,5})\]$', txt)
                if cm:
                    comments = int(cm.group(1))
                    title = txt[:cm.start()].strip()
                else:
                    title = txt

                if not title or len(title) < 5:
                    continue

                # ì—í¨ íŠ¹ì„±: ë„ˆë¬´ ì§§ì€ ì œëª©ì€ ë©”ë‰´/ê´‘ê³ 
                if len(title) < 8:
                    continue

                href = a_tag.get("href", "")

                score = comments * 3

                results.append({
                    "title": title,
                    "url": href if href.startswith("http") else f"https://m.fmkorea.com{href}",
                    "source": "ì—í¨ì½”ë¦¬ì•„",
                    "score": score,
                    "comments": comments,
                    "views": 0,
                    "content": "",
                })

            # ì¤‘ë³µ ì œê±°
            seen = set()
            deduped = []
            for r in results:
                key = r["title"][:20]
                if key not in seen:
                    seen.add(key)
                    deduped.append(r)
            results = deduped

            print(f"  [OK] ì—í¨ì½”ë¦¬ì•„: {len(results)}ê°œ")
        except Exception as e:
            print(f"  [WARN] ì—í¨ì½”ë¦¬ì•„ ì‹¤íŒ¨: {e}")
        return results

    # â”€â”€ [4ìˆœìœ„] ë””ì‹œì¸ì‚¬ì´ë“œ ì‹¤ë² : ìê·¹ì  ì´ìŠˆ â”€â”€

    @classmethod
    def fetch_dcinside(cls) -> list[dict]:
        """ë””ì‹œì¸ì‚¬ì´ë“œ ì‹¤ì‹œê°„ë² ìŠ¤íŠ¸ (ëª¨ë°”ì¼) â€” ì œëª© + ì¶”ì²œìˆ˜ + ì¡°íšŒìˆ˜"""
        results = []
        try:
            resp = requests.get(
                "https://m.dcinside.com/board/dcbest",
                headers={"User-Agent": cls._MOBILE_UA},
                timeout=10,
            )
            if resp.status_code != 200:
                print(f"  [WARN] ë””ì‹œ ì‹¤ë²  HTTP {resp.status_code}")
                return results

            from bs4 import BeautifulSoup
            soup = BeautifulSoup(resp.text, "html.parser")

            for a_tag in soup.select("a.lt"):
                raw = a_tag.get_text(strip=True)
                if not raw or len(raw) < 10:
                    continue

                href = a_tag.get("href", "")
                if "/board/dcbest/" not in href:
                    continue

                # â˜… A-1 fix: ê³µì§€ê¸€/ì†Œê°œê¸€ ì¦‰ì‹œ ìŠ¤í‚µ
                if any(kw in raw for kw in ["ê°¤ëŸ¬ë¦¬ ì´ìš© ì•ˆë‚´", "ì´ìš©ì•ˆë‚´", "ê³µì§€", "ì†Œê°œ"]):
                    continue

                # ë””ì‹œ ëª¨ë°”ì¼: "ì´ë¯¸ì§€[ê°¤]ì œëª©ã…‡ã…‡HH:MMì¡°íšŒ NNNNNì¶”ì²œNNNìˆ«ì"
                # ì œëª© ì¶”ì¶œ: [ê°¤] ë’¤ë¶€í„° ì‹œê°„(HH:MM) ë˜ëŠ” ã…‡ã…‡ ì§ì „ê¹Œì§€
                title = raw
                views = 0
                recommends = 0

                # ê°¤ëŸ¬ë¦¬ íƒœê·¸ ì œê±°
                gal_match = re.search(r'(?:ì´ë¯¸ì§€)?\[.+?\]', title)
                if gal_match:
                    title = title[gal_match.end():]

                # ì¡°íšŒìˆ˜/ì¶”ì²œìˆ˜ ì¶”ì¶œ
                vm = re.search(r'ì¡°íšŒ\s*([\d,]+)', title)
                if vm:
                    views = int(vm.group(1).replace(",", ""))
                rm = re.search(r'ì¶”ì²œ\s*(\d+)', title)
                if rm:
                    recommends = int(rm.group(1))

                # â˜… A-1 fix: ì œëª© ì •ë¦¬ ê°•í™” â€” ë‹‰ë„¤ì„/ì‹œê°„/ì¡°íšŒìˆ˜/ì¶”ì²œìˆ˜/ìˆ«ìì”ì¬ ì „ë¶€ ì œê±°
                for pattern in [
                    r'ã…‡ã…‡(?:\([\d.]+\))?\s*\d{1,2}:\d{2}',  # ã…‡ã…‡(123.456)14:20
                    r'[a-zA-Zê°€-í£]+\d{1,2}:\d{2}',           # ë‹‰ë„¤ì„14:20
                    r'\d{1,2}:\d{2}',                          # ë‹¨ë… ì‹œê°„
                    r'ì¡°íšŒ\s*[\d,]+',
                    r'ì¶”ì²œ\s*\d+',
                ]:
                    cut = re.search(pattern, title)
                    if cut:
                        title = title[:cut.start()]
                # ëì— ë¶™ì€ ë‹‰ë„¤ì„ ì”ì¬ ì œê±° (ã…‡ã…‡, ìˆ«ìë§Œ ë‚¨ì€ ê²½ìš°)
                title = re.sub(r'ã…‡ã…‡$', '', title).strip()
                title = re.sub(r'\d{1,3}$', '', title).strip()
                # .jpg / .gif í™•ì¥ì ì”ì¬ ì œê±°
                title = re.sub(r'\.(jpg|gif|png|jpeg)$', '', title, flags=re.IGNORECASE).strip()

                if not title or len(title) < 5:
                    continue

                score = recommends * 2 + views // 200

                results.append({
                    "title": title,
                    "url": href if href.startswith("http") else f"https://m.dcinside.com{href}",
                    "source": "ë””ì‹œì‹¤ë² ",
                    "score": score,
                    "comments": 0,
                    "views": views,
                    "recommends": recommends,
                    "content": "",
                })

            print(f"  [OK] ë””ì‹œ ì‹¤ë² : {len(results)}ê°œ")
        except Exception as e:
            print(f"  [WARN] ë””ì‹œ ì‹¤ë²  ì‹¤íŒ¨: {e}")
        return results

    # â”€â”€ í†µí•© ìˆ˜ì§‘ + ë©”íŠ¸ë¦­ í•„í„°ë§ â”€â”€

    # â”€â”€ A-2: ìˆì¸  ë°”ì´ëŸ´ ì¹´í…Œê³ ë¦¬ ë¶€ìŠ¤íŠ¸ (100ë§Œë·°+ ê²€ì¦ ê¸°ë°˜) â”€â”€
    _CATEGORY_BOOSTS = {
        "ê³µí¬_ë¯¸ìŠ¤í„°ë¦¬": (["ê³µí¬", "ê·€ì‹ ", "ì‹¬ë ¹", "ë¯¸ìŠ¤í„°ë¦¬", "ì†Œë¦„", "ê´´ë‹´", "ë„ì‹œì „ì„¤", "íê±´ë¬¼", "í˜¸ëŸ¬"], 50),
        "ì¶©ê²©ì‚¬ì‹¤": (["ì¶©ê²©", "ì•Œê³ ë³´ë‹ˆ", "ì§„ì‹¤", "ëª°ëë˜", "ë¹„ë°€", "ë°˜ì „", "ì‹¤í™”", "ê²½ì•…", "ì—­ëŒ€ê¸‰"], 45),
        "ë¬¸í™”ì¶©ê²©": (["ì™¸êµ­ì¸", "ë¬¸í™”ì¶©ê²©", "ë°˜ì‘", "ë¦¬ì•¡ì…˜", "ë†€ë€", "í•´ì™¸", "ì¼ë³¸", "ë¯¸êµ­"], 45),
        "ë°ˆ_ìœ ë¨¸": (["ë°ˆ", "ì§¤", "ã…‹ã…‹", "ì›ƒê¸´", "ê°œì›ƒ", "ì¡´ì›ƒ", "í‚¹ë°›", "í™©ë‹¹", "ì›ƒì°¸", "ë¹¡ì¹¨"], 40),
        "ë¹„êµ_ë­í‚¹": (["ë¹„êµ", "VS", "ë­í‚¹", "ìˆœìœ„", "TOP", "1ìœ„", "ìµœê³ ", "ìµœì•…", "ì°¨ì´"], 40),
        "2030_ì§ì¥": (["ì›”ê¸‰", "í‡´ì‚¬", "ì•¼ê·¼", "ì§ì¥ìƒì‚¬", "ê¼°ëŒ€", "ì‚¬ì§ì„œ", "ì›Œë¼ë°¸", "ì´ì§", "ì—°ë´‰", "ì‹ ì…", "ì¸í„´", "MZ"], 35),
        "2030_ëˆ": (["ì›”ì„¸", "ì „ì„¸", "ìì·¨", "ì¬í…Œí¬", "ì ê¸ˆ", "ì‚¬íšŒì´ˆë…„ìƒ", "ì²­ì•½", "ëŒ€ì¶œ"], 35),
        "ê¿€íŒ_ì •ë³´": (["ê¿€íŒ", "ë°©ë²•", "ë…¸í•˜ìš°", "í•µê¿€", "ê°€ì„±ë¹„", "ê¿€ì¡°í•©", "ë¹„ë²•", "ì ˆì•½", "ì¶”ì²œ", "ë¦¬ë·°", "ì •ë¦¬", "ëª¨ë¥´ë©´ ì†í•´", "ìƒí™œ", "ì‚´ë¦¼", "ì²­ì†Œ", "ìš”ë¦¬"], 35),
        "ì¼ìƒ_ì½”ë¯¸ë””": (["ì›ƒê¸´", "ê°œì›ƒ", "ì¡´ì›ƒ", "í™©ë‹¹", "í‚¹ë°›", "ê³µê°", "ì¼ìƒ", "ì¶œê·¼", "ì›”ìš”ì¼", "ê·€ì°®", "íŠ¹ì§•", "ìœ í˜•"], 35),
        "ìƒì‹_ê¶ê¸ˆ": (["ì™œ", "ì´ìœ ", "ë¹„ë°€", "ìƒì‹", "í€´ì¦ˆ", "ê¶ê¸ˆ", "ê³¼í•™", "ì›ë¦¬", "ì§„ì§œ ì´ìœ "], 35),
    }

    # â”€â”€ A-2: ìˆì¸  ë¶€ì í•© ê°ì  (ì¼ìƒ ì¡ë‹´ = ì¡°íšŒìˆ˜ ì €ì¡°) â”€â”€
    _BORING_PENALTIES = [
        (r"ì„¤ê±°ì§€|ì‹œëŒ|íŒŒí˜¼", -30, "ê°€ì •ì‚¬"),
        (r"ë‹¤ì´ì–´íŠ¸|ì‹ë‹¨|í—¬ìŠ¤|ìš´ë™ë£¨í‹´", -20, "ë‹¤ì´ì–´íŠ¸"),
        (r"ì¹´í˜|ë§›ì§‘|ë””ì €íŠ¸|ë¹µì§‘|ë¸ŒëŸ°ì¹˜", -15, "ì¹´í˜"),
        (r"ì—´ì• |ê²°ë³„|ì†Œì†ì‚¬|ì»´ë°±|íŒ¬ì‹¸", -10, "ì—°ì˜ˆê°€ì‹­"),
    ]

    @classmethod
    def _compute_viral_score(cls, item: dict) -> float:
        """A-2: ìˆì¸  ë°”ì´ëŸ´ ì˜ˆì¸¡ ì ìˆ˜ (ì»¤ë®¤ë‹ˆí‹° ì¸ê¸°ì™€ ë³„ê°œë¡œ ìˆì¸  ì í•©ë„ í‰ê°€)"""
        title = item.get("title", "")
        score = 0.0

        # 1) ì°¸ì—¬ë„ ê¸°ë³¸ì ìˆ˜
        cmt = item.get("comments", 0)
        rec = item.get("recommends", 0)
        views = item.get("views", 0)
        score += cmt * 3 + rec * 2 + views / 200

        # 2) ì¹´í…Œê³ ë¦¬ ë¶€ìŠ¤íŠ¸ (í•µì‹¬!)
        for cat_name, (keywords, boost) in cls._CATEGORY_BOOSTS.items():
            if any(kw in title for kw in keywords):
                score += boost
                break

        # 3) ë°”ì´ëŸ´ í‚¤ì›Œë“œ ë¶€ìŠ¤íŠ¸ (Ã—5ì ìœ¼ë¡œ ìƒí–¥)
        BOOST_KW = [
            "ë ˆì „ë“œ", "ì‹¤í™”", "ëŒ€ë°•", "ë¯¸ì³¤", "ì†Œë¦„", "ë…¼ë€", "ë°˜ì „",
            "í›„ê¸°", "ë¨¹ë°©", "ê²Œì„", "ë¦¬ë·°", "ë°ˆ", "ì±Œë¦°ì§€",
            "í„°ì§", "ë‚œë¦¬", "ë¹„êµ", "ë­í‚¹", "ê¿€íŒ",
            "í•´ë´„", "ì¨ë´„", "ì‚¬ë´„", "ê°€ë´„",
            "ì¸", "ì†Œê°œíŒ…", "ê²°í˜¼", "ì¶•ì˜ê¸ˆ", "ì—°ì• ", "ê³ ë°±",
        ]
        kw_count = sum(1 for kw in BOOST_KW if kw in title)
        score += kw_count * 5

        # 4) ìˆì¸  ë¶€ì í•© ê°ì 
        for pat, penalty, label in cls._BORING_PENALTIES:
            if re.search(pat, title):
                score += penalty
                break

        # 5) ë‚šì‹œ/ìŠ¤íŒ¸ ê°ì 
        CLICKBAIT = [r"ë‹¨í†¡ë°©", r"í…”ë ˆê·¸ë¨", r"ë¬´ë£Œ\s*ë‚˜ëˆ”", r"ì„ ì°©ìˆœ", r"í›„ë°©ì£¼ì˜", r"19ê¸ˆ"]
        for pat in CLICKBAIT:
            if re.search(pat, title):
                score -= 50

        # 6) ì œëª© ê¸¸ì´ ë³´ì •
        if len(title) < 5:
            score -= 20
        elif len(title) >= 15:
            score += 5  # ì œëª©ì´ ê¸¸ë©´ ì •ë³´ëŸ‰ â†‘

        return score

    @classmethod
    def _gemini_evaluate_topics(cls, items: list[dict]) -> list[dict]:
        """A-3: Geminië¡œ ìƒìœ„ í›„ë³´ë“¤ì˜ ìˆì¸  ë°”ì´ëŸ´ ê°€ëŠ¥ì„± 0~100ì  í‰ê°€
        1íšŒ API í˜¸ì¶œë¡œ ìµœëŒ€ 15ê°œ ë™ì‹œ í‰ê°€ â†’ ë¹„ìš© $0
        70ì  ì´ìƒë§Œ í†µê³¼"""
        if not items:
            return items

        api_key = os.getenv("GOOGLE_API_KEY", "")
        if not api_key:
            print("  âš ï¸  GOOGLE_API_KEY ì—†ìŒ â†’ Gemini í‰ê°€ ìŠ¤í‚µ")
            return items

        # ìƒìœ„ 15ê°œë§Œ í‰ê°€ (í† í° ì ˆì•½)
        candidates = items[:15]
        titles_text = "\n".join(
            f"{i+1}. [{c['source']}] {c['title']}"
            for i, c in enumerate(candidates)
        )

        prompt = f"""ë„ˆëŠ” ìœ íŠœë¸Œ ìˆì¸  ë°”ì´ëŸ´ ì „ë¬¸ê°€ë‹¤.
ì•„ë˜ ì»¤ë®¤ë‹ˆí‹° í•«ê¸€ ì œëª©ë“¤ì„ ë³´ê³ , ê°ê° "ìœ íŠœë¸Œ ìˆì¸ ë¡œ ë§Œë“¤ë©´ ì¡°íšŒìˆ˜ê°€ í„°ì§ˆ ê°€ëŠ¥ì„±"ì„ 0~100ì ìœ¼ë¡œ í‰ê°€í•´.

í‰ê°€ ê¸°ì¤€ (4ê°€ì§€ í…Œë§ˆ ëª¨ë‘ ê³ ë ¤):
- 90~100: 100ë§Œë·°+ (ì¶©ê²©ì‚¬ì‹¤, ê³µí¬, ë°ˆ, ë¬¸í™”ì¶©ê²©, ê¶ê·¹ì˜ ê¿€íŒ, ì¼ìƒ ê°œê³µê° ì½”ë¯¸ë””)
- 70~89: 10ë§Œë·°+ (ê³µê°í˜• ì°, ë¹„êµ/ë­í‚¹, ê¿€íŒ/ì •ë³´, ì¼ìƒ ì½”ë¯¸ë””, ìƒì‹/ë¯¸ìŠ¤í„°ë¦¬, í˜¸ê¸°ì‹¬ ìê·¹)
- 50~69: í‰ë²” (ì¼ìƒ, ê°€ì‹­, ì¡ë‹´)
- 0~49: ìˆì¸  ë¶€ì í•© (ì •ì¹˜, ê³µì§€, ìŠ¤íŒ¸, ì‹œì¦Œì•„ì›ƒ)

ìˆì¸  í…Œë§ˆë³„ ë†’ì€ ì ìˆ˜ ê¸°ì¤€:
1. gossip(ì°): ë¶„ë…¸Â·ê³µê° í­ë°œ, ë°˜ì „ ì‚¬ì´ë‹¤
2. life_hack(ê¿€íŒ): "ë‚˜ë§Œ ëª°ëë„¤?" ì‹¤ìš© íŒ, ì €ì¥í•˜ê³  ì‹¶ê²Œ
3. empathy(ê³µê°): "ì–´? ì´ê±° ë‚˜ì¸ë°?" MBTI/ì§ì¥ ê³µê°, ìœ„íŠ¸
4. mystery(ë¯¸ìŠ¤í„°ë¦¬): "ì™œ ê·¸ëŸ°ì§€ ê¶ê¸ˆí•˜ì§€ ì•Šì•„?" í˜¸ê¸°ì‹¬ ìœ ë°œ

ëŒ€ìƒ:
{titles_text}

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µí•´:
{{"scores": [85, 72, 45, ...]}}

scores ë°°ì—´ì˜ ê¸¸ì´ëŠ” ë°˜ë“œì‹œ {len(candidates)}ê°œì—¬ì•¼ í•œë‹¤. JSONë§Œ ì¶œë ¥."""

        try:
            model = genai_flash.GenerativeModel("gemini-2.0-flash")
            response = model.generate_content(
                prompt,
                generation_config=genai_flash.GenerationConfig(
                    temperature=0.2,
                    max_output_tokens=500,
                    response_mime_type="application/json",
                ),
            )
            if response.text:
                data = json.loads(response.text)
                scores = data.get("scores", [])
                if isinstance(scores, list) and len(scores) == len(candidates):
                    passed = []
                    rejected = []
                    for item, gemini_score in zip(candidates, scores):
                        s = int(gemini_score) if isinstance(gemini_score, (int, float)) else 50
                        item["_gemini_score"] = s
                        if s >= 70:
                            item["score"] += s  # ê¸°ì¡´ ì ìˆ˜ì— Gemini ì ìˆ˜ í•©ì‚°
                            passed.append(item)
                        else:
                            rejected.append(item)

                    print(f"  ğŸ§  Gemini í‰ê°€: {len(passed)}ê°œ í†µê³¼ / {len(rejected)}ê°œ íƒˆë½")
                    for p in passed[:5]:
                        print(f"    âœ… [{p['_gemini_score']}ì ] {p['title'][:40]}")
                    for r in rejected[:3]:
                        print(f"    âŒ [{r['_gemini_score']}ì ] {r['title'][:40]}")

                    # í†µê³¼í•œ ê²ƒ + í‰ê°€ ì•ˆ ëœ ë‚˜ë¨¸ì§€ (15ìœ„ ì´í›„)
                    rest = items[15:]
                    return passed + rest
                else:
                    print(f"  âš ï¸  Gemini ì‘ë‹µ ê¸¸ì´ ë¶ˆì¼ì¹˜ ({len(scores)} vs {len(candidates)}) â†’ ìŠ¤í‚µ")
        except Exception as e:
            print(f"  âš ï¸  Gemini ì£¼ì œ í‰ê°€ ì‹¤íŒ¨: {e} â†’ ê¸°ì¡´ ì ìˆ˜ ì‚¬ìš©")

        return items

    @classmethod
    def _deduplicate_with_history(cls, items: list[dict]) -> list[dict]:
        """A-4: ì£¼ì œ ì¤‘ë³µ ë°©ì§€ â€” ìµœê·¼ 200ê°œ ì œëª©ê³¼ ìœ ì‚¬ë„ ë¹„êµ"""
        history_path = os.path.join(os.path.dirname(os.path.abspath(__file__)),
                                     "data", "topic_history.json")
        past_titles = []
        try:
            if os.path.exists(history_path):
                with open(history_path, "r", encoding="utf-8") as f:
                    past_titles = json.load(f)
        except Exception:
            pass

        if not past_titles:
            return items

        # ê°„ë‹¨ ìœ ì‚¬ë„: ì œëª© ì• 20ì ë¹„êµ
        past_keys = set(t[:20] for t in past_titles)
        filtered = []
        skipped = 0
        for item in items:
            key = item["title"][:20]
            if key in past_keys:
                skipped += 1
                continue
            filtered.append(item)

        if skipped:
            print(f"  ğŸ”„ ì¤‘ë³µ ì œê±°: {skipped}ê°œ ìŠ¤í‚µ (ìµœê·¼ íˆìŠ¤í† ë¦¬ì™€ ê²¹ì¹¨)")
        return filtered

    @classmethod
    def _save_topic_history(cls, items: list[dict]) -> None:
        """A-4: ì„ íƒëœ ì£¼ì œë¥¼ íˆìŠ¤í† ë¦¬ì— ì €ì¥ (ìµœëŒ€ 200ê°œ ìœ ì§€)"""
        history_path = os.path.join(os.path.dirname(os.path.abspath(__file__)),
                                     "data", "topic_history.json")
        past_titles = []
        try:
            if os.path.exists(history_path):
                with open(history_path, "r", encoding="utf-8") as f:
                    past_titles = json.load(f)
        except Exception:
            pass

        new_titles = [item["title"] for item in items if item.get("title")]
        past_titles = new_titles + past_titles
        past_titles = past_titles[:200]  # ìµœê·¼ 200ê°œë§Œ ìœ ì§€

        os.makedirs(os.path.dirname(history_path), exist_ok=True)
        with open(history_path, "w", encoding="utf-8") as f:
            json.dump(past_titles, f, ensure_ascii=False, indent=2)

    @classmethod
    def collect_all(cls) -> list[dict]:
        """v7.0: 4ê°œ ì»¤ë®¤ë‹ˆí‹° í¬ë¡¤ë§ â†’ ë°”ì´ëŸ´ ì˜ˆì¸¡ ì ìˆ˜ â†’ Gemini í‰ê°€ â†’ ìƒìœ„ í›„ë³´ ë°˜í™˜"""
        print(f"\n{'='*60}")
        print(f"ğŸ”¥ Stage 0: ì»¤ë®¤ë‹ˆí‹° ë°”ì´ëŸ´ í¬ë¡¤ë§ v7.0 (AI ì£¼ì œ ì„ ë³„)")
        print(f"{'='*60}")

        all_items = []
        # ìˆœì„œëŒ€ë¡œ í¬ë¡¤ë§ (ê° ì†ŒìŠ¤ ì‹¤íŒ¨í•´ë„ ë‹¤ìŒìœ¼ë¡œ)
        all_items.extend(cls.fetch_natepann())
        all_items.extend(cls.fetch_instiz())
        all_items.extend(cls.fetch_fmkorea())
        all_items.extend(cls.fetch_dcinside())

        if not all_items:
            print("  âš ï¸  ëª¨ë“  ì»¤ë®¤ë‹ˆí‹° í¬ë¡¤ë§ ì‹¤íŒ¨ â€” Google Trends í´ë°±")
            all_items.extend(cls._fallback_google_trends())

        # â˜… A-2: ìˆì¸  ë°”ì´ëŸ´ ì˜ˆì¸¡ ì ìˆ˜ë¡œ ì •ë ¬ (ê¸°ì¡´ ë‹¨ìˆœ ë©”íŠ¸ë¦­ ëŒ€ì²´)
        for item in all_items:
            item["score"] = cls._compute_viral_score(item)
        all_items.sort(key=lambda x: x.get("score", 0), reverse=True)

        # â˜… A-4: ì£¼ì œ ì¤‘ë³µ ë°©ì§€ (íˆìŠ¤í† ë¦¬ ê¸°ë°˜)
        all_items = cls._deduplicate_with_history(all_items)

        # â˜… A-3: Gemini ì‚¬ì „ í‰ê°€ ê²Œì´íŠ¸ (ìƒìœ„ 15ê°œ â†’ 70ì + ë§Œ í†µê³¼)
        all_items = cls._gemini_evaluate_topics(all_items)

        # ìµœì¢… ì •ë ¬ (Gemini ì ìˆ˜ í•©ì‚°ëœ ìƒíƒœ)
        all_items.sort(key=lambda x: x.get("score", 0), reverse=True)

        print(f"\n  ğŸ“Š ì´ {len(all_items)}ê°œ ë°”ì´ëŸ´ ì†Œì¬ ìµœì¢… ì„ ë³„ ì™„ë£Œ")
        for i, item in enumerate(all_items[:8]):
            src = item["source"]
            cmt = item.get("comments", 0)
            rec = item.get("recommends", 0)
            views = item.get("views", 0)
            gs = item.get("_gemini_score", "?")
            metric = f"ğŸ’¬{cmt}" if cmt else f"ğŸ‘{rec}"
            if views:
                metric += f" ğŸ‘€{views:,}"
            print(f"  #{i+1} [{src}] {item['title'][:40]} ({metric}, ì ìˆ˜:{item.get('score',0):.0f}, AI:{gs})")

        # â˜… A-4: ì„ íƒëœ ì£¼ì œë¥¼ íˆìŠ¤í† ë¦¬ì— ì €ì¥
        cls._save_topic_history(all_items[:10])

        return all_items

    @staticmethod
    def _fallback_google_trends() -> list[dict]:
        """í´ë°±: ì»¤ë®¤ë‹ˆí‹° ì „ë©¸ ì‹œ Google Trends KR RSS"""
        results = []
        try:
            import xml.etree.ElementTree as ET
            resp = requests.get(
                "https://trends.google.co.kr/trending/rss?geo=KR",
                timeout=10,
                headers={"User-Agent": "Mozilla/5.0"},
            )
            if resp.status_code == 200:
                root = ET.fromstring(resp.text)
                ns = {"ht": "https://trends.google.co.kr/trending/rss"}
                for item in root.findall(".//item")[:15]:
                    title_el = item.find("title")
                    title = title_el.text if title_el is not None else ""
                    if title:
                        results.append({
                            "title": title,
                            "url": "",
                            "source": "êµ¬ê¸€íŠ¸ë Œë“œ",
                            "score": 50,
                            "comments": 0,
                            "views": 0,
                            "content": "",
                        })
                print(f"  [OK] Google Trends KR í´ë°±: {len(results)}ê°œ")
        except Exception as e:
            print(f"  [WARN] Google Trends í´ë°±ë„ ì‹¤íŒ¨: {e}")
        return results


# ============================================================
# ğŸ•·ï¸ Stage 1: í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
# ============================================================
class CommunityScraper:
    """ë””ì‹œ/ë„¤ì´íŠ¸íŒ ë² ìŠ¤íŠ¸ê¸€ í¬ë¡¤ë§ + í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜"""

    SOURCES = {
        "natepann": {
            "best_url": "https://pann.nate.com/talk/ranking/d",
            "name": "ë„¤ì´íŠ¸íŒ",
            "platform": "natepann",
        },
        "dcinside": {
            "best_url": "https://gall.dcinside.com/board/lists/?id={gallery}&exception_mode=recommend&sort_type=N&page=1",
            "name": "ë””ì‹œì¸ì‚¬ì´ë“œ",
            "platform": "dcinside",
        },
        "dcinside_realtime_best": {
            "best_url": "https://gall.dcinside.com/board/lists/?id=dcbest",
            "name": "ë””ì‹œ ì‹¤ì‹œê°„ë² ìŠ¤íŠ¸",
            "platform": "dcinside",
        },
        "dcinside_hit": {
            "best_url": "https://gall.dcinside.com/board/lists/?id=hit",
            "name": "ë””ì‹œ ê°œë…ê¸€",
            "platform": "dcinside",
        },
        "fmkorea": {
            "best_url": "https://www.fmkorea.com/best",
            "name": "ì—í¨ì½”ë¦¬ì•„",
            "platform": "fmkorea",
        },
        "ruliweb": {
            "best_url": "https://bbs.ruliweb.com/best/humor/best",
            "name": "ë£¨ë¦¬ì›¹ ìœ ë¨¸ ë² ìŠ¤íŠ¸",
            "platform": "ruliweb",
        },
        "instiz": {
            "best_url": "https://www.instiz.net/pt",
            "name": "ì¸ìŠ¤í‹°ì¦ˆ",
            "platform": "instiz",
        },
        "theqoo": {
            "best_url": "https://theqoo.net/hot",
            "name": "ë”ì¿ ",
            "platform": "theqoo",
        },
    }

    # UI/ê´‘ê³ /ì†Œê°œê¸€/ê³µì§€ê¸€ í‚¤ì›Œë“œ (1ê°œë¼ë„ í¬í•¨ â†’ ì¦‰ì‹œ ì°¨ë‹¨)
    BLOCK_KEYWORDS = [
        # DC ê°¤ëŸ¬ë¦¬ ìš´ì˜
        "ê°¤ëŸ¬ë¦¬ ì´ìš© ì•ˆë‚´", "ê°¤ëŸ¬ë¦¬ ì´ìš©ì•ˆë‚´", "ì´ìš© ì•ˆë‚´",
        "ê°¤ëŸ¬ë¦¬ ì†Œê°œ", "ê°¤ëŸ¬ë¦¬ë¥¼ ì†Œê°œ", "ê°¤ëŸ¬ë¦¬ ê°œì„¤",
        "ë§ˆì´ë„ˆ ê°¤ëŸ¬ë¦¬", "ë§ˆì´ë„ˆê°¤ëŸ¬ë¦¬",
        "CONNECTING HEARTS", "ë””ì‹œì¸ì‚¬ì´ë“œì…ë‹ˆë‹¤",
        # ê³µí†µ ê³µì§€/ì•ˆë‚´
        "[ê³µì§€]", "[í•„ë…]", "[ì•ˆë‚´]", "[ìš´ì˜]", "[ê·œì¹™]",
        "[Notice]", "[notice]", "[ì´ë²¤íŠ¸]", "[ëª¨ì§‘]",
        "ìš´ì˜ìì…ë‹ˆë‹¤", "ê³µì§€ì‚¬í•­ì…ë‹ˆë‹¤", "ì´ìš©ê·œì¹™",
        # ê´‘ê³ /ìŠ¤íŒ¸
        "í…”ë ˆê·¸ë¨", "ë‹¨í†¡ë°©", "ì¹´í†¡ë°©", "ì˜¤í”ˆì±„íŒ…",
        "ë¬´ë£Œ ë‚˜ëˆ”", "ì„ ì°©ìˆœ", "í• ì¸ì½”ë“œ", "ì¿ í°ì½”ë“œ",
        "ë¹„íŠ¸ì½”ì¸", "ê°€ìƒí™”í", "ì½”ì¸ ì¶”ì²œ", "NFT",
        "ìˆ˜ìµë¥ ", "íˆ¬ì ì¶”ì²œ", "ì›ê¸ˆë³´ì¥",
        # ì„±ì¸/ë¶€ì ì ˆ
        "í›„ë°©ì£¼ì˜", "19ê¸ˆ", "ì•¼ì§¤", "ì€ê¼´",
        # ì»¤ë®¤ë‹ˆí‹° ê´€ë¦¬
        "êµ¬ì¸êµ¬ì§", "íŒë‹ˆë‹¤", "ì‚½ë‹ˆë‹¤", "ê¸‰êµ¬",
        "ì²´í—˜ë‹¨", "í˜‘ì°¬", "ì œíœ´ ë¬¸ì˜",
        # ì‹œì¦Œ/ëª…ì ˆ ì´ìŠˆ (ì§€ë‚œ ì´ìŠˆ ë°°ì œ)
        "ì„¤ë‚ ", "ìƒˆí•´", "ì¶”ì„", "í•œê°€ìœ„", "í¬ë¦¬ìŠ¤ë§ˆìŠ¤", "ì„±íƒ„ì ˆ",
        "ë°œë Œíƒ€ì¸", "í™”ì´íŠ¸ë°ì´", "ì–´ë²„ì´ë‚ ", "ìŠ¤ìŠ¹ì˜ë‚ ",
        "ì¡¸ì—…ì‹", "ì…í•™ì‹", "ìˆ˜ëŠ¥", "ìˆ˜ëŠ¥ë‚ ",
    ]
    # UI/ìŠ¤íŒ¸ í‚¤ì›Œë“œ (2ê°œ ì´ìƒ í¬í•¨ â†’ ì°¨ë‹¨)
    UI_KEYWORDS = [
        "ê°¤ëŸ¬ë¦¬ ë§Œë“¤ê¸°", "íšŒì›ê°€ì…", "ë¡œê·¸ì¸", "ê´‘ê³  ë¬¸ì˜",
        "ì´ ê°¤ëŸ¬ë¦¬ë¥¼ , , ,", "ê°¤ëŸ¬ë¦¬ ê·œì •", "ê³µì§€ì‚¬í•­",
        "ìš´ì˜ ë°©ì¹¨", "ë§¤ë‹ˆì € ì‹ ì²­", "ë¶€ë§¤ë‹ˆì €",
        "í•œì¤„í‰", "í‰ê°€í•´ì£¼ì„¸ìš”", "ì„¤ë¬¸ì¡°ì‚¬",
    ]

    # ì½˜í…ì¸  ìœ„í—˜ í‚¤ì›Œë“œ (ì˜ë£Œ/ë²•ë¥ /ê¸ˆìœµ í—ˆìœ„ì •ë³´ ë°©ì§€)
    RISKY_CONTENT_KEYWORDS = [
        # ì˜ë£Œ â€” í—ˆìœ„ì •ë³´ ìœ„í—˜
        "ì•” ì¹˜ë£Œ", "íŠ¹íš¨ì•½", "ë¯¼ê°„ìš”ë²•", "ìê°€ì§„ë‹¨",
        "ë³‘ì›ì—ì„œ ì•ˆ ì•Œë ¤ì£¼ëŠ”", "ì˜ì‚¬ê°€ ìˆ¨ê¸°ëŠ”",
        # ë²•ë¥  â€” ì†Œì†¡ ìœ„í—˜
        "ê³ ì†Œ", "ì†Œì†¡", "í•©ì˜ê¸ˆ", "í˜•ì‚¬ì‚¬ê±´",
        # ê¸ˆìœµ â€” íˆ¬ì ê¶Œìœ  ìœ„í—˜
        "ëŒ€ì¶œ", "ì‚¬ê¸°", "í”¼í•´ì‚¬ë¡€",
    ]

    # Apify removeElements ê°•í™” ì…€ë ‰í„°
    DC_REMOVE_CSS = (
        "nav, footer, .ad, .advertisement, #header, .sidebar, "
        "script, style, .comment_box, .reply_box, "
        ".minor_intro_banner, .dchead_bg, .visit_card, .pop_wrap, "
        ".issue_wrap, .dc_logo, .gnb_bar, .user_info, .fl, "
        ".btn_recommend, .gall_exposure, .ad_bottom_list, .appdown, "
        ".notion_tag, #dchead, .darkmode-layer, .issue_contentbox, "
        ".minor_banner_list, .dcwiki, .listwrap.clear, "
        "#dccon_progress_bar, .repimg_thumb"
    )

    def __init__(self, config: Config):
        self.config = config
        self.client = None
        if config.apify_api_token:
            self.client = ApifyClient(config.apify_api_token)

    def scrape_with_screenshots(self) -> list[dict]:
        """
        ë² ìŠ¤íŠ¸ê¸€ í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ· ìº¡ì²˜
        Returns: [{title, content, url, screenshots: [path1, path2, ...]}]
        """
        print(f"\n{'='*60}")
        print(f"ğŸ•·ï¸  Stage 1: í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ·")
        src_name = self.SOURCES.get(self.config.source, {}).get('name', self.config.source)
        print(f"  ì†ŒìŠ¤: {src_name}")
        print(f"{'='*60}")

        if self.config.target_url:
            return self._scrape_single_with_screenshot(self.config.target_url)

        if self.client:
            return self._scrape_apify_with_screenshots()

        return self._scrape_fallback_with_fake_screenshots()

    # ë””ì‹œ ê³µì§€/ì†Œê°œê¸€ ë²ˆí˜¸ (í•­ìƒ ëª©ë¡ ìµœìƒë‹¨ì— ê³ ì •, ì‹¤ì œ ë² ìŠ¤íŠ¸ê¸€ì´ ì•„ë‹˜)
    DC_NOTICE_NOS = {
        "30638",   # ì‹¤ì‹œê°„ë² ìŠ¤íŠ¸ ê°¤ëŸ¬ë¦¬ ì´ìš© ì•ˆë‚´
        "17784",   # ê°œë…ê¸€ ê°¤ëŸ¬ë¦¬ ì´ìš© ì•ˆë‚´
    }

    # ë°”ì´ëŸ´ ê°€ì‚°ì  í‚¤ì›Œë“œ (ì œëª©ì— í¬í•¨ ì‹œ ìš°ì„  ì„ íƒ)
    VIRAL_BOOST_KEYWORDS = [
        "ã…‹ã…‹", "ë ˆì „ë“œ", "ì†Œë¦„", "ì‹¤í™”", "ëŒ€ë°•",
        "ì¶©ê²©", "ë°˜ì „", "ì›ƒê¸´", "ë¯¸ì³¤", "ì—­ëŒ€ê¸‰",
        "ã„¹ã…‡", "ã…‡ã…ˆ", "ê°œì›ƒ", "ã…‚ã„·ã…‚ã„·", "í—",
        "ã…ˆã„¹", "ì¡´ì›ƒ", "í‚¹ë°›", "ê°œë¹¡", "ê°“",
        "ì¸ìƒ", "ì°", "ê°œê¿€", "í•µê¿€", "ê¿€ì¼",
        # 2030 íƒ€ê²Ÿ ë¶€ìŠ¤íŠ¸
        "ì›”ê¸‰", "í‡´ì‚¬", "ì•¼ê·¼", "ìì·¨", "ì›”ì„¸", "ì „ì„¸",
        "ì‚¬íšŒì´ˆë…„ìƒ", "ì§ì¥ìƒì‚¬", "ê¼°ëŒ€", "MZ", "ì›Œë¼ë°¸",
        "ì—°ë´‰", "ì´ì§", "ì•Œë°”", "ë©´ì ‘", "ì·¨ì¤€",
        "ì¸", "ì†Œê°œíŒ…", "ê²°í˜¼", "ì¶•ì˜ê¸ˆ", "ì²­ì²©ì¥",
    ]

    # 2ì°¨ ë¸”ë™ë¦¬ìŠ¤íŠ¸: ë°”ì´ëŸ´ í‚¤ì›Œë“œê°€ ìˆì–´ë„ ê±¸ëŸ¬ì•¼ í•  ë‚šì‹œ íŒ¨í„´
    CLICKBAIT_PENALTY_PATTERNS = [
        r"ë‹¨í†¡ë°©", r"í…”ë ˆê·¸ë¨", r"ì¹´í†¡ë°©",   # ìŠ¤íŒ¸ ìœ ì…
        r"ë¬´ë£Œ\s*ë‚˜ëˆ”", r"ì„ ì°©ìˆœ",           # ê´‘ê³ ì„±
        r"ê¸‰êµ¬", r"êµ¬í•©ë‹ˆë‹¤", r"íŒë‹ˆë‹¤",      # ì¤‘ê³ ê±°ë˜
        r"í›„ë°©ì£¼ì˜", r"19ê¸ˆ", r"ì•¼ì§¤",        # ì„±ì¸ ì½˜í…ì¸ 
    ]

    # â”€â”€ ìˆì¸  í­ë°œë ¥ ì¹´í…Œê³ ë¦¬ (100ë§Œë·°+ ê²€ì¦ ê¸°ë°˜) â”€â”€
    VIRAL_CATEGORY_BOOSTS = {
        "ê³µí¬": (["ê³µí¬", "ê·€ì‹ ", "ì‹¬ë ¹", "ë¯¸ìŠ¤í„°ë¦¬", "ì†Œë¦„", "ê´´ë‹´", "ë„ì‹œì „ì„¤", "íê±´ë¬¼"], 80.0),
        "ì¶©ê²©ì‚¬ì‹¤": (["ì¶©ê²©", "ì•Œê³ ë³´ë‹ˆ", "ì§„ì‹¤", "ëª°ëë˜", "ë¹„ë°€", "ë°˜ì „", "ì‹¤í™”", "ê²½ì•…"], 70.0),
        "ë°ˆìœ ë¨¸": (["ë°ˆ", "ì§¤", "ã…‹ã…‹", "ì›ƒê¸´", "ê°œì›ƒ", "ì¡´ì›ƒ", "í‚¹ë°›", "í™©ë‹¹", "ì›ƒì°¸"], 60.0),
        "ë¹„êµë­í‚¹": (["ë¹„êµ", "VS", "ë­í‚¹", "ìˆœìœ„", "TOP", "1ìœ„", "ìµœê³ ", "ìµœì•…"], 60.0),
        "ë¬¸í™”ì¶©ê²©": (["ì™¸êµ­ì¸", "ë¬¸í™”ì¶©ê²©", "ë°˜ì‘", "ë¦¬ì•¡ì…˜", "ë†€ë€", "í•´ì™¸"], 70.0),
        "ê¿€íŒ": (["ê¿€íŒ", "ë°©ë²•", "ë…¸í•˜ìš°", "í•µê¿€", "ê°€ì„±ë¹„"], 50.0),
        "2030ì§ì¥ì°": (["ì›”ê¸‰", "í‡´ì‚¬", "ì•¼ê·¼", "ì§ì¥ìƒì‚¬", "ê¼°ëŒ€", "ì‚¬ì§ì„œ", "ì›Œë¼ë°¸",
                        "ì´ì§", "ì—°ë´‰", "ì‹ ì…", "ì¸í„´", "MZ"], 65.0),
        "2030ëˆì°": (["ì›”ì„¸", "ì „ì„¸", "ìì·¨", "ì¬í…Œí¬", "ì ê¸ˆ", "ì‚¬íšŒì´ˆë…„ìƒ", "ì²­ì•½"], 60.0),
        "2030ì¸ê°„ê´€ê³„": (["ì¸", "ì†Œê°œíŒ…", "ê²°í˜¼", "ì¶•ì˜ê¸ˆ", "ì¸ë§¥", "ì†ì ˆ", "ë’·ë‹´í™”"], 55.0),
    }

    # â”€â”€ ìˆì¸  ë¶€ì í•© ê°ì  (ì¼ìƒ ì¡ë‹´ë¥˜ = ì¡°íšŒìˆ˜ ì €ì¡°) â”€â”€
    # â€» 2030 íƒ€ê²Ÿ ì „ëµ: ì§ì¥/ì—°ì•  ì°ì€ í•µì‹¬ ì½˜í…ì¸ ì´ë¯€ë¡œ ê°ì  ì œê±°
    BORING_CONTENT_PENALTIES = [
        (r"ì„¤ê±°ì§€|ì‹œëŒ|ì‹œì–´ë¨¸ë‹ˆ|íŒŒí˜¼", -50.0, "ê²°í˜¼ ê°€ì •ì‚¬"),
        (r"ë‹¤ì´ì–´íŠ¸|ì‹ë‹¨|í—¬ìŠ¤|ìš´ë™ë£¨í‹´", -20.0, "ë‹¤ì´ì–´íŠ¸"),
        (r"ì¹´í˜|ë§›ì§‘|ë””ì €íŠ¸|ë¹µì§‘|ë¸ŒëŸ°ì¹˜", -20.0, "ì¹´í˜/ë§›ì§‘"),
        (r"ì—´ì• |ê²°ë³„|ì†Œì†ì‚¬|ì»´ë°±|íŒ¬ì‹¸", -15.0, "ì—°ì˜ˆ ê°€ì‹­"),
    ]

    def _extract_article_urls_requests(self, list_url: str) -> list[str]:
        """requestsë¡œ ëª©ë¡ í˜ì´ì§€ HTMLì—ì„œ ê°œë³„ ê¸€ URL+ì œëª©+ì°¸ì—¬ë„ ì¶”ì¶œ (ë³µí•© ì ìˆ˜ ì •ë ¬)"""
        try:
            import requests as _req
            headers = {
                "User-Agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/133.0.0.0 Safari/537.36"
                ),
                "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8",
                "Referer": "https://gall.dcinside.com/",
            }
            r = _req.get(list_url, headers=headers, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            # â”€â”€ URL + ì œëª© + ì°¸ì—¬ë„(ì¶”ì²œ/ì¡°íšŒ/ëŒ“ê¸€) í•¨ê»˜ ì¶”ì¶œ â”€â”€
            # (url, title, recommend, view_count, comment_count) íŠœí”Œ
            url_title_pairs = []

            # â”€â”€ DCì¸ì‚¬ì´ë“œ: í–‰(row) ë‹¨ìœ„ë¡œ ì¶”ì²œìˆ˜/ì¡°íšŒìˆ˜/ëŒ“ê¸€ìˆ˜ ì¶”ì¶œ â”€â”€
            dc_engagement = {}  # url â†’ {rec, view, comment}
            # tr.ub-content ê° í–‰ì—ì„œ ì¶”ì²œìˆ˜(gall_recommend), ì¡°íšŒìˆ˜, ëŒ“ê¸€ìˆ˜ ì¶”ì¶œ
            dc_rows_html = re.findall(
                r'<tr\s+class="ub-content[^"]*"[^>]*>(.*?)</tr>',
                html, re.DOTALL
            )
            for row_html in dc_rows_html:
                # URL
                url_m = re.search(
                    r'href="(/board/view/\?id=\w+&no=\d+[^"]*)"', row_html
                )
                if not url_m:
                    continue
                row_url = "https://gall.dcinside.com" + url_m.group(1).replace("&amp;", "&")

                # ì¶”ì²œìˆ˜ (gall_recommend)
                rec_m = re.search(r'<td[^>]*class="gall_recommend"[^>]*>\s*(\d+)\s*</td>', row_html)
                rec = int(rec_m.group(1)) if rec_m else 0

                # ì¡°íšŒìˆ˜ (gall_count)
                view_m = re.search(r'<td[^>]*class="gall_count"[^>]*>\s*(\d+)\s*</td>', row_html)
                view = int(view_m.group(1)) if view_m else 0

                # ëŒ“ê¸€ìˆ˜ (reply_numbox ì•ˆì˜ ìˆ«ì)
                cmt_m = re.search(r'reply_numbox.*?>\[(\d+)\]', row_html)
                cmt = int(cmt_m.group(1)) if cmt_m else 0

                dc_engagement[row_url] = {"rec": rec, "view": view, "comment": cmt}

            # ë””ì‹œ: view-msg ì†ì„± <a> íƒœê·¸ (ì œëª© ë§í¬ë§Œ ì •í™•íˆ ë§¤ì¹­)
            dc_title_links = re.findall(
                r'<a\s+href="(/board/view/\?id=\w+&no=\d+[^"]*)"\s*view-msg\s*[^>]*>'
                r'(.*?)</a>',
                html, re.DOTALL
            )
            for path, inner_html in dc_title_links:
                full = "https://gall.dcinside.com" + path.replace("&amp;", "&")
                # inner_htmlì—ì„œ íƒœê·¸ ì œê±° â†’ ìˆœìˆ˜ ì œëª© í…ìŠ¤íŠ¸
                title = re.sub(r'<[^>]+>', '', inner_html).strip()
                if title:
                    url_title_pairs.append((full, title))

            # í´ë°±: view-msg ì—†ëŠ” ì¼ë°˜ íŒ¨í„´
            if not url_title_pairs:
                dc_rows = re.findall(
                    r'<a[^>]*href="(/board/view/\?id=\w+&no=\d+[^"]*)"[^>]*>'
                    r'\s*(?:<[^>]*>)*\s*([^<]{2,})',
                    html
                )
                for path, title in dc_rows:
                    full = "https://gall.dcinside.com" + path.replace("&amp;", "&")
                    url_title_pairs.append((full, title.strip()))

            # ë””ì‹œ: reply_numbox ë“± ì „ì²´ URL (ì œëª© ì—†ì´, ì¤‘ë³µ ì œê±°ìš©)
            dc_full_pat = re.findall(
                r'https?://gall\.dcinside\.com/board/view/\?id=\w+&no=\d+[^\s"\'<>]*',
                html
            )
            existing_urls = {u for u, _ in url_title_pairs}
            for u in dc_full_pat:
                if u not in existing_urls:
                    url_title_pairs.append((u, ""))

            # ë„¤ì´íŠ¸íŒ: /talk/ìˆ«ì
            nate_pat = re.findall(r'href="(/talk/\d+)"', html)
            for path in nate_pat:
                url_title_pairs.append(("https://pann.nate.com" + path, ""))

            nate_full = re.findall(r'https?://pann\.nate\.com/talk/\d+', html)
            for u in nate_full:
                url_title_pairs.append((u, ""))

            # ì—í¨ì½”ë¦¬ì•„: /ìˆ«ì (document_srl 10ìë¦¬)
            fm_links = re.findall(
                r'<a[^>]*href="(/\d{8,})"[^>]*>(.*?)</a>', html, re.DOTALL
            )
            for path, inner in fm_links:
                full = "https://www.fmkorea.com" + path
                title = re.sub(r'<[^>]+>', '', inner).strip()
                url_title_pairs.append((full, title))

            # ë£¨ë¦¬ì›¹: bbs.ruliweb.com/.../read/ìˆ«ì
            ruli_links = re.findall(
                r'<a[^>]*href="(https?://bbs\.ruliweb\.com/[^"]*read/\d+)"[^>]*>(.*?)</a>',
                html, re.DOTALL
            )
            for href, inner in ruli_links:
                title = re.sub(r'<[^>]+>', '', inner).strip()
                if title and len(title) > 3:
                    url_title_pairs.append((href, title))

            # ì¸ìŠ¤í‹°ì¦ˆ: /pt/ìˆ«ì
            instiz_links = re.findall(
                r'href="(?:https?://www\.instiz\.net)?(/pt/\d+)[^"]*"', html
            )
            for path in instiz_links:
                url_title_pairs.append(("https://www.instiz.net" + path, ""))

            # ë”ì¿ : /hot/ìˆ«ì
            theqoo_links = re.findall(
                r'href="(/hot/\d{5,})"', html
            )
            for path in theqoo_links:
                url_title_pairs.append(("https://theqoo.net" + path, ""))

            # â”€â”€ ê³µì§€/ì†Œê°œê¸€ í•„í„°ë§ â”€â”€
            filtered = []
            for u, title in url_title_pairs:
                no_m = re.search(r'no=(\d+)', u)
                if no_m and no_m.group(1) in self.DC_NOTICE_NOS:
                    continue
                if no_m and ("dcbest" in u or "hit" in u):
                    if int(no_m.group(1)) < 100000:
                        continue
                if title and any(kw in title for kw in self.BLOCK_KEYWORDS):
                    continue
                filtered.append((u, title))

            # â”€â”€ ë³µí•© ë°”ì´ëŸ´ ì ìˆ˜ ì •ë ¬ (ì°¸ì—¬ë„ + í‚¤ì›Œë“œ + ë‚šì‹œ ê°ì ) â”€â”€
            def _viral_score(pair):
                u, t = pair
                score = 0.0

                # 1) ì°¸ì—¬ë„ ì ìˆ˜ (ëŒ“ê¸€ ìµœìš°ì„ ! ëŒ“ê¸€ ë§ìŒ = ì°¬ë°˜ ë…¼ë€ = ëŒ“ê¸€ì°½ í­ë°œ)
                eng = dc_engagement.get(u, {})
                rec = eng.get("rec", 0)
                view = eng.get("view", 0)
                cmt = eng.get("comment", 0)
                score += rec * 2.0 + cmt * 5.0 + view * 0.01
                # â˜… ëŒ“ê¸€ 100ê°œ ì´ìƒ = ì•Œê³ ë¦¬ì¦˜ í­ë°œ ë³´ì¥ ì†Œì¬ (ìŠˆí¼ ë¶€ìŠ¤íŠ¸)
                if cmt >= 100:
                    score += 200.0
                elif cmt >= 50:
                    score += 80.0
                elif cmt >= 20:
                    score += 30.0

                # 2) ë°”ì´ëŸ´ í‚¤ì›Œë“œ ê°€ì‚°ì  (ê° í‚¤ì›Œë“œ +3)
                kw_count = sum(1 for kw in self.VIRAL_BOOST_KEYWORDS if kw in t)
                score += kw_count * 3.0

                # 3) ë‚šì‹œ/ìŠ¤íŒ¸ íŒ¨í„´ ê°ì  (-50 per match)
                for pat in self.CLICKBAIT_PENALTY_PATTERNS:
                    if re.search(pat, t):
                        score -= 50.0

                # 4) ìˆì¸  í­ë°œë ¥ ì¹´í…Œê³ ë¦¬ ë¶€ìŠ¤íŠ¸ (í•µì‹¬!)
                for cat_name, (cat_kws, cat_boost) in self.VIRAL_CATEGORY_BOOSTS.items():
                    if any(ck in t for ck in cat_kws):
                        score += cat_boost
                        break  # ìµœê³  ì¹´í…Œê³ ë¦¬ 1ê°œë§Œ ì ìš©

                # 5) ìˆì¸  ë¶€ì í•© ì½˜í…ì¸  ê°ì  (ì¼ìƒ ì¡ë‹´)
                for pat, penalty, label in self.BORING_CONTENT_PENALTIES:
                    if re.search(pat, t):
                        score += penalty  # ìŒìˆ˜
                        break

                # 6) ì œëª© ê¸¸ì´ ë³´ì • (ë„ˆë¬´ ì§§ì€ ì œëª© = ì €í’ˆì§ˆ)
                if len(t) < 5:
                    score -= 10.0

                return score

            filtered.sort(key=_viral_score, reverse=True)

            # ì œëª© ì •ë³´ë¥¼ ì¸ìŠ¤í„´ìŠ¤ì— ì €ì¥ (í›„ì† ë‹¨ê³„ì—ì„œ í™œìš©)
            self._url_titles = {u: t for u, t in filtered if t}

            result_urls = [u for u, _ in filtered]
            if result_urls:
                top = filtered[0]
                top_title = top[1] if top[1] else "(ì œëª© ë¯¸í™•ì¸)"
                top_eng = dc_engagement.get(top[0], {})
                top_score = _viral_score(top)
                print(f"  âœ… requestsë¡œ {len(result_urls)}ê°œ URL ì¶”ì¶œ (ê³µì§€ ì œì™¸)")
                print(f"     ğŸ”¥ 1ìˆœìœ„: {top_title[:50]}")
                print(f"     ğŸ“Š ì ìˆ˜: {top_score:.1f} (ì¶”ì²œ {top_eng.get('rec', 0)} / ì¡°íšŒ {top_eng.get('view', 0)} / ëŒ“ê¸€ {top_eng.get('comment', 0)})")
            else:
                print(f"  âš ï¸  requests HTMLì—ì„œ URL ë¯¸ë°œê²¬")
            return result_urls

        except Exception as e:
            print(f"  âš ï¸  requests ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            return []

    def _extract_article_urls_apify(self, list_url: str) -> list[str]:
        """Apifyë¡œ ëª©ë¡ í˜ì´ì§€ì—ì„œ ê°œë³„ ê¸€ URL ì¶”ì¶œ (í´ë°±)"""
        try:
            list_input = {
                "startUrls": [{"url": list_url}],
                "crawlerType": "playwright:firefox",
                "maxCrawlPages": 1,
                "maxCrawlDepth": 0,
                "outputFormats": ["markdown"],
                "removeCookieWarnings": True,
                "saveScreenshots": False,
            }
            list_run = self.client.actor("apify/website-content-crawler").call(
                run_input=list_input, timeout_secs=120,
            )

            urls = []
            list_dataset = self.client.dataset(list_run["defaultDatasetId"])
            for item in list_dataset.iterate_items():
                page_text = item.get("text", "") or item.get("markdown", "")

                dc_pat = re.findall(
                    r'https?://gall\.dcinside\.com/board/view/\?id=\w+&no=\d+[^\s"\'<>]*',
                    page_text + " " + str(item)
                )
                urls.extend(dc_pat)

                nate_pat = re.findall(
                    r'https?://pann\.nate\.com/talk/\d+',
                    page_text + " " + str(item)
                )
                urls.extend(nate_pat)

            return urls

        except Exception as e:
            print(f"  âš ï¸  Apify ëª©ë¡ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return []

    def _scrape_apify_with_screenshots(self) -> list[dict]:
        """
        v4.2: 2ë‹¨ê³„ í¬ë¡¤ë§ â€” ëª©ë¡â†’URL ì¶”ì¶œâ†’ê°œë³„ ê¸€ í¬ë¡¤ë§
        [1ë‹¨ê³„] ê¸€ ëª©ë¡ í˜ì´ì§€ì—ì„œ ê°œë³„ ê¸€ URLë§Œ ì¶”ì¶œ
        [2ë‹¨ê³„] ê° ê°œë³„ ê¸€ URLì„ ë³„ë„ë¡œ í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ·
        """
        source_info = self.SOURCES[self.config.source]
        url = source_info["best_url"]
        if self.config.source == "dcinside":
            url = url.format(gallery=self.config.gallery)
        # dcinside_realtime_best, dcinside_hitì€ format ë¶ˆí•„ìš”

        print(f"  ğŸ”— ëª©ë¡ URL: {url}")
        print(f"  ğŸ“¡ [1ë‹¨ê³„] ê¸€ ëª©ë¡ì—ì„œ ê°œë³„ URL ì¶”ì¶œ ì¤‘...")

        try:
            # â”â” 1ë‹¨ê³„: ëª©ë¡ í˜ì´ì§€ì—ì„œ ê°œë³„ ê¸€ URL ì¶”ì¶œ â”â”
            # requestsë¡œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸° (Apifyë³´ë‹¤ ë¹ ë¥´ê³  ë¬´ë£Œ)
            article_urls = self._extract_article_urls_requests(url)

            # requests ì‹¤íŒ¨ ì‹œ Apify í´ë°±
            if not article_urls and self.client:
                print(f"  ğŸ“¡ requests ì‹¤íŒ¨, Apifyë¡œ 1ë‹¨ê³„ ì¬ì‹œë„...")
                article_urls = self._extract_article_urls_apify(url)

            # ì¤‘ë³µ ì œê±° + ì œí•œ
            seen = set()
            unique_urls = []
            for u in article_urls:
                base = re.sub(r'&page=\d+', '', u)
                if base not in seen:
                    seen.add(base)
                    unique_urls.append(u)
            unique_urls = unique_urls[:self.config.crawl_count]

            if not unique_urls:
                print(f"  âš ï¸  ê°œë³„ ê¸€ URLì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í´ë°± ì‹œë„...")
                return self._scrape_fallback_with_fake_screenshots()

            print(f"  âœ… {len(unique_urls)}ê°œ ê¸€ URL ì¶”ì¶œ ì™„ë£Œ")
            for u in unique_urls:
                print(f"     ğŸ“„ {u[:80]}")

            # â”â” 2ë‹¨ê³„: ê° ê°œë³„ ê¸€ í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ· â”â”
            print(f"  ğŸ“¡ [2ë‹¨ê³„] ê°œë³„ ê¸€ í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ·...")
            posts = []

            for art_idx, art_url in enumerate(unique_urls):
                # 1ë‹¨ê³„ì—ì„œ ê°€ì ¸ì˜¨ ì œëª© ì •ë³´ í™œìš©
                known_title = getattr(self, '_url_titles', {}).get(art_url, "")
                title_display = known_title[:40] if known_title else art_url[:60]
                print(f"  ğŸ“– [{art_idx+1}/{len(unique_urls)}] {title_display}...")

                post = None

                # â”€â”€ requestsë¡œ ë³¸ë¬¸ ë¨¼ì € ì‹œë„ (ë¹ ë¥´ê³  ì•ˆì •ì ) â”€â”€
                try:
                    req_post = self._fetch_article_by_platform(art_url)
                    if req_post and len(req_post.get("content", "")) >= 200:
                        # í’ˆì§ˆ í•„í„°
                        text = req_post["content"]
                        title = req_post["title"]
                        if any(kw in text for kw in self.BLOCK_KEYWORDS):
                            blk = [kw for kw in self.BLOCK_KEYWORDS if kw in text]
                            print(f"     ğŸš« ì†Œê°œ/ê³µì§€ê¸€ ì°¨ë‹¨: {blk[0] if blk else 'unknown'}")
                            continue
                        if any(kw in title for kw in self.BLOCK_KEYWORDS):
                            print(f"     ğŸš« ì œëª©ì—ì„œ ì†Œê°œê¸€ ê°ì§€, ê±´ë„ˆëœ€")
                            continue
                        spam_count = sum(1 for kw in self.UI_KEYWORDS if kw in text)
                        if spam_count >= 2:
                            print(f"     âš ï¸  UI í…ìŠ¤íŠ¸ ê°ì§€ ({spam_count}ê°œ), ê±´ë„ˆëœ€")
                            continue
                        post = req_post
                        print(f"     âœ… requests ë³¸ë¬¸ í™•ë³´ ({len(text)}ì)")
                except Exception as e:
                    print(f"     âš ï¸  requests ì‹¤íŒ¨: {e}")

                # â”€â”€ requests ì‹¤íŒ¨ ì‹œ Apify í´ë°± â”€â”€
                if not post:
                    try:
                        art_input = {
                            "startUrls": [{"url": art_url}],
                            "crawlerType": "playwright:firefox",
                            "maxCrawlPages": 1,
                            "maxCrawlDepth": 0,
                            "outputFormats": ["markdown"],
                            "removeCookieWarnings": True,
                            "saveScreenshots": True,
                            "screenshotQuality": 80,
                            "removeElementsCssSelector": self.DC_REMOVE_CSS,
                        }
                        art_run = self.client.actor("apify/website-content-crawler").call(
                            run_input=art_input, timeout_secs=120,
                        )

                        art_dataset = self.client.dataset(art_run["defaultDatasetId"])
                        art_kvs = self.client.key_value_store(art_run["defaultKeyValueStoreId"])

                        for item in art_dataset.iterate_items():
                            text = item.get("text", "") or item.get("markdown", "")
                            if len(text) < 200:
                                continue
                            if any(kw in text for kw in self.BLOCK_KEYWORDS):
                                blk = [kw for kw in self.BLOCK_KEYWORDS if kw in text]
                                print(f"     ğŸš« ì†Œê°œ/ê³µì§€ê¸€ ì°¨ë‹¨: {blk[0] if blk else 'unknown'}")
                                continue
                            item_title = item.get("metadata", {}).get("title", "")
                            if any(kw in item_title for kw in self.BLOCK_KEYWORDS):
                                print(f"     ğŸš« ì œëª©ì—ì„œ ì†Œê°œê¸€ ê°ì§€, ê±´ë„ˆëœ€")
                                continue
                            spam_count = sum(1 for kw in self.UI_KEYWORDS if kw in text)
                            if spam_count >= 2:
                                continue

                            post = {
                                "title": item_title or "ì œëª©ì—†ìŒ",
                                "content": text[:3000],
                                "url": item.get("url", art_url),
                                "source": self.config.source,
                                "screenshots": [],
                            }
                            # ìŠ¤í¬ë¦°ìƒ· ë‹¤ìš´ë¡œë“œ
                            ss_key = item.get("screenshotUrl", "")
                            if ss_key:
                                ss_path = self._download_screenshot(
                                    art_kvs, ss_key, len(posts)
                                )
                                if ss_path:
                                    post["screenshots"].append(ss_path)
                            break

                    except Exception as e:
                        print(f"     âš ï¸  Apify í´ë°±ë„ ì‹¤íŒ¨: {e}")

                if post:
                    posts.append(post)

            # ìŠ¤í¬ë¦°ìƒ· ì—†ëŠ” ê¸€ â†’ í…ìŠ¤íŠ¸ ê¸°ë°˜ ìƒì„±
            for post in posts:
                if not post["screenshots"]:
                    fake_ss = self._generate_text_screenshots(post)
                    post["screenshots"] = fake_ss

            if not posts:
                print(f"  âš ï¸  í¬ë¡¤ë§ëœ ê¸€ ì¤‘ ë³¸ë¬¸ì´ ìˆëŠ” ê¸€ì´ ì—†ìŠµë‹ˆë‹¤")
                return self._scrape_fallback_with_fake_screenshots()

            print(f"  âœ… {len(posts)}ê°œ ê¸€ ìˆ˜ì§‘ ì™„ë£Œ! (ë³¸ë¬¸ í™•ì¸ë¨)")
            for p in posts:
                print(f"     ğŸ“„ {p['title'][:30]} ({len(p['content'])}ì)")
            return posts

        except Exception as e:
            print(f"  âš ï¸  Apify ì—ëŸ¬: {e}")
            return self._scrape_fallback_with_fake_screenshots()

    def _scrape_single_with_screenshot(self, url: str) -> list[dict]:
        """ë‹¨ì¼ URL í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ·"""
        print(f"  ğŸ”— ë‹¨ì¼ URL: {url}")

        post = {"title": "", "content": "", "url": url,
                "source": "direct", "screenshots": []}

        if self.client:
            try:
                run_input = {
                    "startUrls": [{"url": url}],
                    "crawlerType": "playwright:firefox",
                    "maxCrawlPages": 1,
                    "maxCrawlDepth": 0,
                    "outputFormats": ["markdown"],
                    "saveScreenshots": True,
                    "screenshotQuality": 80,
                }
                run = self.client.actor("apify/website-content-crawler").call(
                    run_input=run_input, timeout_secs=90
                )
                dataset = self.client.dataset(run["defaultDatasetId"])
                for item in dataset.iterate_items():
                    post["title"] = item.get("metadata", {}).get("title", "")
                    post["content"] = (
                        item.get("text", "") or item.get("markdown", "")
                    )[:3000]

                    # ìŠ¤í¬ë¦°ìƒ·
                    ss_key = item.get("screenshotUrl", "")
                    if ss_key:
                        kvs = self.client.key_value_store(
                            run["defaultKeyValueStoreId"]
                        )
                        ss_path = self._download_screenshot(kvs, ss_key, 0)
                        if ss_path:
                            post["screenshots"].append(ss_path)
                    break

            except Exception as e:
                print(f"  âš ï¸  Apify ì—ëŸ¬: {e}, í´ë°± ì‹œë„...")

        # ë‚´ìš©ì´ ì—†ìœ¼ë©´ requests í´ë°±
        if not post["content"]:
            post = self._fetch_simple(url)

        # ìŠ¤í¬ë¦°ìƒ· ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ìƒì„±
        if not post["screenshots"]:
            post["screenshots"] = self._generate_text_screenshots(post)

        return [post]

    def _download_screenshot(self, kvs, key: str, idx: int) -> Optional[str]:
        """Apify KVSì—ì„œ ìŠ¤í¬ë¦°ìƒ· ë‹¤ìš´ë¡œë“œ"""
        try:
            ss_dir = os.path.join(self.config.output_dir, "_screenshots")
            os.makedirs(ss_dir, exist_ok=True)
            path = os.path.join(ss_dir, f"screenshot_{idx}.png")

            record = kvs.get_record(key)
            if record and record.get("value"):
                with open(path, "wb") as f:
                    f.write(record["value"])
                print(f"  ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: {path}")
                return path
        except Exception as e:
            print(f"  âš ï¸  ìŠ¤í¬ë¦°ìƒ· ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

    def _fetch_dc_article_requests(self, url: str) -> Optional[dict]:
        """requestsë¡œ ë””ì‹œ ê°œë³„ ê¸€ ë³¸ë¬¸+ëŒ“ê¸€ ì§ì ‘ ì¶”ì¶œ (Apify ë¶ˆí•„ìš”, ë¹ ë¦„)"""
        try:
            import requests as _req
            headers = {
                "User-Agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/133.0.0.0 Safari/537.36"
                ),
                "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8",
                "Referer": "https://gall.dcinside.com/",
            }
            r = _req.get(url, headers=headers, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            # ì œëª© ì¶”ì¶œ
            title = ""
            title_m = re.search(r'<span\s+class="title_subject">(.*?)</span>', html)
            if title_m:
                title = re.sub(r'<[^>]+>', '', title_m.group(1)).strip()
            if not title:
                title_m = re.search(r'<title>(.*?)</title>', html)
                title = title_m.group(1).strip() if title_m else ""

            # ë³¸ë¬¸ ì¶”ì¶œ (write_div ì˜ì—­)
            body = ""
            body_m = re.search(
                r'<div\s+class="write_div"[^>]*>(.*?)</div>\s*(?:<div\s+class="btn)',
                html, re.DOTALL
            )
            if not body_m:
                body_m = re.search(
                    r'<div\s+class="write_div"[^>]*>(.*?)</div>',
                    html, re.DOTALL
                )
            if body_m:
                raw = body_m.group(1)
                # <br> â†’ ì¤„ë°”ê¿ˆ, íƒœê·¸ ì œê±°
                raw = re.sub(r'<br\s*/?>', '\n', raw)
                raw = re.sub(r'<[^>]+>', ' ', raw)
                raw = re.sub(r'&[a-zA-Z]+;', ' ', raw)
                raw = re.sub(r'&#\d+;', ' ', raw)
                body = re.sub(r'\s+', ' ', raw).strip()

            # ëŒ“ê¸€ ì¶”ì¶œ (ë² ìŠ¤íŠ¸ ëŒ“ê¸€ ìš°ì„ )
            comments = []
            cmt_matches = re.findall(
                r'<p\s+class="usertxt\s*[^"]*">(.*?)</p>', html
            )
            for cmt in cmt_matches[:5]:
                cmt_text = re.sub(r'<[^>]+>', '', cmt).strip()
                if cmt_text and len(cmt_text) > 5:
                    comments.append(cmt_text)

            if not body or len(body) < 50:
                return None

            return {
                "title": title,
                "content": body[:3000],
                "url": url,
                "source": self.config.source,
                "comments": comments,
                "screenshots": [],
            }

        except Exception as e:
            return None

    def _fetch_article_by_platform(self, url: str) -> Optional[dict]:
        """URL ê¸°ë°˜ìœ¼ë¡œ í”Œë«í¼ ìë™ ê°ì§€ â†’ í•´ë‹¹ í”Œë«í¼ íŒŒì„œë¡œ ë³¸ë¬¸ ì¶”ì¶œ"""
        if "dcinside.com" in url:
            return self._fetch_dc_article_requests(url)
        elif "fmkorea.com" in url:
            return self._fetch_fmkorea_article(url)
        elif "ruliweb.com" in url:
            return self._fetch_ruliweb_article(url)
        elif "instiz.net" in url:
            return self._fetch_instiz_article(url)
        elif "theqoo.net" in url:
            return self._fetch_theqoo_article(url)
        elif "pann.nate.com" in url:
            return self._fetch_natepann_article(url)
        return None

    _REQ_HEADERS = {
        "User-Agent": (
            "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
            "AppleWebKit/537.36 (KHTML, like Gecko) "
            "Chrome/133.0.0.0 Safari/537.36"
        ),
        "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8",
    }

    def _clean_html(self, raw: str) -> str:
        """HTML íƒœê·¸ ì œê±° + ê³µë°± ì •ë¦¬"""
        raw = re.sub(r'<br\s*/?>', '\n', raw)
        raw = re.sub(r'<[^>]+>', ' ', raw)
        raw = re.sub(r'&[a-zA-Z]+;', ' ', raw)
        raw = re.sub(r'&#\d+;', ' ', raw)
        return re.sub(r'\s+', ' ', raw).strip()

    def _fetch_fmkorea_article(self, url: str) -> Optional[dict]:
        """ì—í¨ì½”ë¦¬ì•„ ê°œë³„ ê¸€ ë³¸ë¬¸ ì¶”ì¶œ"""
        try:
            import requests as _req
            r = _req.get(url, headers=self._REQ_HEADERS, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            title = ""
            title_m = re.search(r'<title>(.*?)</title>', html)
            if title_m:
                title = self._clean_html(title_m.group(1))

            # document_* í´ë˜ìŠ¤ ë˜ëŠ” xe_content
            body = ""
            body_m = re.search(
                r'class="document_\d+_\d+\s+[^"]*xe_content[^"]*"[^>]*>(.*?)</div>\s*(?:<div|<script)',
                html, re.DOTALL
            )
            if not body_m:
                body_m = re.search(r'class="xe_content"[^>]*>(.*?)</div>', html, re.DOTALL)
            if body_m:
                body = self._clean_html(body_m.group(1))

            # ëŒ“ê¸€ ì¶”ì¶œ
            comments = []
            cmt_matches = re.findall(r'class="xe_content"[^>]*>(.*?)</div>', html)
            for i, cmt in enumerate(cmt_matches[1:6]):  # ì²« ë²ˆì§¸ëŠ” ë³¸ë¬¸
                cmt_text = self._clean_html(cmt)
                if cmt_text and 5 < len(cmt_text) < 200:
                    comments.append(cmt_text)

            if not body or len(body) < 50:
                return None

            return {
                "title": title,
                "content": body[:3000],
                "url": url,
                "source": "fmkorea",
                "comments": comments,
                "screenshots": [],
            }
        except Exception:
            return None

    def _fetch_ruliweb_article(self, url: str) -> Optional[dict]:
        """ë£¨ë¦¬ì›¹ ê°œë³„ ê¸€ ë³¸ë¬¸ ì¶”ì¶œ"""
        try:
            import requests as _req
            r = _req.get(url, headers=self._REQ_HEADERS, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            title = ""
            title_m = re.search(r'<title>(.*?)</title>', html)
            if title_m:
                title = self._clean_html(title_m.group(1))

            body = ""
            # view_content í´ë˜ìŠ¤ (autolink ë“± ë’¤ì— ì˜¬ ìˆ˜ ìˆìŒ)
            body_m = re.search(
                r'class="view_content[^"]*"[^>]*>(.*?)<div\s+class="(?:view_bottom|board_bottom|row)',
                html, re.DOTALL
            )
            if not body_m:
                body_m = re.search(r'class="view_content[^"]*"[^>]*>(.*?)</article>', html, re.DOTALL)
            if body_m:
                body = self._clean_html(body_m.group(1))

            # ëŒ“ê¸€
            comments = []
            cmt_matches = re.findall(r'class="text_wrapper[^"]*"[^>]*>(.*?)</div>', html)
            for cmt in cmt_matches[:5]:
                cmt_text = self._clean_html(cmt)
                if cmt_text and 5 < len(cmt_text) < 200:
                    comments.append(cmt_text)

            if not body or len(body) < 50:
                return None

            return {
                "title": title,
                "content": body[:3000],
                "url": url,
                "source": "ruliweb",
                "comments": comments,
                "screenshots": [],
            }
        except Exception:
            return None

    def _fetch_instiz_article(self, url: str) -> Optional[dict]:
        """ì¸ìŠ¤í‹°ì¦ˆ ê°œë³„ ê¸€ ë³¸ë¬¸ ì¶”ì¶œ"""
        try:
            import requests as _req
            r = _req.get(url, headers=self._REQ_HEADERS, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            title = ""
            title_m = re.search(r'<title>(.*?)</title>', html)
            if title_m:
                title = self._clean_html(title_m.group(1))
                # "- ì¸ìŠ¤í‹°ì¦ˆ(instiz) ..." ì ‘ë¯¸ì‚¬ ì œê±°
                title = re.sub(r'\s*-\s*ì¸ìŠ¤í‹°ì¦ˆ.*$', '', title)

            body = ""
            body_m = re.search(r'class="memo_content[^"]*"[^>]*>(.*?)</div>', html, re.DOTALL)
            if not body_m:
                body_m = re.search(r'id="memo_content_\d+"[^>]*>(.*?)</div>', html, re.DOTALL)
            if body_m:
                body = self._clean_html(body_m.group(1))

            # ëŒ“ê¸€
            comments = []
            cmt_matches = re.findall(r'class="reply_content[^"]*"[^>]*>(.*?)</div>', html)
            for cmt in cmt_matches[:5]:
                cmt_text = self._clean_html(cmt)
                if cmt_text and 5 < len(cmt_text) < 200:
                    comments.append(cmt_text)

            if not body or len(body) < 50:
                return None

            return {
                "title": title,
                "content": body[:3000],
                "url": url,
                "source": "instiz",
                "comments": comments,
                "screenshots": [],
            }
        except Exception:
            return None

    def _fetch_theqoo_article(self, url: str) -> Optional[dict]:
        """ë”ì¿  ê°œë³„ ê¸€ ë³¸ë¬¸ ì¶”ì¶œ (Rhymix/XE CMS ê¸°ë°˜)"""
        try:
            import requests as _req
            r = _req.get(url, headers=self._REQ_HEADERS, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            title = ""
            title_m = re.search(r'<title>(.*?)</title>', html)
            if title_m:
                title = self._clean_html(title_m.group(1))
                title = re.sub(r'\s*-\s*ë”ì¿ .*$', '', title)

            body = ""
            # xe_content / rhymix_content
            body_m = re.search(
                r'class="[^"]*xe_content[^"]*"[^>]*>(.*?)</div>\s*(?:<div\s+class="(?:document_|rd_body|comment)|<script)',
                html, re.DOTALL
            )
            if not body_m:
                body_m = re.search(r'class="[^"]*xe_content[^"]*"[^>]*>(.*?)</div>', html, re.DOTALL)
            if body_m:
                body = self._clean_html(body_m.group(1))

            # ëŒ“ê¸€
            comments = []
            cmt_matches = re.findall(r'class="[^"]*xe_content[^"]*"[^>]*>(.*?)</div>', html)
            for cmt in cmt_matches[1:6]:
                cmt_text = self._clean_html(cmt)
                if cmt_text and 5 < len(cmt_text) < 200:
                    comments.append(cmt_text)

            if not body or len(body) < 50:
                return None

            return {
                "title": title,
                "content": body[:3000],
                "url": url,
                "source": "theqoo",
                "comments": comments,
                "screenshots": [],
            }
        except Exception:
            return None

    def _fetch_natepann_article(self, url: str) -> Optional[dict]:
        """ë„¤ì´íŠ¸íŒ ê°œë³„ ê¸€ ë³¸ë¬¸ ì¶”ì¶œ"""
        try:
            import requests as _req
            r = _req.get(url, headers=self._REQ_HEADERS, timeout=15)
            r.encoding = "utf-8"
            html = r.text

            title = ""
            title_m = re.search(r'<title>(.*?)</title>', html)
            if title_m:
                title = self._clean_html(title_m.group(1))

            body = ""
            body_m = re.search(r'id="contentArea"[^>]*>(.*?)</div>', html, re.DOTALL)
            if not body_m:
                body_m = re.search(r'class="posting_area[^"]*"[^>]*>(.*?)</div>', html, re.DOTALL)
            if body_m:
                body = self._clean_html(body_m.group(1))

            # ëŒ“ê¸€
            comments = []
            cmt_matches = re.findall(r'class="txt_detail[^"]*"[^>]*>(.*?)</p>', html)
            for cmt in cmt_matches[:5]:
                cmt_text = self._clean_html(cmt)
                if cmt_text and 5 < len(cmt_text) < 200:
                    comments.append(cmt_text)

            if not body or len(body) < 50:
                return None

            return {
                "title": title,
                "content": body[:3000],
                "url": url,
                "source": "natepann",
                "comments": comments,
                "screenshots": [],
            }
        except Exception:
            return None

    def _fetch_simple(self, url: str) -> dict:
        """requests í´ë°± í¬ë¡¤ë§"""
        try:
            headers = {
                "User-Agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36"
                )
            }
            resp = requests.get(url, headers=headers, timeout=15)
            resp.encoding = "utf-8"

            from html.parser import HTMLParser

            class TextExtractor(HTMLParser):
                def __init__(self):
                    super().__init__()
                    self.texts = []
                    self.skip = False
                def handle_starttag(self, tag, attrs):
                    if tag in ("script", "style", "nav", "footer"):
                        self.skip = True
                def handle_endtag(self, tag):
                    if tag in ("script", "style", "nav", "footer"):
                        self.skip = False
                def handle_data(self, data):
                    if not self.skip and data.strip():
                        self.texts.append(data.strip())

            parser = TextExtractor()
            parser.feed(resp.text)
            content = "\n".join(parser.texts)

            title_match = re.search(r"<title>(.*?)</title>", resp.text)
            title = title_match.group(1) if title_match else "í¬ë¡¤ë§ëœ ê¸€"

            return {
                "title": title,
                "content": content[:3000],
                "url": url,
                "source": "fallback",
                "screenshots": [],
            }
        except Exception as e:
            print(f"  âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return {"title": "ì‹¤íŒ¨", "content": "", "url": url,
                    "source": "error", "screenshots": []}

    def _scrape_fallback_with_fake_screenshots(self) -> list[dict]:
        """Apify ì—†ì„ ë•Œ í´ë°± + í…ìŠ¤íŠ¸ ìŠ¤í¬ë¦°ìƒ· ìƒì„±"""
        source_info = self.SOURCES[self.config.source]
        url = source_info["best_url"]
        if self.config.source == "dcinside":
            url = url.format(gallery=self.config.gallery)
        post = self._fetch_simple(url)
        post["screenshots"] = self._generate_text_screenshots(post)
        return [post]

    def _generate_text_screenshots(self, post: dict) -> list[str]:
        """
        ğŸ¨ í…ìŠ¤íŠ¸ ê¸°ë°˜ ê°€ì§œ 'ì»¤ë®¤ë‹ˆí‹° ìŠ¤í¬ë¦°ìƒ·' ìƒì„±
        ì‹¤ì œ ë””ì‹œ/ë„¤ì´íŠ¸íŒ UIë¥¼ í‰ë‚´ë‚¸ ì´ë¯¸ì§€
        """
        print(f"  ğŸ¨ í…ìŠ¤íŠ¸ ê¸°ë°˜ ìŠ¤í¬ë¦°ìƒ· ìƒì„± ì¤‘...")
        ss_dir = os.path.join(self.config.output_dir, "_screenshots")
        os.makedirs(ss_dir, exist_ok=True)

        w, h = self.config.width, self.config.height
        content = post.get("content", "")
        title = post.get("title", "")
        source = post.get("source", "community")

        # ë‚´ìš©ì„ 3~5 ì²­í¬ë¡œ ë¶„í•  (ê° ì²­í¬ê°€ í•œ ì¥ë©´ì˜ ë°°ê²½)
        paragraphs = [p.strip() for p in content.split("\n") if p.strip()]
        if not paragraphs:
            paragraphs = [content[:200]]

        # ìµœì†Œ 3ì¥, ìµœëŒ€ 6ì¥
        chunk_size = max(1, len(paragraphs) // 5)
        text_chunks = []
        for i in range(0, len(paragraphs), max(1, chunk_size)):
            chunk = "\n".join(paragraphs[i:i + chunk_size])
            if chunk.strip():
                text_chunks.append(chunk[:300])
        text_chunks = text_chunks[:6] if text_chunks else ["ë‚´ìš© ì—†ìŒ"]

        font = FontManager.get_font(36)
        title_font = FontManager.get_font(44, bold=True)

        paths = []
        for idx, chunk_text in enumerate(text_chunks):
            img = Image.new("RGB", (w, h))
            draw = ImageDraw.Draw(img)

            # ì»¤ë®¤ë‹ˆí‹° ëŠë‚Œì˜ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½
            # (ì–´ë‘ìš´ ë°°ê²½ + ë³¸ë¬¸ í…ìŠ¤íŠ¸ = ë””ì‹œ/ë„¤ì´íŠ¸íŒ ëŠë‚Œ)
            colors = [
                [(25, 28, 35), (45, 38, 30)],   # ë‹¤í¬ë¸”ë£¨ â†’ ë‹¤í¬ë¸Œë¼ìš´
                [(35, 25, 30), (25, 35, 40)],   # ë‹¤í¬ë ˆë“œ â†’ ë‹¤í¬í‹¸
                [(30, 30, 20), (20, 25, 40)],   # ë‹¤í¬ì˜ë¡œ â†’ ë‹¤í¬ë¸”ë£¨
                [(20, 30, 25), (35, 25, 35)],   # ë‹¤í¬ê·¸ë¦° â†’ ë‹¤í¬í¼í”Œ
                [(35, 30, 20), (25, 20, 35)],   # ë‹¤í¬ì˜¤ë Œì§€ â†’ ë‹¤í¬í¼í”Œ
                [(25, 25, 35), (35, 30, 25)],   # ë‹¤í¬ë¸”ë£¨ â†’ ë‹¤í¬ë¸Œë¼ìš´
            ]
            c1, c2 = colors[idx % len(colors)]
            for y in range(h):
                ratio = y / h
                r = int(c1[0] * (1 - ratio) + c2[0] * ratio)
                g = int(c1[1] * (1 - ratio) + c2[1] * ratio)
                b = int(c1[2] * (1 - ratio) + c2[2] * ratio)
                draw.line([(0, y), (w, y)], fill=(r, g, b))

            # ìƒë‹¨: ì†ŒìŠ¤ í‘œì‹œ ë°”
            bar_h = 80
            draw.rectangle([(0, 0), (w, bar_h)], fill=(18, 18, 22, 230))
            source_labels = {
                "dcinside": "ë””ì‹œì¸ì‚¬ì´ë“œ ë² ìŠ¤íŠ¸",
                "natepann": "ë„¤ì´íŠ¸íŒ HOT",
                "direct": "ì»¤ë®¤ë‹ˆí‹° ê¸€",
                "fallback": "ì»¤ë®¤ë‹ˆí‹°",
                "manual": "ì°",
            }
            label = source_labels.get(source, "ì»¤ë®¤ë‹ˆí‹°")
            draw.text((30, 20), f"ğŸ“‹ {label}", fill=(180, 180, 180), font=font)

            # ì œëª© ì˜ì—­ (ì²« ë²ˆì§¸ ì¥ì—ë§Œ)
            y_offset = bar_h + 30
            if idx == 0 and title:
                # ì œëª© ë°°ê²½ ë°•ìŠ¤
                title_wrapped = textwrap.fill(title[:40], width=20)
                draw.rectangle(
                    [(40, y_offset), (w - 40, y_offset + 120)],
                    fill=(255, 255, 255, 15),
                    outline=(80, 80, 80),
                    width=1
                )
                draw.text(
                    (60, y_offset + 15), title_wrapped,
                    fill=(255, 255, 255), font=title_font
                )
                y_offset += 140

            # ë³¸ë¬¸ í…ìŠ¤íŠ¸ (ì»¤ë®¤ë‹ˆí‹° ê¸€ ëŠë‚Œ)
            # ì¤„ë°”ê¿ˆ ì²˜ë¦¬
            wrapped_lines = []
            for line in chunk_text.split("\n"):
                wrapped = textwrap.fill(line, width=24)  # ì„¸ë¡œ í™”ë©´ì´ë¼ ì¢ê²Œ
                wrapped_lines.extend(wrapped.split("\n"))

            text_y = y_offset + 40
            for line in wrapped_lines[:20]:  # ìµœëŒ€ 20ì¤„
                if text_y > h - 200:
                    break
                # ì•½ê°„ì˜ íˆ¬ëª… ë°°ê²½
                bbox = draw.textbbox((60, text_y), line, font=font)
                text_w = bbox[2] - bbox[0]
                draw.rectangle(
                    [(50, text_y - 5), (70 + text_w, text_y + 42)],
                    fill=(0, 0, 0, 60)
                )
                draw.text(
                    (60, text_y), line,
                    fill=(220, 220, 220), font=font
                )
                text_y += 48

            # í•˜ë‹¨: í˜ì´ì§€ í‘œì‹œ
            page_text = f"{idx + 1} / {len(text_chunks)}"
            draw.text(
                (w // 2 - 30, h - 80), page_text,
                fill=(120, 120, 120), font=font
            )

            # ì €ì¥
            path = os.path.join(ss_dir, f"textss_{idx:02d}.png")
            img.save(path, quality=90)
            paths.append(path)

        print(f"  âœ… {len(paths)}ì¥ ìŠ¤í¬ë¦°ìƒ· ì´ë¯¸ì§€ ìƒì„±")
        return paths


# ============================================================
# ğŸ“ Stage 2: ëŒ€ë³¸ ìƒì„± (Gemini 2.0 Flash)
# ============================================================
class ScriptGenerator:
    """v7.0: Gemini (gemini-2.0-flash) ê¸°ë°˜ â€” 100ë§Œë·° ìˆì¸  ëŒ€ë³¸ ìƒì„±ê¸°

    3ë¶„í•  í”„ë¡¬í”„íŠ¸ ì•„í‚¤í…ì²˜:
      ROLE_PROMPT  â†’ í•µì‹¬ ì—­í•  (1ì¸ì¹­ ì° ì‘ê°€)
      FORMAT_SPEC  â†’ JSON ìŠ¤í‚¤ë§ˆ + ì˜ˆì‹œ
      CONTENT_RULES â†’ ê¸ˆì§€ì‚¬í•­ + 2030 í‚¤ì›Œë“œ + ê°ì • ê³¡ì„ 
    """

    # v6.1 â†’ v6.2: Claude â†’ Gemini ë¡¤ë°± (í¬ë ˆë”§ ë¶€ì¡± ì´ìŠˆ)
    GEMINI_MODEL = "gemini-2.0-flash"

    # â”€â”€ [0/3] DIRECTOR_PERSONA: ëª¨ë“  í…Œë§ˆ ê³µí†µ ìƒìœ„ í˜ë¥´ì†Œë‚˜ â”€â”€
    DIRECTOR_PERSONA = """ë‹¹ì‹ ì€ ì „ ì„¸ê³„ ìˆì¸  íŠ¸ë Œë“œë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” 'ë°”ì´ëŸ´ ì½˜í…ì¸  ë””ë ‰í„°'ì…ë‹ˆë‹¤.
ë‹¨ìˆœíˆ ëŒ€ë³¸ì„ ì“°ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì‹œì²­ìê°€ í™”ë©´ì„ ë©ˆì¶”ê³  ëê¹Œì§€ ë³´ê²Œ ë§Œë“œëŠ” 'í›„í‚¹ì˜ ê¸°ìˆ 'ê³¼ 'ì‹œê°ì  ì¶©ê²©'ì„ ì„¤ê³„í•©ë‹ˆë‹¤.

[3ë‹¨ê³„ ë¶„ì„ í”„ë¡œì„¸ìŠ¤]
Step 1. íŠ¸ë Œë“œ ë¶„ì„: ì´ ì£¼ì œê°€ ì™œ ìˆì¸ ì—ì„œ í„°ì§ˆ ìˆ˜ ìˆëŠ”ì§€(ê³µê°/ë¶„ë…¸/í˜¸ê¸°ì‹¬/ìœ ìµí•¨) ì´ìœ ë¥¼ í•œ ì¤„ë¡œ ì •ì˜.
Step 2. ìˆì¸  4-Scene Formula:
  - 0~3ì´ˆ (ë„íŒŒë¯¼ í›„í‚¹): ì‹œì²­ìì˜ ìƒì‹ì„ íŒŒê´´í•˜ê±°ë‚˜ ê°•í•œ ê³µê°ì„ ìœ ë°œí•˜ëŠ” ì²« ë¬¸ì¥.
  - 4~15ì´ˆ (ë¹Œë“œì—…): "ì™œ?"ë¼ëŠ” ì˜ë¬¸ì´ í•´ì†Œë˜ê¸° ì§ì „ê¹Œì§€ í…ì…˜ ìœ ì§€.
  - 16~50ì´ˆ (ì„íŒ©íŠ¸ íŒ©íŠ¸): í•µì‹¬ ì •ë³´ë‚˜ ë°˜ì „ì„ ì„íŒ©íŠ¸ ìˆê²Œ ì „ë‹¬.
  - 51~60ì´ˆ (ëŒ“ê¸€ ìœ ë„): ì •ë‹µì„ ë§íˆê±°ë‚˜ ì˜ê²¬ì´ ê°ˆë¦¬ê²Œ ë§Œë“¤ì–´ ëŒ“ê¸€ì°½ì„ í„°ëœ¨ë¦¬ëŠ” ì „ëµ.
Step 3. AI ì‹œê°í™”: ëª¨ë“  image_promptëŠ” ì˜ì–´ë¡œ, ì•„ë˜ í‚¤ì›Œë“œë¥¼ ì¡°í•©í•´ 'ìš”ì¦˜ ê°ì„±' ìœ ì§€.
  ê¸°ë³¸ í‚¤ì›Œë“œ: Cinematic, 8k, Trendy Aesthetic, Moody Lighting, High Contrast

[Pace ê·œì¹™] 1ì´ˆë‹¹ 3.5ìŒì ˆ. í•œ ë¬¸ì¥ 20ì ì´ë‚´. ë¶ˆí•„ìš”í•œ ë¯¸ì‚¬ì—¬êµ¬ ì‚­ì œ.

ì£¼ì˜: Step 1ì˜ íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼ëŠ” JSONì— í¬í•¨í•˜ì§€ ë§ˆ. ëŒ€ë³¸ JSONë§Œ ì¶œë ¥."""

    # v6.2: Gemini ë¡¤ë°± â€” DIRECTOR_PERSONAë¥¼ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©
    SYSTEM_PROMPT = DIRECTOR_PERSONA

    # â”€â”€ [1/3] ROLE_PROMPT: í•µì‹¬ ì—­í•  + ë§íˆ¬ â”€â”€
    ROLE_PROMPT = """ë„ˆëŠ” ìê·¹ì ì¸ ì»¤ë®¤ë‹ˆí‹° ì´ìŠˆë¥¼ ì „ë‹¬í•˜ëŠ” ìŠ¤í† ë¦¬í…”ëŸ¬ì•¼.
ì°ì¹œí•œí…Œ ì¹´í†¡ìœ¼ë¡œ ë¶„ë…¸ í† í•˜ë“¯ ë§í•˜ëŠ” ìŠ¤íƒ€ì¼.

[í•µì‹¬ ê·œì¹™ 3ê°œ]
1. ì²« ë¬¸ì¥ = 12ì ì´ë‚´ ê°•ë ¬í•œ ê°íƒ„/ì§ˆë¬¸ ("ì•„ ì§„ì§œ ë¯¸ì³¤ìŒ" "ì´ê²Œ ì‚¬ëŒì´ëƒ")
2. ê°ì • ë¡¤ëŸ¬ì½”ìŠ¤í„° í•„ìˆ˜: shockedâ†’sadâ†’tensionâ†’angryâ†’funnyâ†’neutral (6ì¢…+ ì‚¬ìš©, ê°™ì€ ê°ì • 2ì—°ì†ê¹Œì§€ë§Œ)
3. highlightëŠ” ìµœëŒ€ 2ê°œë§Œ true. ì§„ì§œ í•µì‹¬ ë°˜ì „/í€ì¹˜ë¼ì¸ë§Œ.

[ë§íˆ¬]
- ì–´ë¯¸: ~ì„, ~ìŒ, ~ê±°ë“ , ~ì–ì•„, ~ì¸ë° (ë°˜ë§ í†µì¼)
- ì¶”ì„ìƒˆ: ì•„ë‹ˆ, ì§„ì§œ, ã…‹ã…‹ã…‹, ã„¹ã…‡, ì•„ ê·¼ë°, í—
- ê¸ˆì§€ì–´: í¥ë¯¸ë¡­, ë†€ë¼ìš´, ì¶©ê²©ì , ì•Œì•„ë³´ê² , ì‚´í´ë³´ê² , ê²°ë¡ ì ìœ¼ë¡œ, í•˜ê² ìŠµë‹ˆë‹¤
- text í•œêµ­ì–´ë§Œ 15ì ì´ë‚´. image_prompt ì˜ì–´ë§Œ.

[image_prompt â€” ì ˆëŒ€ ê·œì¹™]
- ì£¼ì œì™€ 100% ì—°ê´€ëœ ì¥ë©´ë§Œ ë¬˜ì‚¬ (ë¬´ê´€í•œ ì´ë¯¸ì§€ ê¸ˆì§€)
- "Same character as scene 1" ì ˆëŒ€ ê¸ˆì§€! ë§¤ ì¥ë©´ ë…ë¦½ì  ë¬˜ì‚¬.
- ë§¤ ì¥ë©´ ì¹´ë©”ë¼ ì•µê¸€ ë‹¬ë¼ì•¼ í•¨: extreme close-up / bird's eye / low angle / wide shot / over-the-shoulder / dutch angle / tracking shot
- ê¸°ë³¸: Cinematic, 8k, High Contrast, Korean webtoon style, bold outlines
- ì²« ì¥ë©´: "Young Korean [ì„±ë³„], [ë¨¸ë¦¬], [ì²´í˜•], [ì˜·], [í‘œì •], extreme close-up, cinematic lighting, 8k, Korean webtoon style"
- ì´í›„ ì¥ë©´: ìºë¦­í„° ì™¸ëª¨ë¥¼ ë§¤ë²ˆ ì§ì ‘ ë¬˜ì‚¬ (í‚¤, ë¨¸ë¦¬, ì˜· ë°˜ë³µ OK)
- í‘œì •: jaw dropped / face burning red / veins popping / tears streaming
- ì¡°ëª…: cinematic lighting, high contrast, dramatic red backlight / single spotlight"""

    # â”€â”€ [2/3] FORMAT_SPEC: JSON ìŠ¤í‚¤ë§ˆ (ê°„ê²°í•˜ê²Œ) â”€â”€
    FORMAT_SPEC = """{
  "title": "ì–´ê·¸ë¡œ ì œëª© 15ì ì´ë‚´",
  "mood": "funny|angry|sad|touching|scary|satisfying|shocking",
  "tags": ["#íƒœê·¸1", ... "#íƒœê·¸15"],
  "thumbnail_text": "ì¸ë„¤ì¼ 5ì ì´ë‚´",
  "description": "ì˜ìƒ ì„¤ëª… 50ì ì´ë‚´",
  "script": [
    {
      "scene_number": 1,
      "text": "í•œêµ­ì–´ ëŒ€ì‚¬ 15ì ì´ë‚´",
      "emotion": "shocked",
      "highlight": true,
      "pause_ms": 800,
      "important_words": ["í•µì‹¬ë‹¨ì–´"],
      "direction": "BGM+ì—°ì¶œ ì§€ì‹œ (í•œêµ­ì–´)",
      "image_prompt": "ì˜ì–´ ì¥ë©´ ë¬˜ì‚¬ (English only, ì£¼ì œ ì—°ê´€ í•„ìˆ˜, Same character ê¸ˆì§€, ì¹´ë©”ë¼ ì•µê¸€ ë§¤ë²ˆ ë‹¤ë¥´ê²Œ)",
      "sfx": "gasp",
      "sfx_volume": 0.4
    }
  ]
}
emotion í—ˆìš©ê°’: neutral, tension, surprise, angry, sad, funny, shocked, excited, warm, serious, whisper, relief
sfx í—ˆìš©ê°’: laugh, rimshot, boing, punch, glass_break, thunder, dramatic_stinger, whoosh, ding, swoosh, gasp, crowd_ooh, record_scratch, kakao_alert, typing, ddiyong (ì—†ìœ¼ë©´ "")
highlight: ìµœëŒ€ 2ê°œë§Œ true. ë‚˜ë¨¸ì§€ëŠ” false."""

    # â”€â”€ [3/3] CONTENT_RULES: êµ¬ì¡° + ê¸ˆì§€ì‚¬í•­ (í•µì‹¬ë§Œ) â”€â”€
    CONTENT_RULES = """[Pace] 1ì´ˆë‹¹ 3.5ìŒì ˆ. í•œ ë¬¸ì¥ 15ì ì´ë‚´ ì—„ìˆ˜. ë¯¸ì‚¬ì—¬êµ¬ ì‚­ì œ.

[ëŒ€ë³¸ êµ¬ì¡° â€” 12~15ê°œ ì¥ë©´ (60ì´ˆ ëª©í‘œ)]
Act1 í›… (1~2ë¬¸ì¥): shocked/excited. ì²«ë¬¸ì¥ 12ìâ†“. sfx: gasp or glass_break. pause_ms: 0.
Act2 ë¹Œë“œì—… (3~5ë¬¸ì¥): sadâ†’tension. ê³µê° ë””í…Œì¼. directionì— "ë¶ˆí˜‘í™”ìŒ BGM" ëª…ì‹œ.
Act3 í”¼í¬ (2~3ë¬¸ì¥): angry. ê°ì • í­ë°œ. sfx: punch. pause_ms: 800~1200 (ìŒì†Œê±° íš¨ê³¼). highlight: true.
Act4 ë°˜ì „ (2~3ë¬¸ì¥): funny/relief. ì¹´íƒ€ë¥´ì‹œìŠ¤. sfx: dramatic_stinger or rimshot.
Act5 CTA (1ë¬¸ì¥): neutral. ëŒ“ê¸€ ìœ ë„ ì§ˆë¬¸. pause_ms: 0.

[í•„ìˆ˜ ì²´í¬]
- ê°™ì€ ê°ì • ìµœëŒ€ 2ì—°ì†. 6ì¢…ë¥˜+ ê°ì • ì‚¬ìš©.
- highlight: ìµœëŒ€ 2ê°œë§Œ (Act3 í”¼í¬ + Act4 ë°˜ì „ì—ë§Œ)
- important_words: ë§¤ ë¬¸ì¥ 1~2ê°œ. ê¸ˆì•¡/ì¸ë¬¼/í•µì‹¬ëª…ì‚¬.
- direction: ë§¤ ì¥ë©´ BGM ìƒíƒœ ëª…ì‹œ ("ë¸Œê¸ˆ ìœ ì§€" "ë¸Œê¸ˆ ë©ˆì¶¤" "ë¹„ì¥í•œ ìŒì•… IN")
- sfx: ì „ì²´ 3~5ê°œë§Œ (ë§¤ ì¥ë©´ ë„£ì§€ ë§ˆ. í”¼í¬ì—ë§Œ.)
- CTA ë§ˆì§€ë§‰ ë¬¸ì¥ = ë§¤ë²ˆ ë‹¤ë¥¸ í˜•ì‹ (ì§ˆë¬¸/ë„ë°œ/ê³ ë°±/ì œì•ˆ ë“± ë‹¤ì–‘í•˜ê²Œ)

[ê¸ˆì§€]
- ì›ë¬¸ì— ì—†ëŠ” ìˆ˜ì¹˜/ëŒ€í™” ì°½ì‘
- ì‹¤ëª…, ë³´ë„ì²´, ì¢‹ì•„ìš”/êµ¬ë… ìœ ë„
- ì‹œì¦Œ ì§€ë‚œ ì†Œì¬ (ì„¤ë‚ /ì¶”ì„/í¬ë¦¬ìŠ¤ë§ˆìŠ¤)
- highlight ì „ë¶€ true (ë°˜ë“œì‹œ ëŒ€ë¶€ë¶„ false)"""

    # â”€â”€ few-shot ì˜ˆì‹œ (ì‹¤ì œ JSONìœ¼ë¡œ â€” Geminiê°€ ì •í™•íˆ ë”°ë¼í•˜ë„ë¡) â”€â”€
    FEW_SHOT_EXAMPLES = """[ì˜ˆì‹œ â€” ì´ JSON í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼í•´]
{"title":"ê¸°íšì•ˆ ë„ë‘‘ ìƒì‚¬","mood":"satisfying","tags":["#ì§ì¥ì°","#ì°¸êµìœ¡","#ìƒì‚¬","#ì‚¬ì´ë‹¤","#ë¶„ë…¸","#ê³µê°","#ìˆì¸ ","#ë ˆì „ë“œ","#íšŒì‚¬","#ì§ì¥ì¸","#ì›ƒê¸´ì§¤","#ë°˜ì „","#ì¼ìƒ","#ì‹¤í™”","#ê°œë¹¡ì¹¨"],"thumbnail_text":"ë‚´ ê¸°íšì•ˆ?","description":"3ì£¼ ì•¼ê·¼í•œ ê¸°íšì•ˆ í›”ì³ê°„ ìƒì‚¬ ê²°ë§ ã…‹ã…‹","script":[
{"scene_number":1,"text":"ì•„ ì§„ì§œ ë¯¸ì³¤ìŒ","emotion":"shocked","highlight":false,"pause_ms":0,"important_words":["ë¯¸ì³¤"],"direction":"ê²½ì¾Œí•œ ë¸Œê¸ˆ ê°‘ìê¸° ë©ˆì¶¤","image_prompt":"Young Korean male, short brown hair, thin build, worn gray hoodie, jaw dropped with extreme shock, close-up shot, cold fluorescent office light, Korean webtoon style, bold outlines","sfx":"glass_break","sfx_volume":0.4},
{"scene_number":2,"text":"3ì£¼ë¥¼ ì•¼ê·¼í–ˆê±°ë“ ","emotion":"sad","highlight":false,"pause_ms":300,"important_words":["3ì£¼","ì•¼ê·¼"],"direction":"ë¶ˆí˜‘í™”ìŒ BGM ì‹œì‘","image_prompt":"Same character as scene 1, hunched over desk surrounded by papers, dark circles under eyes, dimly lit office at night, Korean webtoon style","sfx":"","sfx_volume":0.3},
{"scene_number":3,"text":"ê¸°íšì•ˆ ì§„ì§œ í”¼ë•€ì„","emotion":"sad","highlight":false,"pause_ms":200,"important_words":["í”¼ë•€"],"direction":"ë¶ˆí˜‘í™”ìŒ ìœ ì§€","image_prompt":"Same character as scene 1, exhausted face illuminated by laptop screen, energy drink cans around, Korean webtoon style","sfx":"","sfx_volume":0.3},
{"scene_number":4,"text":"ê·¼ë° íšŒì˜ ë•Œ","emotion":"tension","highlight":false,"pause_ms":400,"important_words":["íšŒì˜"],"direction":"ë¸Œê¸ˆ ê¸´ì¥ê° ìƒìŠ¹","image_prompt":"Same character as scene 1, sitting nervously in meeting room, wide shot showing conference table, tense atmosphere, Korean webtoon style","sfx":"","sfx_volume":0.3},
{"scene_number":5,"text":"íŒ€ì¥ì´ ë‚´ ê¸°íšì•ˆ ë°œí‘œí•¨","emotion":"tension","highlight":false,"pause_ms":300,"important_words":["íŒ€ì¥","ê¸°íšì•ˆ"],"direction":"ë¸Œê¸ˆ ë©ˆì¶¤ ì§ì „","image_prompt":"Same character as scene 1, eyes widening in disbelief, low angle looking at team leader presenting, dramatic shadows, Korean webtoon style","sfx":"","sfx_volume":0.3},
{"scene_number":6,"text":"ì œê°€ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤?","emotion":"angry","highlight":true,"pause_ms":1000,"important_words":["ì œê°€","ì¤€ë¹„"],"direction":"BGM ì™„ì „ ë©ˆì¶¤ + ë¬µìŒ (ìŒì†Œê±° íš¨ê³¼)","image_prompt":"Same character as scene 1, extreme close-up on eyes, burning red face, veins on forehead, dark ominous background with red glow, Korean webtoon style","sfx":"punch","sfx_volume":0.6},
{"scene_number":7,"text":"í”¼ê°€ ê±°ê¾¸ë¡œ ì†ŸìŒ ã„¹ã…‡","emotion":"angry","highlight":false,"pause_ms":400,"important_words":["í”¼"],"direction":"ê¸´ì¥ ë¸Œê¸ˆ IN","image_prompt":"Same character as scene 1, fists clenched on table, knuckles white, trembling with rage, Korean webtoon style","sfx":"","sfx_volume":0.3},
{"scene_number":8,"text":"ê·¼ë° ëŒ€í‘œê°€ ë¬¼ì–´ë´„","emotion":"tension","highlight":false,"pause_ms":800,"important_words":["ëŒ€í‘œ"],"direction":"ë¸Œê¸ˆ ì„œìŠ¤íœìŠ¤","image_prompt":"Same character as scene 1, frozen in place, CEO pointing at screen questioning, wide shot meeting room, Korean webtoon style","sfx":"","sfx_volume":0.3},
{"scene_number":9,"text":"ì›ë³¸ íŒŒì¼ ëˆ„êµ¬ ê±°ì„?","emotion":"shocked","highlight":true,"pause_ms":400,"important_words":["ì›ë³¸"],"direction":"ë¸Œê¸ˆ ë©ˆì¶¤","image_prompt":"Same character as scene 1, eyes wide open, mouth slightly open, dramatic close-up, single spotlight effect, Korean webtoon style","sfx":"dramatic_stinger","sfx_volume":0.5},
{"scene_number":10,"text":"ë‚´ ì´ë¦„ ë°•í˜€ìˆìŒ ã…‹ã…‹","emotion":"funny","highlight":true,"pause_ms":300,"important_words":["ì´ë¦„"],"direction":"í†µì¾Œí•œ ë¹„ì¥ ìŒì•… IN","image_prompt":"Same character as scene 1, smirking with pure satisfaction, triumphant expression, bright warm light flooding in, Korean webtoon style","sfx":"rimshot","sfx_volume":0.4},
{"scene_number":11,"text":"íŒ€ì¥ ì–¼êµ´ ë´¤ì–´ì•¼ í•¨","emotion":"funny","highlight":false,"pause_ms":200,"important_words":["ì–¼êµ´"],"direction":"ë¹„ì¥ ìŒì•… ìœ ì§€","image_prompt":"Same character as scene 1, laughing with hand covering mouth, team leader blurred in background looking pale, Korean webtoon style","sfx":"","sfx_volume":0.3},
{"scene_number":12,"text":"ì´ëŸ° ìƒì‚¬ ì–´ë–»ê²Œ í•´ì•¼ ë¨?","emotion":"neutral","highlight":false,"pause_ms":0,"important_words":["ìƒì‚¬"],"direction":"ë¸Œê¸ˆ í˜ì´ë“œì•„ì›ƒ","image_prompt":"Same character as scene 1, looking directly at viewer with curious expression, casual pose, soft lighting, Korean webtoon style","sfx":"","sfx_volume":0.3}
]}
ì£¼ëª©: highlightëŠ” 12ê°œ ì¤‘ 3ê°œë§Œ true. ê°ì • 6ì¢…(shocked,sad,tension,angry,funny,neutral). sfx 4ê°œë§Œ. ì²«ë¬¸ì¥ 7ì."""

    # â”€â”€ ëŒ€ë³¸ ê²€ì¦ìš© ìƒìˆ˜ â”€â”€
    _VALID_EMOTIONS = {
        "neutral", "tension", "surprise", "angry", "sad", "funny",
        "shocked", "excited", "warm", "serious", "whisper", "relief",
    }
    _AI_SLOP_WORDS = [
        "í¥ë¯¸ë¡­", "ë†€ë¼ìš´", "ì¶©ê²©ì ì¸", "ì•Œì•„ë³´ê² ", "ì‚´í´ë³´ê² ", "ê²°ë¡ ì ìœ¼ë¡œ",
        "í•˜ê² ìŠµë‹ˆë‹¤", "ë§ˆë¬´ë¦¬í•˜", "ìš”ì•½í•˜ìë©´", "ì •ë¦¬í•˜ë©´", "ì£¼ëª©í•  ë§Œí•œ",
        "ê¶ê¸ˆí•˜ì§€ ì•Šìœ¼ì‹ ê°€ìš”", "í•¨ê»˜ ì•Œì•„ë³¼ê¹Œìš”", "ì§€ê¸ˆë¶€í„°",
    ]

    # â”€â”€ í…Œë§ˆë³„ í”„ë¡¬í”„íŠ¸ í”„ë¦¬ì…‹ (info / comedy / mystery) â”€â”€
    # gossip í”„ë¦¬ì…‹ì€ __init__ì—ì„œ ê¸°ì¡´ í´ë˜ìŠ¤ ìƒìˆ˜ë¡œ ë™ì  ì¡°ë¦½
    _LIFE_HACK_ROLE = """ë„ˆëŠ” ì‚´ë¦¼ê³¼ ì—…ë¬´ íš¨ìœ¨ì„ 200% ë†’ì—¬ì£¼ëŠ” ê¿€íŒ ì „ë¬¸ê°€ì•¼.
"ë‚˜ë§Œ ì†í•´ ë³´ê³  ìˆì—ˆë„¤?" ì‹¬ë¦¬ë¥¼ ìê·¹í•˜ëŠ” ì‹¤ìš© íŒ ì˜ìƒ ì „ë¬¸.

[í•µì‹¬ ê·œì¹™ 3ê°œ]
1. ì²« ë¬¸ì¥ = 15ì ì´ë‚´ ì¶©ê²© ì§ˆë¬¸/ì‚¬ì‹¤ ("ì•„ì§ë„ ì„¸ì œë¡œë§Œ ë‹¦ìœ¼ì„¸ìš”?" "ì´ê±° ëª¨ë¥´ë©´ ë§¤ë‹¬ 3ë§Œì› ì†í•´")
2. ê°ì • íë¦„: excitedâ†’neutralâ†’warm (ì •ë³´ì „ë‹¬ì€ ì°¨ë¶„, í•µì‹¬ì€ ê°•ì¡°)
3. highlightëŠ” ê° íŒ ì œëª©(í•µì‹¬ ìš”ì•½)ì—ë§Œ true. ì „ì²´ì˜ 30% ì´í•˜.

[ë§íˆ¬]
- ì–´ë¯¸: ~í•˜ì„¸ìš”, ~ê±°ë“ ìš”, ~ì¸ë°ìš” (ì¡´ëŒ€ì§€ë§Œ ì¹œê·¼í•œ í†¤)
- ì¶”ì„ìƒˆ: ê·¼ë°ìš”, ì§„ì§œ, ì´ê±°, ì•„ ê·¸ë¦¬ê³ 
- ê¸ˆì§€ì–´: í¥ë¯¸ë¡­, ë†€ë¼ìš´, ì¶©ê²©ì , ì•Œì•„ë³´ê² , ì‚´í´ë³´ê² , ê²°ë¡ ì ìœ¼ë¡œ, í•˜ê² ìŠµë‹ˆë‹¤
- text í•œêµ­ì–´ë§Œ. image_prompt ì˜ì–´ë§Œ.

[image_prompt â€” ì˜ì–´ í•„ìˆ˜]
- ê¸°ë³¸ í‚¤ì›Œë“œ: Cinematic close-up, 8k resolution, clean bright lighting, minimalist, trendy aesthetic
- íŒ ì¥ë©´: "High-quality cinematic close-up of [object], 8k resolution, clean lighting"
- before/after ë¹„êµ, ì¸í¬ê·¸ë˜í”½ ëŠë‚Œ
- ì²« ì¥ë©´: ì£¼ì¸ê³µ ì™¸í˜• ìƒì„¸ + "8k, clean bright lighting, minimalist interior"
- 2ì¥ë©´+: "Same character as scene 1, ..." í•„ìˆ˜"""

    _LIFE_HACK_FORMAT = """{
  "title": "ê¿€íŒ ì œëª© 15ì ì´ë‚´ (ì˜ë¬¸í˜• ê¶Œì¥)",
  "mood": "funny|satisfying|shocking",
  "tags": ["#íƒœê·¸1", ... "#íƒœê·¸15"],
  "thumbnail_text": "ì¸ë„¤ì¼ 5ì ì´ë‚´",
  "description": "ì˜ìƒ ì„¤ëª… 50ì ì´ë‚´",
  "script": [
    {
      "scene_number": 1,
      "text": "í•œêµ­ì–´ ëŒ€ì‚¬ 20ì ì´ë‚´",
      "emotion": "excited",
      "highlight": true,
      "pause_ms": 0,
      "important_words": ["í•µì‹¬ë‹¨ì–´"],
      "direction": "BGM+ì—°ì¶œ ì§€ì‹œ (í•œêµ­ì–´)",
      "image_prompt": "ì˜ì–´ ì¥ë©´ ë¬˜ì‚¬ (English only)",
      "sfx": "",
      "sfx_volume": 0.3
    }
  ]
}
emotion í—ˆìš©ê°’: neutral, excited, warm, surprise, funny, shocked, serious, relief
sfx í—ˆìš©ê°’: ding, whoosh, swoosh, typing, dramatic_stinger (ì—†ìœ¼ë©´ "")
highlight: ê° íŒ ì œëª©ì—ë§Œ true. ì „ì²´ì˜ 30% ì´í•˜."""

    _LIFE_HACK_RULES = """[Pace] 1ì´ˆë‹¹ 3.5ìŒì ˆ. í•œ ë¬¸ì¥ 20ì ì´ë‚´ ì—„ìˆ˜. ë¯¸ì‚¬ì—¬êµ¬ ì‚­ì œ.

[ëŒ€ë³¸ êµ¬ì¡° â€” 10~14ë¬¸ì¥]
Hook (1~2ë¬¸ì¥): excited/surprise. ì¶©ê²© ì§ˆë¬¸ìœ¼ë¡œ ì‹œì‘. sfx: ding. pause_ms: 0.
íŒ1 (2~3ë¬¸ì¥): neutralâ†’excited. íŒ ì œëª©(highlight:true) + ì„¤ëª…. directionì— "ê²½ì¾Œí•œ BGM" ëª…ì‹œ.
íŒ2 (2~3ë¬¸ì¥): neutralâ†’warm. ë‘ë²ˆì§¸ íŒ. sfx ì—†ìŒ.
íŒ3 (2~3ë¬¸ì¥): excitedâ†’surprise. ê°€ì¥ ë†€ë¼ìš´ íŒ. sfx: dramatic_stinger.
CTA (1ë¬¸ì¥): warm. "ì €ì¥í•˜ê³  ì¹œêµ¬í•œí…Œ ê³µìœ í•˜ì„¸ìš”!" ë¥˜. pause_ms: 0.

[í•„ìˆ˜ ì²´í¬]
- ê°ì • ì¢…ë¥˜ ìµœì†Œ 3ì¢… (excited, neutral, warm ê¸°ë³¸ + alpha)
- highlight: ì „ì²´ì˜ 30% ì´í•˜ (íŒ ì œëª©ì—ë§Œ)
- important_words: ë§¤ ë¬¸ì¥ 1~2ê°œ. ìˆ˜ì¹˜/í•µì‹¬ëª…ì‚¬.
- direction: ë§¤ ì¥ë©´ BGM ìƒíƒœ ëª…ì‹œ
- sfx: ì „ì²´ 2~3ê°œë§Œ
- CTA = ê³µìœ /ì €ì¥ ìœ ë„ (êµ¬ë…/ì¢‹ì•„ìš” ê¸ˆì§€)

[ê¸ˆì§€]
- ê·¼ê±° ì—†ëŠ” ìˆ˜ì¹˜ ì°½ì‘, ì˜í•™/ë²•ë¥  ì¡°ì–¸
- ì¢‹ì•„ìš”/êµ¬ë… ìœ ë„, highlight ì „ë¶€ true"""

    _LIFE_HACK_FEWSHOT = """[ì˜ˆì‹œ â€” ì´ JSON í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼í•´]
{"title":"ì„¸ì œ ì—†ì´ ë°˜ì§","mood":"satisfying","tags":["#ê¿€íŒ","#ì²­ì†Œ","#ìƒí™œíŒ","#ì‚´ë¦¼","#ìì·¨","#ë¼ì´í”„í•µ","#ìˆì¸ ","#ì •ë³´","#ì„¸íƒ","#ì£¼ë°©","#ìš•ì‹¤","#ê°€ì„±ë¹„","#ê¿€ì¡°í•©","#ì‚´ë¦¼ê¿€íŒ","#ìì·¨ìƒ"],"thumbnail_text":"ì„¸ì œ ëŒ€ì‹ ?","description":"ì„¸ì œ ì—†ì´ë„ ë°˜ì§! ì§‘ì— ìˆëŠ” ì¬ë£Œë¡œ ì²­ì†Œ ë","script":[
{"scene_number":1,"text":"ì•„ì§ë„ ì„¸ì œë¡œë§Œ ë‹¦ìœ¼ì„¸ìš”?","emotion":"excited","highlight":false,"pause_ms":0,"important_words":["ì„¸ì œ"],"direction":"ê²½ì¾Œí•œ ë¸Œê¸ˆ ì‹œì‘","image_prompt":"Young Korean woman, short bob hair, apron, holding cleaning spray, surprised expression, cinematic close-up, 8k resolution, clean bright lighting, minimalist kitchen","sfx":"ding","sfx_volume":0.4},
{"scene_number":2,"text":"ì‹ì´ˆ í•œ ìŠ¤í‘¼ì´ë©´ ëì´ì—ìš”","emotion":"neutral","highlight":true,"pause_ms":200,"important_words":["ì‹ì´ˆ","í•œ ìŠ¤í‘¼"],"direction":"ë¸Œê¸ˆ ìœ ì§€","image_prompt":"Same character as scene 1, pouring vinegar into spray bottle, cinematic close-up of hands, 8k, clean bright lighting","sfx":"","sfx_volume":0.3},
{"scene_number":3,"text":"ê¸°ë¦„ë•Œê°€ ë…¹ì•„ìš” ì§„ì§œ","emotion":"warm","highlight":false,"pause_ms":200,"important_words":["ê¸°ë¦„ë•Œ"],"direction":"ë¸Œê¸ˆ ìœ ì§€","image_prompt":"High-quality cinematic close-up of greasy stovetop before and after, 8k resolution, clean lighting, trendy aesthetic","sfx":"","sfx_volume":0.3},
{"scene_number":4,"text":"ë‘ë²ˆì§¸ ë² ì´í‚¹ì†Œë‹¤","emotion":"excited","highlight":true,"pause_ms":200,"important_words":["ë² ì´í‚¹ì†Œë‹¤"],"direction":"ë¸Œê¸ˆ ë°ê²Œ ì „í™˜","image_prompt":"Same character as scene 1, sprinkling baking soda on tiles, cinematic close-up, 8k, clean bright lighting","sfx":"","sfx_volume":0.3},
{"scene_number":5,"text":"ìš•ì‹¤ ê³°íŒ¡ì´ì— ë¿Œë¦¬ë©´","emotion":"neutral","highlight":false,"pause_ms":200,"important_words":["ê³°íŒ¡ì´"],"direction":"ë¸Œê¸ˆ ìœ ì§€","image_prompt":"Same character as scene 1, spraying bathroom grout, cinematic close-up, 8k, clean lighting","sfx":"","sfx_volume":0.3},
{"scene_number":6,"text":"30ë¶„ ë’¤ì— ì‹¹ ì‚¬ë¼ì ¸ìš”","emotion":"surprise","highlight":false,"pause_ms":300,"important_words":["30ë¶„"],"direction":"ë¸Œê¸ˆ ìœ ì§€","image_prompt":"High-quality cinematic close-up of sparkling clean bathroom result, 8k resolution, bright lighting, trendy aesthetic","sfx":"","sfx_volume":0.3},
{"scene_number":7,"text":"ì„¸ë²ˆì§¸ê°€ ì§„ì§œ ëŒ€ë°•ì¸ë°ìš”","emotion":"excited","highlight":false,"pause_ms":400,"important_words":["ëŒ€ë°•"],"direction":"ë¸Œê¸ˆ ì„œìŠ¤íœìŠ¤ ì „í™˜","image_prompt":"Same character as scene 1, excited expression holding mysterious bottle, cinematic, 8k, clean lighting","sfx":"dramatic_stinger","sfx_volume":0.5},
{"scene_number":8,"text":"ì½œë¼ë¡œ ë³€ê¸° ì²­ì†Œë¼ìš”","emotion":"surprise","highlight":true,"pause_ms":300,"important_words":["ì½œë¼","ë³€ê¸°"],"direction":"ë¸Œê¸ˆ ë°˜ì „","image_prompt":"High-quality cinematic close-up of cola being poured into toilet, bubbling reaction, 8k resolution, clean lighting","sfx":"","sfx_volume":0.3},
{"scene_number":9,"text":"ì €ì¥í•˜ê³  ë‚˜ì¤‘ì— ì¨ë³´ì„¸ìš”","emotion":"warm","highlight":false,"pause_ms":0,"important_words":["ì €ì¥"],"direction":"ë¸Œê¸ˆ í˜ì´ë“œì•„ì›ƒ","image_prompt":"Same character as scene 1, smiling at viewer giving thumbs up, 8k, clean bright lighting, trendy aesthetic","sfx":"","sfx_volume":0.3}
]}
ì£¼ëª©: highlight 9ê°œ ì¤‘ 3ê°œ. ê°ì • 4ì¢…(excited,neutral,warm,surprise). sfx 2ê°œ. ì¡´ëŒ€ì²´."""

    _EMPATHY_ROLE = """ë„ˆëŠ” í˜„ëŒ€ì¸ì˜ ë§ˆìŒì„ ê¿°ëš«ì–´ ë³´ëŠ” ìœ„íŠ¸ ìˆëŠ” ê´€ì°°ìì•¼.
ëˆ„êµ¬ë‚˜ ê²ªëŠ” ê·€ì°®ì€ ìƒí™©ì„ ìœ ë¨¸ë¡œ í„°ëœ¨ë¦¬ëŠ” ìŠ¤íƒ€ì¼. "ì–´? ì´ê±° ë‚˜ì¸ë°?" ë°˜ì‘ ìœ ë„.

[í•µì‹¬ ê·œì¹™ 3ê°œ]
1. ì²« ë¬¸ì¥ = 15ì ì´ë‚´ ê³µê° ìƒí™© ("ì›”ìš”ì¼ ì•„ì¹¨ ì•ŒëŒ 5ê°œì§¸" "ì—„ë§ˆí•œí…Œ ì „í™” ì˜´")
2. ê°ì •: funny ì¤‘ì‹¬ + surprise ë°˜ì „. ã…‹ã…‹ã…‹ ììœ ë¡­ê²Œ.
3. highlightëŠ” ë°˜ì „/í€ì¹˜ë¼ì¸ì—ë§Œ true. ì „ì²´ì˜ 25% ì´í•˜.

[ë§íˆ¬]
- ì–´ë¯¸: ~ì„, ~ìŒ, ~ê±°ë“ , ~ì–ì•„ (ë°˜ë§ í†µì¼)
- ì¶”ì„ìƒˆ: ã…‹ã…‹ã…‹, ã„¹ã…‡, ì•„ë‹ˆ, ì§„ì§œ, í—, ì•„ ê·¼ë°
- ê¸ˆì§€ì–´: í¥ë¯¸ë¡­, ë†€ë¼ìš´, ì¶©ê²©ì , ì•Œì•„ë³´ê² , ê²°ë¡ ì ìœ¼ë¡œ
- text í•œêµ­ì–´ë§Œ. image_prompt ì˜ì–´ë§Œ.

[image_prompt â€” ì˜ì–´ í•„ìˆ˜]
- ê¸°ë³¸ í‚¤ì›Œë“œ: Anime style, vibrant colors, high contrast, expressive, trendy aesthetic
- ê³¼ì¥ëœ í‘œì •: exaggerated funny face, deadpan stare, dramatic eye roll
- ì¼ìƒ ë°°ê²½: relatable daily office/home setting, vibrant colors
- ì²« ì¥ë©´: ì£¼ì¸ê³µ ì™¸í˜• ìƒì„¸ + "anime style, expressive, vibrant colors, 8k"
- 2ì¥ë©´+: "Same character as scene 1, ..." í•„ìˆ˜"""

    _EMPATHY_FORMAT = """{
  "title": "ê³µê° ì œëª© 15ì ì´ë‚´",
  "mood": "funny|satisfying",
  "tags": ["#íƒœê·¸1", ... "#íƒœê·¸15"],
  "thumbnail_text": "ì¸ë„¤ì¼ 5ì ì´ë‚´",
  "description": "ì˜ìƒ ì„¤ëª… 50ì ì´ë‚´",
  "script": [
    {
      "scene_number": 1,
      "text": "í•œêµ­ì–´ ëŒ€ì‚¬ 20ì ì´ë‚´",
      "emotion": "funny",
      "highlight": false,
      "pause_ms": 0,
      "important_words": ["í•µì‹¬ë‹¨ì–´"],
      "direction": "BGM+ì—°ì¶œ ì§€ì‹œ (í•œêµ­ì–´)",
      "image_prompt": "ì˜ì–´ ì¥ë©´ ë¬˜ì‚¬ (English only)",
      "sfx": "",
      "sfx_volume": 0.3
    }
  ]
}
emotion í—ˆìš©ê°’: neutral, funny, surprise, shocked, excited, warm, sad, relief, tension
sfx í—ˆìš©ê°’: laugh, rimshot, boing, record_scratch, whoosh, ding, kakao_alert (ì—†ìœ¼ë©´ "")
highlight: ë°˜ì „/í€ì¹˜ë¼ì¸ì—ë§Œ true. ì „ì²´ì˜ 25% ì´í•˜."""

    _EMPATHY_RULES = """[Pace] 1ì´ˆë‹¹ 3.5ìŒì ˆ. í•œ ë¬¸ì¥ 20ì ì´ë‚´ ì—„ìˆ˜. ë¯¸ì‚¬ì—¬êµ¬ ì‚­ì œ.

[ëŒ€ë³¸ êµ¬ì¡° â€” 10~14ë¬¸ì¥]
ìƒí™©ì„¤ì • (2~3ë¬¸ì¥): funny/neutral. ëˆ„êµ¬ë‚˜ ê³µê°í•  ì¼ìƒ. pause_ms: 0.
ì˜ˆìƒì „ê°œ (2~3ë¬¸ì¥): neutralâ†’funny. "ë‹¹ì—°íˆ ì´ë ‡ê²Œ ë˜ê² ì§€?" ê¸°ëŒ€ê°.
ë°˜ì „1 (2~3ë¬¸ì¥): surprise/shocked. ì˜ˆìƒ ë¹—ë‚˜ê°€ëŠ” ì „ê°œ. sfx: record_scratch. highlight: true.
ë°˜ì „2 (2~3ë¬¸ì¥): funny. ë” í™©ë‹¹í•œ ê²°ë§. sfx: rimshot.
ê³µê°ì§ˆë¬¸ (1ë¬¸ì¥): neutral/funny. "ì´ê±° ë‚˜ë§Œ ê·¸ëŸ¼?" ë¥˜. pause_ms: 0.

[í•„ìˆ˜ ì²´í¬]
- funny ê°ì • ìµœì†Œ 40% ì´ìƒ
- ê°™ì€ ê°ì • 3ì—°ì†ê¹Œì§€ í—ˆìš© (comedy íŠ¹ë¡€)
- highlight: ì „ì²´ì˜ 25% ì´í•˜ (ë°˜ì „ì—ë§Œ)
- ã…‹ã…‹ í¬í•¨ ë¬¸ì¥ ìµœì†Œ 2ê°œ
- sfx: ì „ì²´ 2~4ê°œ
- CTA = ê³µê° ì§ˆë¬¸ (êµ¬ë…/ì¢‹ì•„ìš” ê¸ˆì§€)

[ê¸ˆì§€]
- íŠ¹ì •ì¸ ë¹„í•˜/ì¡°ë¡±, ì¢‹ì•„ìš”/êµ¬ë… ìœ ë„, highlight ì „ë¶€ true"""

    _EMPATHY_FEWSHOT = """[ì˜ˆì‹œ â€” ì´ JSON í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼í•´]
{"title":"ë°°ë‹¬ ì‹œí‚¨ ë‚˜","mood":"funny","tags":["#ì¼ìƒ","#ê³µê°","#ë°°ë‹¬","#ì›ƒê¹€","#ìˆì¸ ","#ì½”ë¯¸ë””","#ë¨¹ë°©","#í˜¼ë°¥","#ìì·¨","#ë¸Œì´ë¡œê·¸","#ì¼ìƒë¸Œì´ë¡œê·¸","#ì›ƒê¸´ì§¤","#ë°ˆ","#MZ","#ê°œì›ƒ"],"thumbnail_text":"ë°°ë‹¬ ì‹¤í™”","description":"ë°°ë‹¬ ì‹œì¼°ëŠ”ë° ë²Œì–´ì§„ ì¼ ã…‹ã…‹ã…‹","script":[
{"scene_number":1,"text":"ë°°ë‹¬ ì‹œí‚¤ê³  ëˆ„ì›€","emotion":"neutral","highlight":false,"pause_ms":0,"important_words":["ë°°ë‹¬"],"direction":"ëŠê¸‹í•œ ë¸Œê¸ˆ","image_prompt":"Young Korean male, messy hair, oversized t-shirt, lying on couch scrolling phone, anime style, expressive, vibrant colors, 8k, relatable messy room","sfx":"kakao_alert","sfx_volume":0.3},
{"scene_number":2,"text":"ì¡°ë¦¬ ì‹œì‘ì´ë˜ ã…‹ã…‹","emotion":"funny","highlight":false,"pause_ms":200,"important_words":["ì¡°ë¦¬"],"direction":"ë¸Œê¸ˆ ìœ ì§€","image_prompt":"Same character as scene 1, looking at phone with exaggerated happy expression, anime style, vibrant colors, high contrast","sfx":"","sfx_volume":0.3},
{"scene_number":3,"text":"10ë¶„ ë’¤ ë‹¤ì‹œ ë´„","emotion":"neutral","highlight":false,"pause_ms":200,"important_words":["10ë¶„"],"direction":"ë¸Œê¸ˆ ìœ ì§€","image_prompt":"Same character as scene 1, checking phone with impatient deadpan stare, anime style, expressive, vibrant colors","sfx":"","sfx_volume":0.3},
{"scene_number":4,"text":"ì•„ì§ë„ ì¡°ë¦¬ ì‹œì‘ ã…‹ã…‹","emotion":"funny","highlight":false,"pause_ms":300,"important_words":["ì•„ì§ë„"],"direction":"ë¸Œê¸ˆ ì•½ê°„ ê¸´ì¥","image_prompt":"Same character as scene 1, dramatic eye roll in disbelief, anime style, vibrant colors, high contrast","sfx":"","sfx_volume":0.3},
{"scene_number":5,"text":"30ë¶„ì§¸ ì¡°ë¦¬ ì‹œì‘","emotion":"funny","highlight":false,"pause_ms":200,"important_words":["30ë¶„ì§¸"],"direction":"ë¸Œê¸ˆ ë©ˆì¶¤","image_prompt":"Same character as scene 1, sitting up frustrated, exaggerated angry expression, anime style, vibrant colors, 8k","sfx":"","sfx_volume":0.3},
{"scene_number":6,"text":"ì „í™”í–ˆë”ë‹ˆ","emotion":"tension","highlight":false,"pause_ms":400,"important_words":["ì „í™”"],"direction":"ì„œìŠ¤íœìŠ¤ ë¸Œê¸ˆ","image_prompt":"Same character as scene 1, holding phone to ear with intense expression, anime style, high contrast, moody lighting","sfx":"","sfx_volume":0.3},
{"scene_number":7,"text":"ì£¼ë¬¸ ì•ˆ ë“¤ì–´ì™”ëŒ€ ã…‹ã…‹","emotion":"shocked","highlight":true,"pause_ms":300,"important_words":["ì•ˆ ë“¤ì–´ì™”"],"direction":"ë¸Œê¸ˆ ë©ˆì¶¤","image_prompt":"Same character as scene 1, jaw dropped in shock, phone falling, extreme close-up, anime style, vibrant colors, high contrast","sfx":"record_scratch","sfx_volume":0.5},
{"scene_number":8,"text":"ë°°ê³ íŒŒ ì£½ëŠ” ì¤‘ ã…‹ã…‹ã…‹","emotion":"funny","highlight":false,"pause_ms":200,"important_words":["ë°°ê³ íŒŒ"],"direction":"ì½”ë¯¸ë”” ë¸Œê¸ˆ IN","image_prompt":"Same character as scene 1, dramatically lying on floor, exaggerated funny hungry face, anime style, vibrant colors","sfx":"rimshot","sfx_volume":0.4},
{"scene_number":9,"text":"ê²°êµ­ ë¼ë©´ ë“ì„ ã…‹ã…‹","emotion":"funny","highlight":true,"pause_ms":200,"important_words":["ë¼ë©´"],"direction":"ë¸Œê¸ˆ ìœ ì§€","image_prompt":"Same character as scene 1, sadly cooking ramen, defeated expression, anime style, warm vibrant colors, trendy aesthetic","sfx":"","sfx_volume":0.3},
{"scene_number":10,"text":"ì´ê±° ë‚˜ë§Œ ê·¸ëŸ¼?","emotion":"neutral","highlight":false,"pause_ms":0,"important_words":["ë‚˜ë§Œ"],"direction":"ë¸Œê¸ˆ í˜ì´ë“œì•„ì›ƒ","image_prompt":"Same character as scene 1, looking at viewer with knowing smile, anime style, vibrant colors, 8k, trendy aesthetic","sfx":"","sfx_volume":0.3}
]}
ì£¼ëª©: highlight 10ê°œ ì¤‘ 2ê°œ. ê°ì • 5ì¢…(neutral,funny,tension,shocked). sfx 3ê°œ. ã…‹ã…‹ 4ê°œ ë¬¸ì¥."""

    _MYSTERY_ROLE = """ë„ˆëŠ” ì„¸ìƒì˜ ì‹ ë¹„ë¡œìš´ ì¡í•™ì§€ì‹ì„ ì•Œë ¤ì£¼ëŠ” ë¯¸ìŠ¤í„°ë¦¬ íë ˆì´í„°ì•¼.
í˜¸ê¸°ì‹¬ ìê·¹ â†’ ëê¹Œì§€ ë³´ê²Œ ë§Œë“œëŠ” ì „ë¬¸ê°€. "ë¹„í–‰ê¸° ì°½ë¬¸ì€ ì™œ ë‘¥ê¸€ê¹Œ?" ë¥˜.

[í•µì‹¬ ê·œì¹™ 3ê°œ]
1. ì²« ë¬¸ì¥ = 15ì ì´ë‚´ í˜¸ê¸°ì‹¬ ì§ˆë¬¸ ("ì™œ ë¹„í–‰ê¸° ì°½ë¬¸ì€ ë‘¥ê¸€ê¹Œ?" "ì—˜ë¦¬ë² ì´í„°ì— ê±°ìš¸ ì™œ ìˆì„ê¹Œ?")
2. ê°ì • ê³¡ì„ : tensionâ†’neutralâ†’tensionâ†’shockedâ†’relief (ì„œì„œíˆ ê³ ì¡° â†’ ë°˜ì „ íŒ©íŠ¸)
3. highlightëŠ” ë°˜ì „ íŒ©íŠ¸(ì •ë‹µ)ì—ë§Œ true. ì „ì²´ì˜ 20% ì´í•˜.

[ë§íˆ¬]
- ì–´ë¯¸: ~ì¸ë°, ~ê±°ë“ , ~ì´ì—ˆìŒ, ~ì˜€ëŒ€ (ë°˜ë§)
- ì¶”ì„ìƒˆ: ê·¼ë°, ì§„ì§œ, ì•„ ì´ê²Œ, ì•Œê³  ë³´ë‹ˆ, ì‹¤ì€
- ê¸ˆì§€ì–´: í¥ë¯¸ë¡­, ë†€ë¼ìš´, ì¶©ê²©ì , ì•Œì•„ë³´ê² , ì‚´í´ë³´ê² , ê²°ë¡ ì ìœ¼ë¡œ
- text í•œêµ­ì–´ë§Œ. image_prompt ì˜ì–´ë§Œ.

[image_prompt â€” ì˜ì–´ í•„ìˆ˜]
- ê¸°ë³¸ í‚¤ì›Œë“œ: Mysterious atmosphere, dark moody lighting, hyper-realistic, 4k, cinematic fog, high contrast
- ë‹¨ì„œ ì¥ë©´: dark tones, mysterious shadows, dramatic silhouettes
- ë°˜ì „ íŒ©íŠ¸: bright revealing light, infographic style, clean contrast
- ì²« ì¥ë©´: ì£¼ì¸ê³µ ì™¸í˜• ìƒì„¸ + "dark moody lighting, mysterious atmosphere, 4k, cinematic fog"
- 2ì¥ë©´+: "Same character as scene 1, ..." í•„ìˆ˜"""

    _MYSTERY_FORMAT = """{
  "title": "ë¯¸ìŠ¤í„°ë¦¬ ì œëª© 15ì ì´ë‚´ (ì˜ë¬¸í˜•)",
  "mood": "scary|shocking|satisfying",
  "tags": ["#íƒœê·¸1", ... "#íƒœê·¸15"],
  "thumbnail_text": "ì¸ë„¤ì¼ 5ì ì´ë‚´",
  "description": "ì˜ìƒ ì„¤ëª… 50ì ì´ë‚´",
  "script": [
    {
      "scene_number": 1,
      "text": "í•œêµ­ì–´ ëŒ€ì‚¬ 20ì ì´ë‚´",
      "emotion": "tension",
      "highlight": false,
      "pause_ms": 0,
      "important_words": ["í•µì‹¬ë‹¨ì–´"],
      "direction": "BGM+ì—°ì¶œ ì§€ì‹œ (í•œêµ­ì–´)",
      "image_prompt": "ì˜ì–´ ì¥ë©´ ë¬˜ì‚¬ (English only)",
      "sfx": "",
      "sfx_volume": 0.3
    }
  ]
}
emotion í—ˆìš©ê°’: neutral, tension, surprise, shocked, excited, serious, whisper, relief, warm, funny
sfx í—ˆìš©ê°’: whoosh, dramatic_stinger, thunder, glass_break, ding, typing (ì—†ìœ¼ë©´ "")
highlight: ë°˜ì „ íŒ©íŠ¸ì—ë§Œ true. ì „ì²´ì˜ 20% ì´í•˜."""

    _MYSTERY_RULES = """[Pace] 1ì´ˆë‹¹ 3.5ìŒì ˆ. í•œ ë¬¸ì¥ 20ì ì´ë‚´ ì—„ìˆ˜. ë¯¸ì‚¬ì—¬êµ¬ ì‚­ì œ.

[ëŒ€ë³¸ êµ¬ì¡° â€” 10~14ë¬¸ì¥]
ì§ˆë¬¸ (1~2ë¬¸ì¥): tension/surprise. í˜¸ê¸°ì‹¬ ìê·¹ ì§ˆë¬¸. sfx: whoosh. pause_ms: 0.
ë‹¨ì„œ1 (2~3ë¬¸ì¥): neutralâ†’tension. ì˜¤í•´í•˜ê¸° ì‰¬ìš´ ìƒì‹. direction: "ë¯¸ìŠ¤í„°ë¦¬ BGM".
ë‹¨ì„œ2 (2~3ë¬¸ì¥): tensionâ†’serious. ì§„ì§œ ì´ìœ ì— ê°€ê¹Œì›Œì§. ê¸´ì¥ê° ê³ ì¡°.
ë°˜ì „íŒ©íŠ¸ (2~3ë¬¸ì¥): shockedâ†’excited. ë†€ë¼ìš´ ì§„ì§œ ì´ìœ . sfx: dramatic_stinger. highlight: true.
CTA (1ë¬¸ì¥): relief/warm. "ì•Œê³  ìˆì—ˆìŒ?" / "ì´ê²ƒë„ ê¶ê¸ˆí•˜ë©´ íŒ”ë¡œìš°" ë¥˜. pause_ms: 0.

[í•„ìˆ˜ ì²´í¬]
- ê°ì • ì¢…ë¥˜ ìµœì†Œ 4ì¢… (tension, neutral, shocked, relief ê¸°ë³¸)
- highlight: ì „ì²´ì˜ 20% ì´í•˜ (ë°˜ì „ íŒ©íŠ¸ì—ë§Œ)
- important_words: ë§¤ ë¬¸ì¥ 1~2ê°œ. í•µì‹¬ ê°œë…/ìˆ˜ì¹˜.
- direction: ë¯¸ìŠ¤í„°ë¦¬ BGM íë¦„ ëª…ì‹œ
- sfx: ì „ì²´ 2~3ê°œ (ì§ˆë¬¸ + ë°˜ì „ì—ë§Œ)

[ê¸ˆì§€]
- ê²€ì¦ ì•ˆ ëœ ê³¼í•™/ì—­ì‚¬ ì‚¬ì‹¤ ì°½ì‘, ìŒëª¨ë¡ /ë¯¸ì‹  ì¡°ì¥
- ì¢‹ì•„ìš”/êµ¬ë… ìœ ë„, highlight ì „ë¶€ true"""

    _MYSTERY_FEWSHOT = """[ì˜ˆì‹œ â€” ì´ JSON í˜•ì‹ì„ ì •í™•íˆ ë”°ë¼í•´]
{"title":"ì—˜ë¦¬ë² ì´í„° ê±°ìš¸ ë¹„ë°€","mood":"shocking","tags":["#ë¯¸ìŠ¤í„°ë¦¬","#ìƒì‹","#ì•Œì“¸ì‹ ì¡","#ëª°ëë˜ì‚¬ì‹¤","#ìˆì¸ ","#ê¶ê¸ˆ","#ì—˜ë¦¬ë² ì´í„°","#ì¼ìƒ","#ê³¼í•™","#ìƒì‹í€´ì¦ˆ","#ë°˜ì „","#ì •ë³´","#ê¿€íŒ","#ë ˆì „ë“œ","#ì†Œë¦„"],"thumbnail_text":"ê±°ìš¸ ì™œ?","description":"ì—˜ë¦¬ë² ì´í„° ê±°ìš¸ì˜ ì§„ì§œ ì´ìœ  ì•Œë©´ ì†Œë¦„","script":[
{"scene_number":1,"text":"ì—˜ë¦¬ë² ì´í„°ì— ê±°ìš¸ ì™œ ìˆì„ê¹Œ?","emotion":"tension","highlight":false,"pause_ms":0,"important_words":["ì—˜ë¦¬ë² ì´í„°","ê±°ìš¸"],"direction":"ë¯¸ìŠ¤í„°ë¦¬ ë¸Œê¸ˆ ì‹œì‘","image_prompt":"Elevator interior with large mirror, mysterious atmosphere, dark moody lighting, cinematic fog, hyper-realistic, 4k, high contrast","sfx":"whoosh","sfx_volume":0.4},
{"scene_number":2,"text":"ë¨¸ë¦¬ í™•ì¸í•˜ë ¤ê³ ?","emotion":"neutral","highlight":false,"pause_ms":300,"important_words":["ë¨¸ë¦¬"],"direction":"ë¸Œê¸ˆ ìœ ì§€","image_prompt":"Person checking hair in elevator mirror, dark moody lighting, mysterious shadows, 4k, cinematic","sfx":"","sfx_volume":0.3},
{"scene_number":3,"text":"ê·¸ëŸ´ë“¯í•œë° ì•„ë‹˜","emotion":"tension","highlight":false,"pause_ms":200,"important_words":["ì•„ë‹˜"],"direction":"ë¸Œê¸ˆ ê¸´ì¥ê° ìƒìŠ¹","image_prompt":"Red X mark graphic overlay on mirror scene, dark moody lighting, mysterious atmosphere, 4k, high contrast","sfx":"","sfx_volume":0.3},
{"scene_number":4,"text":"ì…€ì¹´ ì°ìœ¼ë ¤ê³ ?","emotion":"funny","highlight":false,"pause_ms":200,"important_words":["ì…€ì¹´"],"direction":"ë¸Œê¸ˆ ìœ ì§€","image_prompt":"Person taking selfie in elevator mirror, dark moody lighting, mysterious atmosphere, 4k, cinematic","sfx":"","sfx_volume":0.3},
{"scene_number":5,"text":"ê·¸ê²ƒë„ ì•„ë‹ˆê±°ë“ ","emotion":"tension","highlight":false,"pause_ms":300,"important_words":["ì•„ë‹ˆ"],"direction":"ë¸Œê¸ˆ ì„œìŠ¤íœìŠ¤","image_prompt":"Darkening atmosphere around elevator, dramatic silhouettes, mysterious shadows, 4k, cinematic fog, high contrast","sfx":"","sfx_volume":0.3},
{"scene_number":6,"text":"ì§„ì§œ ì´ìœ ê°€ ì†Œë¦„ì¸ë°","emotion":"serious","highlight":false,"pause_ms":400,"important_words":["ì†Œë¦„"],"direction":"ë¸Œê¸ˆ ë©ˆì¶¤ ì§ì „","image_prompt":"Dark elevator with single spotlight on mirror, ominous atmosphere, dark moody lighting, 4k, cinematic fog","sfx":"","sfx_volume":0.3},
{"scene_number":7,"text":"íœ ì²´ì–´ ì‚¬ìš©ì ë•Œë¬¸ì„","emotion":"shocked","highlight":true,"pause_ms":300,"important_words":["íœ ì²´ì–´"],"direction":"ë¸Œê¸ˆ ë©ˆì¶¤ + ë°˜ì „ìŒ","image_prompt":"Wheelchair user using mirror to see behind them, bright revealing light, clean contrast, infographic style, 4k, high contrast","sfx":"dramatic_stinger","sfx_volume":0.5},
{"scene_number":8,"text":"ë’¤ë¥¼ ëª» ëŒì•„ë³´ë‹ˆê¹Œ","emotion":"neutral","highlight":false,"pause_ms":200,"important_words":["ë’¤"],"direction":"ì”ì”í•œ ë¸Œê¸ˆ IN","image_prompt":"Diagram showing wheelchair in elevator with arrow to mirror, bright revealing light, infographic style, 4k, clean contrast","sfx":"","sfx_volume":0.3},
{"scene_number":9,"text":"ê±°ìš¸ë¡œ ë’¤ë¥¼ í™•ì¸í•˜ëŠ” ê±°ì„","emotion":"warm","highlight":true,"pause_ms":200,"important_words":["í™•ì¸"],"direction":"ë”°ëœ»í•œ ë¸Œê¸ˆ","image_prompt":"Wheelchair user smiling while checking exit through mirror, warm bright lighting, 4k, cinematic, high contrast","sfx":"","sfx_volume":0.3},
{"scene_number":10,"text":"ì´ê±° ì•Œê³  ìˆì—ˆìŒ?","emotion":"relief","highlight":false,"pause_ms":0,"important_words":["ì•Œê³ "],"direction":"ë¸Œê¸ˆ í˜ì´ë“œì•„ì›ƒ","image_prompt":"Person looking at viewer with curious knowing expression, soft cinematic lighting, 4k, trendy aesthetic","sfx":"","sfx_volume":0.3}
]}
ì£¼ëª©: highlight 10ê°œ ì¤‘ 2ê°œ. ê°ì • 6ì¢…(tension,neutral,funny,serious,shocked,warm,relief). sfx 2ê°œ."""

    # â”€â”€ í…Œë§ˆ ìë™ ê°ì§€ í‚¤ì›Œë“œ â”€â”€
    _THEME_KEYWORDS = {
        "life_hack": ["ê¿€íŒ", "ë°©ë²•", "ë…¸í•˜ìš°", "ë¹„ë²•", "ì ˆì•½", "ê°€ì„±ë¹„", "ì¶”ì²œ", "TOP", "ë­í‚¹",
                      "ìˆœìœ„", "ë¦¬ë·°", "ì •ë¦¬", "ëª¨ë¥´ë©´ ì†í•´", "ìƒí™œ", "ì‚´ë¦¼", "ì²­ì†Œ", "ìš”ë¦¬",
                      "ì§€ìš°ëŠ” ë²•", "ë§Œë“œëŠ” ë²•", "í•˜ëŠ” ë²•", "ê¸°ëŠ¥"],
        "empathy": ["ì›ƒê¸´", "ã…‹ã…‹", "ê°œì›ƒ", "ì¡´ì›ƒ", "í™©ë‹¹", "í‚¹ë°›", "ë°ˆ", "ì§¤", "ê³µê°",
                    "ì¼ìƒ", "ì¶œê·¼", "ì›”ìš”ì¼", "ê·€ì°®", "vs", "íŠ¹ì§•", "ìœ í˜•", "ì•„ì¹¨",
                    "í—¬ìŠ¤ì¥", "ì²«ë‚ ", "ì¼ì£¼ì¼", "MBTI", "ì§ì¥"],
        "mystery": ["ë¯¸ìŠ¤í„°ë¦¬", "ì™œ", "ë¹„ë°€", "ì§„ì‹¤", "ì•Œê³ ë³´ë‹ˆ", "ëª°ëë˜", "ì´ìœ ",
                    "ê³¼í•™", "ìƒì‹", "í€´ì¦ˆ", "ê¶ê¸ˆ", "ì†Œë¦„", "ê´´ë‹´", "ë‘¥ê¸€", "ì§„ì§œ",
                    "ë¹„ì‹¼", "ì„¸ê³„ì—ì„œ", "ìš°ì£¼"],
    }

    def __init__(self, config: Config):
        self.config = config
        self.theme = getattr(config, "theme", "auto")
        # v6.2: Gemini ë¡¤ë°± â€” google_api_key ì‚¬ìš©
        api_key = config.google_api_key
        if not api_key:
            raise ValueError("GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤! (ëŒ€ë³¸ ìƒì„±: Gemini)")
        genai_flash.configure(api_key=api_key)
        self._model = genai_flash.GenerativeModel(
            self.GEMINI_MODEL,
            generation_config=genai_flash.types.GenerationConfig(
                temperature=0.4,
                top_p=0.95,
                max_output_tokens=4096,
            ),
        )

        # â˜… í…Œë§ˆ í”„ë¦¬ì…‹ ë ˆì§€ìŠ¤íŠ¸ë¦¬ (gossipì€ ê¸°ì¡´ í´ë˜ìŠ¤ ìƒìˆ˜ ì°¸ì¡°)
        self.THEME_PRESETS = {
            "gossip": {
                "ROLE_PROMPT": self.ROLE_PROMPT,
                "FORMAT_SPEC": self.FORMAT_SPEC,
                "CONTENT_RULES": self.CONTENT_RULES,
                "FEW_SHOT_EXAMPLES": self.FEW_SHOT_EXAMPLES,
                "padded_instruction": (
                    "ì´ ì£¼ì œë¡œ 2030 ì„¸ëŒ€ê°€ ê²©í•˜ê²Œ ê³µê°í•˜ëŠ” 1ì¸ì¹­ ì° ëŒ€ë³¸ì„ ì¨ì¤˜. "
                    "ë¶„ë…¸ì™€ ë°˜ì „ì„ ê°•ì¡°í•´ì„œ ì‘ì„±í•´ì¤˜."
                ),
                "build_prompt_suffix": "ìœ„ ì†ŒìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ë…¸ì™€ ë°˜ì „ì„ ê°•ì¡°í•œ 1ì¸ì¹­ ì° í˜•ì‹ì˜ ìˆì¸  ëŒ€ë³¸ì„ JSONìœ¼ë¡œ ì¶œë ¥í•´.",
                "image_style": "Cinematic, 8k, High Contrast, Korean webtoon style, bold outlines",
                "quality_params": {
                    "min_emotion_types": 4, "max_highlight_ratio": 0.30,
                    "max_long_sentence_count": 2, "long_sentence_threshold": 12,
                    "min_sentence_count": 6, "max_first_sentence_len": 12,
                    "max_consecutive_same_emotion": 2,
                },
            },
            "life_hack": {
                "ROLE_PROMPT": self._LIFE_HACK_ROLE, "FORMAT_SPEC": self._LIFE_HACK_FORMAT,
                "CONTENT_RULES": self._LIFE_HACK_RULES, "FEW_SHOT_EXAMPLES": self._LIFE_HACK_FEWSHOT,
                "padded_instruction": (
                    "ì´ ì£¼ì œë¡œ ê¿€íŒ ëŒ€ë³¸ì„ ì¨ì¤˜. "
                    "ì„œë¡  ë¹¼ê³  ë°”ë¡œ 'ë°©ë²•'ë¶€í„° ì„íŒ©íŠ¸ ìˆê²Œ ì„¤ëª…í•´ì¤˜. "
                    "ì‹œì²­ìê°€ ì €ì¥í•˜ê³  ì‹¶ê²Œ ë§Œë“¤ì–´ì•¼ í•´."
                ),
                "build_prompt_suffix": "ìœ„ ì†ŒìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„œë¡  ì—†ì´ ë°”ë¡œ ë°©ë²•ë¶€í„° ì„íŒ©íŠ¸ ìˆëŠ” ê¿€íŒ ìˆì¸  ëŒ€ë³¸ì„ JSONìœ¼ë¡œ ì¶œë ¥í•´.",
                "image_style": "Cinematic close-up, 8k resolution, clean bright lighting, minimalist, trendy aesthetic",
                "quality_params": {
                    "min_emotion_types": 3, "max_highlight_ratio": 0.35,
                    "max_long_sentence_count": 2, "long_sentence_threshold": 12,
                    "min_sentence_count": 6, "max_first_sentence_len": 12,
                    "max_consecutive_same_emotion": 2,
                },
            },
            "empathy": {
                "ROLE_PROMPT": self._EMPATHY_ROLE, "FORMAT_SPEC": self._EMPATHY_FORMAT,
                "CONTENT_RULES": self._EMPATHY_RULES, "FEW_SHOT_EXAMPLES": self._EMPATHY_FEWSHOT,
                "padded_instruction": (
                    "ì´ ì£¼ì œë¡œ ì¼ìƒ ê³µê° ëŒ€ë³¸ì„ ì¨ì¤˜. "
                    "MBTIë‚˜ ì§ì¥ ìƒí™œ ë“± ëˆ„êµ¬ë‚˜ ê²ªì„ ë²•í•œ ìƒí™©ì„ "
                    "'ë‚´ ì´ì•¼ê¸°'ì²˜ëŸ¼ ì¹œê·¼í•˜ê²Œ ì¨ì¤˜."
                ),
                "build_prompt_suffix": "ìœ„ ì†ŒìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ëˆ„êµ¬ë‚˜ ê³µê°í•  ìˆ˜ ìˆëŠ” 'ë‚´ ì´ì•¼ê¸°' ëŠë‚Œì˜ ìˆì¸  ëŒ€ë³¸ì„ JSONìœ¼ë¡œ ì¶œë ¥í•´.",
                "image_style": "Anime style, vibrant colors, high contrast, expressive, trendy aesthetic",
                "quality_params": {
                    "min_emotion_types": 3, "max_highlight_ratio": 0.30,
                    "max_long_sentence_count": 2, "long_sentence_threshold": 12,
                    "min_sentence_count": 6, "max_first_sentence_len": 12,
                    "max_consecutive_same_emotion": 3, "min_funny_ratio": 0.35,
                },
            },
            "mystery": {
                "ROLE_PROMPT": self._MYSTERY_ROLE, "FORMAT_SPEC": self._MYSTERY_FORMAT,
                "CONTENT_RULES": self._MYSTERY_RULES, "FEW_SHOT_EXAMPLES": self._MYSTERY_FEWSHOT,
                "padded_instruction": (
                    "ì´ ì£¼ì œë¡œ ë¯¸ìŠ¤í„°ë¦¬/ìƒì‹ ëŒ€ë³¸ì„ ì¨ì¤˜. "
                    "ì²˜ìŒì— ê¶ê¸ˆì¦ì„ ìœ ë°œí•˜ëŠ” ì§ˆë¬¸ì„ ë˜ì§€ê³ , "
                    "ëê¹Œì§€ ë³´ê²Œ ë§Œë“  ë’¤ ë§ˆì§€ë§‰ì— ê²°ë¡ ì„ ë‚´ì¤˜."
                ),
                "build_prompt_suffix": "ìœ„ ì†ŒìŠ¤ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¶ê¸ˆì¦ ìœ ë°œ â†’ ëê¹Œì§€ ë³´ê²Œ ë§Œë“œëŠ” ë¯¸ìŠ¤í„°ë¦¬ ìˆì¸  ëŒ€ë³¸ì„ JSONìœ¼ë¡œ ì¶œë ¥í•´.",
                "image_style": "Mysterious atmosphere, dark moody lighting, hyper-realistic, 4k, cinematic fog, high contrast",
                "quality_params": {
                    "min_emotion_types": 3, "max_highlight_ratio": 0.25,
                    "max_long_sentence_count": 2, "long_sentence_threshold": 12,
                    "min_sentence_count": 6, "max_first_sentence_len": 12,
                    "max_consecutive_same_emotion": 2,
                },
            },
        }
        self._active_preset = self.THEME_PRESETS["gossip"]  # ê¸°ë³¸ê°’

    def _detect_theme(self, title: str) -> str:
        """ì£¼ì œ í‚¤ì›Œë“œ ê¸°ë°˜ í…Œë§ˆ ìë™ ê°ì§€. ë§¤ì¹­ ì•ˆ ë˜ë©´ 'gossip' ë°˜í™˜."""
        scores = {}
        for theme, keywords in self._THEME_KEYWORDS.items():
            score = sum(1 for kw in keywords if kw in title)
            if score > 0:
                scores[theme] = score
        if not scores:
            return "gossip"
        return max(scores, key=scores.get)

    def _get_preset(self, topic_title: str = "") -> dict:
        """í˜„ì¬ í…Œë§ˆì— ë§ëŠ” í”„ë¦¬ì…‹ ë°˜í™˜. autoë©´ topic_titleë¡œ ê°ì§€."""
        theme = self.theme
        if theme == "auto":
            theme = self._detect_theme(topic_title)
            print(f"  ğŸ­ í…Œë§ˆ ìë™ ê°ì§€: '{theme}' (ì£¼ì œ: {topic_title[:30]})")
        preset = self.THEME_PRESETS.get(theme, self.THEME_PRESETS["gossip"])
        return preset

    def _build_prompt(self, post: dict, retry_feedback: str = "") -> str:
        """3ë¶„í•  í”„ë¡¬í”„íŠ¸ ì¡°ë¦½: í…Œë§ˆë³„ Role + Content + Format + Few-shot + ì†ŒìŠ¤ ë°ì´í„°"""
        # â˜… í…Œë§ˆ í”„ë¦¬ì…‹ ì‚¬ìš©
        preset = self._active_preset

        comments = post.get('comments', [])
        comments_text = ""
        if isinstance(comments, list) and comments:
            comments_text = "\n## ë² ìŠ¤íŠ¸ ëŒ“ê¸€\n" + "\n".join(f"- {c}" for c in comments[:4])

        source_name = post.get('source', 'ì»¤ë®¤ë‹ˆí‹°')
        source_brand_map = {
            "natepan": "ë„¤ì´íŠ¸íŒ ë ˆì „ë“œ ì°", "nate_pann": "ë„¤ì´íŠ¸íŒ ë ˆì „ë“œ ì°",
            "ë„¤ì´íŠ¸íŒ": "ë„¤ì´íŠ¸íŒ ë ˆì „ë“œ ì°", "dcinside": "ë””ì”¨ ë ˆì „ë“œ",
            "dc_inside": "ë””ì”¨ ë ˆì „ë“œ", "ë””ì‹œì¸ì‚¬ì´ë“œ": "ë””ì”¨ ë ˆì „ë“œ",
            "fmkorea": "í¨ì½” í•«ê¸€", "viral_topic": "í™”ì œê¸€",
        }
        source_brand = source_brand_map.get(source_name.lower(), f"{source_name} í™”ì œê¸€")

        retry_section = ""
        if retry_feedback:
            retry_section = f"\nâš ï¸ [ì´ì „ ëŒ€ë³¸ ë¬¸ì œì  â€” ë°˜ë“œì‹œ ìˆ˜ì •í•´ì„œ ë‹¤ì‹œ ì¨ì¤˜]\n{retry_feedback}\n"

        # â˜… image_style ê°•ì œ ì§€ì‹œ
        image_style = preset.get('image_style', '')
        image_style_section = ""
        if image_style:
            image_style_section = f"\n[image_prompt ìŠ¤íƒ€ì¼ ê°•ì œ]\nëª¨ë“  image_prompt ëì— ë°˜ë“œì‹œ í¬í•¨: {image_style}\n"

        # ì‚¬ìš©ì ë©”ì‹œì§€ (ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ëŠ” SHORTS_SYSTEM_PROMPTë¡œ ë³„ë„ ì „ë‹¬)
        return f"""{preset['ROLE_PROMPT']}

{preset['FEW_SHOT_EXAMPLES']}

[ì¶œë ¥ JSON ìŠ¤í‚¤ë§ˆ]
{preset['FORMAT_SPEC']}

{preset['CONTENT_RULES']}
{image_style_section}
---
[ì†ŒìŠ¤ ë°ì´í„°]
ì¶œì²˜: {source_name} | ë¸Œëœë”©: "{source_brand}"
ì œëª©: {post['title']}

{post.get('content', '')[:2500]}
{comments_text}
{retry_section}
{preset['build_prompt_suffix']}"""

    def _quality_check(self, script_data: dict) -> list[str]:
        """ëŒ€ë³¸ í’ˆì§ˆ ê²€ì¦ v3 â€” í…Œë§ˆë³„ íŒŒë¼ë¯¸í„° ì ìš©. ë¬¸ì œì  ë¦¬ìŠ¤íŠ¸ ë°˜í™˜."""
        issues = []
        lines = script_data.get("script", [])
        if not lines:
            issues.append("script ë°°ì—´ì´ ë¹„ì–´ìˆìŒ")
            return issues

        # â˜… í…Œë§ˆë³„ íŒŒë¼ë¯¸í„° ë¡œë“œ
        qp = self._active_preset.get("quality_params", {})
        min_emotions = qp.get("min_emotion_types", 5)
        max_hl_ratio = qp.get("max_highlight_ratio", 0.30)
        max_long = qp.get("max_long_sentence_count", 2)
        long_thresh = qp.get("long_sentence_threshold", 22)
        min_sentences = qp.get("min_sentence_count", 10)
        max_first_len = qp.get("max_first_sentence_len", 15)
        max_consec = qp.get("max_consecutive_same_emotion", 2)

        n = len(lines)
        emotions = [l.get("emotion", "neutral") for l in lines]

        # 1) ê°™ì€ ê°ì • ì—°ì† ì²´í¬ (í…Œë§ˆë³„: gossip 2ì—°ì†, comedy 3ì—°ì†)
        limit = max_consec + 1
        for i in range(len(emotions) - limit + 1):
            if len(set(emotions[i:i+limit])) == 1:
                issues.append(f"ê°™ì€ ê°ì • {limit}ì—°ì†: {emotions[i]} (ì¥ë©´ {i+1}~{i+limit})")
                break

        # 2) ê°ì • ì¢…ë¥˜ ìµœì†Œ Nì¢…
        unique_emotions = set(emotions)
        if len(unique_emotions) < min_emotions:
            issues.append(f"ê°ì • ì¢…ë¥˜ ë¶€ì¡±: {len(unique_emotions)}ì¢… (ìµœì†Œ {min_emotions}ì¢… í•„ìš”) â€” {unique_emotions}")

        # 3) highlight ë¹„ìœ¨ ì²´í¬
        highlight_count = sum(1 for l in lines if l.get("highlight") is True)
        max_highlights = max(2, int(n * max_hl_ratio))
        if highlight_count > max_highlights:
            issues.append(f"highlight ë‚¨ìš©: {highlight_count}/{n}ê°œ (ìµœëŒ€ {max_highlights}ê°œ)")
        if n >= 8 and highlight_count == n:
            issues.append(f"highlight ì „ë¶€ true ({n}ê°œ)")

        # 4) ê¸´ ë¬¸ì¥ ì²´í¬
        long_count = sum(1 for l in lines if len(l.get("text", "")) > long_thresh)
        if long_count > max_long:
            issues.append(f"{long_thresh}ì ì´ˆê³¼ ë¬¸ì¥ {long_count}ê°œ (ìµœëŒ€ {max_long}ê°œ)")

        # 5) AIìŠ¬ë¡­ ë‹¨ì–´ ì²´í¬
        full_text = " ".join(l.get("text", "") for l in lines)
        slop_found = [w for w in self._AI_SLOP_WORDS if w in full_text]
        if len(slop_found) >= 2:
            issues.append(f"AIìŠ¬ë¡­ ë‹¨ì–´ {len(slop_found)}ê°œ: {slop_found}")

        # 6) ì˜ì–´/ì™¸êµ­ì–´ í˜¼ì… ì²´í¬ (text í•„ë“œë§Œ)
        foreign_pattern = re.compile(r'[a-zA-ZĞ°-ÑĞ-Ğ¯Ñ‘Ğ]{3,}')
        allowed_english = {
            "CCTV", "SNS", "MZ", "GDP", "AI", "CEO", "IT", "PC", "TV", "OTT",
            "MBTI", "TMI", "BGM", "SFX", "TOP", "DNA", "USB", "LED", "DIY", "FAQ",
            # 16 MBTI ìœ í˜•
            "ISTJ", "ISFJ", "INFJ", "INTJ", "ISTP", "ISFP", "INFP", "INTP",
            "ESTP", "ESFP", "ENFP", "ENTP", "ESTJ", "ESFJ", "ENFJ", "ENTJ",
        }
        for l in lines:
            txt = l.get("text", "")
            foreign_matches = foreign_pattern.findall(txt)
            real_foreign = [m for m in foreign_matches if m.upper() not in allowed_english]
            if real_foreign:
                issues.append(f"ì™¸êµ­ì–´ í˜¼ì…: {real_foreign} (ì¥ë©´ {l.get('scene_number', '?')})")
                break

        # 7) ì²« ë¬¸ì¥ ê¸¸ì´
        if lines and len(lines[0].get("text", "")) > max_first_len:
            first_len = len(lines[0].get("text", ""))
            issues.append(f"ì²« ë¬¸ì¥(í›…) {first_len}ì â€” {max_first_len}ì ì´ë‚´ ê¶Œì¥")

        # 8) ë¶„ëŸ‰ ì²´í¬
        if n < min_sentences:
            issues.append(f"ë¬¸ì¥ ìˆ˜ ë¶€ì¡±: {n}ê°œ (ìµœì†Œ {min_sentences}ê°œ)")

        # 9) image_prompt í•œêµ­ì–´ ì²´í¬ (ì˜ì–´ í•„ìˆ˜)
        kr_pattern = re.compile(r'[ê°€-í£]')
        kr_prompts = [i for i, l in enumerate(lines, 1) if kr_pattern.search(l.get("image_prompt", ""))]
        if kr_prompts:
            issues.append(f"image_promptì— í•œêµ­ì–´ í¬í•¨ (ì¥ë©´ {kr_prompts[:3]}). ì˜ì–´ë¡œë§Œ ì‘ì„±í•´ì•¼ í•¨.")

        # 10) comedy ì „ìš©: funny ë¹„ìœ¨ ì²´í¬
        min_funny = qp.get("min_funny_ratio", 0)
        if min_funny > 0 and n > 0:
            funny_count = sum(1 for e in emotions if e == "funny")
            if funny_count / n < min_funny:
                issues.append(f"funny ê°ì • ë¶€ì¡±: {funny_count}/{n} ({min_funny*100:.0f}%+ í•„ìš”)")

        return issues

    def generate(self, post: dict) -> Optional[dict]:
        """v8.0: í…Œë§ˆë³„ ëŒ€ë³¸ ìƒì„±. ê²€ì¦ ì‹¤íŒ¨ ì‹œ ìµœëŒ€ 3íšŒ ì¬ìƒì„±."""
        # â˜… í…Œë§ˆ í”„ë¦¬ì…‹ ê²°ì •
        self._active_preset = self._get_preset(post.get("title", ""))

        print(f"\n{'='*60}")
        print(f"ğŸ“ Stage 2: ëŒ€ë³¸ ìƒì„± (v8.0 ë©€í‹°í…Œë§ˆ í”„ë¡¬í”„íŠ¸)")
        print(f"  ì œëª©: {post['title'][:40]}...")
        print(f"{'='*60}")

        content = post.get("content", "")
        title = post.get("title", "")
        is_viral = post.get("_is_viral", False)

        # â”€â”€ ì†ŒìŠ¤ í’ˆì§ˆ ì²´í¬ (ë°”ì´ëŸ´/í† í”½ ì†ŒìŠ¤ëŠ” ì œëª© ê¸°ë°˜ì´ë¯€ë¡œ ìŠ¤í‚µ) â”€â”€
        if not is_viral:
            if len(content) < 200:
                print(f"  âš ï¸  ì†ŒìŠ¤ ë‚´ìš© ë¶€ì¡± ({len(content)}ì), ê±´ë„ˆëœ€")
                return None
            for kw in CommunityScraper.BLOCK_KEYWORDS:
                if kw in content or kw in title:
                    print(f"  ğŸš« ì°¨ë‹¨ í‚¤ì›Œë“œ: '{kw}' ë°œê²¬ â†’ ê±´ë„ˆëœ€")
                    return None
            spam_count = sum(1 for kw in CommunityScraper.UI_KEYWORDS if kw in content)
            if spam_count >= 2:
                print(f"  âš ï¸  UI/ê´‘ê³  í…ìŠ¤íŠ¸ ê°ì§€ ({spam_count}ê°œ í‚¤ì›Œë“œ), ê±´ë„ˆëœ€")
                return None
            risk_count = sum(1 for kw in CommunityScraper.RISKY_CONTENT_KEYWORDS if kw in content or kw in title)
            if risk_count >= 1:
                print(f"  âš ï¸  ìœ„í—˜ ì½˜í…ì¸  ê°ì§€ ({risk_count}ê°œ): í—ˆìœ„ì •ë³´ ë°©ì§€ë¥¼ ìœ„í•´ ê±´ë„ˆëœ€")
                return None
        else:
            print(f"  ğŸ”¥ ë°”ì´ëŸ´ ì†ŒìŠ¤ â†’ í’ˆì§ˆ í•„í„° ë°”ì´íŒ¨ìŠ¤")

        start = time.time()
        retry_feedback = ""
        max_attempts = 3

        for attempt in range(1, max_attempts + 1):
            try:
                prompt = self._build_prompt(post, retry_feedback)
                # v6.2: Gemini ë¡¤ë°± â€” DIRECTOR_PERSONA + í”„ë¡¬í”„íŠ¸ë¥¼ í•©ì³ ì „ë‹¬
                full_prompt = self.SYSTEM_PROMPT + "\n\n" + prompt
                response = self._model.generate_content(full_prompt)
                if not response.text:
                    raise ValueError("Gemini API returned empty response")
                raw = response.text
                script_data = self._extract_json(raw)

                # ì •í™•ì„± ê²€ì¦ (ì›ë¬¸ ëŒ€ì¡°)
                script_data = self._validate_script_accuracy(script_data, post)

                # ëŒ€ë³¸ ë°ì´í„° í´ë¦¬ë‹
                script_data = self._clean_script_data(script_data)

                # â˜… v7.0: í’ˆì§ˆ ê²€ì¦ + ì¬ìƒì„± ë£¨í”„
                quality_issues = self._quality_check(script_data)

                if not quality_issues:
                    elapsed = time.time() - start
                    n = len(script_data.get("script", []))
                    script_data["_meta"] = {
                        "time": f"{elapsed:.1f}s",
                        "model": self.GEMINI_MODEL,
                        "source": post.get("content", "")[:100],
                        "accuracy_warnings": script_data.get("_accuracy_warnings", 0),
                        "attempts": attempt,
                    }
                    print(f"  âœ… ëŒ€ë³¸ ì™„ë£Œ! ({elapsed:.1f}ì´ˆ, {n}ë¬¸ì¥, {attempt}íšŒì°¨, Gemini)")
                    return script_data

                # ê²€ì¦ ì‹¤íŒ¨ â†’ ì¬ìƒì„± ì¤€ë¹„
                print(f"  âš ï¸  í’ˆì§ˆ ê²€ì¦ ì‹¤íŒ¨ (ì‹œë„ {attempt}/{max_attempts}):")
                for issue in quality_issues:
                    print(f"     - {issue}")

                if attempt < max_attempts:
                    retry_feedback = "\n".join(f"- {issue}" for issue in quality_issues)
                    print(f"  ğŸ”„ í”¼ë“œë°± í¬í•¨í•˜ì—¬ ì¬ìƒì„±...")
                else:
                    # ë§ˆì§€ë§‰ ì‹œë„ë„ ì‹¤íŒ¨ â†’ ê·¸ë˜ë„ ì‚¬ìš© (ì™„ë²½í•˜ì§€ ì•Šì§€ë§Œ)
                    elapsed = time.time() - start
                    n = len(script_data.get("script", []))
                    script_data["_meta"] = {
                        "time": f"{elapsed:.1f}s",
                        "model": self.GEMINI_MODEL,
                        "source": post.get("content", "")[:100],
                        "accuracy_warnings": script_data.get("_accuracy_warnings", 0),
                        "attempts": attempt,
                        "quality_issues": quality_issues,
                    }
                    print(f"  âš ï¸  {max_attempts}íšŒ ì‹œë„ í›„ì—ë„ ë¯¸í†µê³¼ â€” ìµœì„  ê²°ê³¼ ì‚¬ìš© ({n}ë¬¸ì¥)")
                    return script_data

            except Exception as e:
                print(f"  âŒ Gemini API ì—ëŸ¬ (ì‹œë„ {attempt}/{max_attempts}): {e}")
                try:
                    if 'raw' in locals():
                        print(f"  ğŸ” Gemini ì›ë³¸ (ì• 300ì): {raw[:300]}")
                except Exception:
                    pass
                if attempt == max_attempts:
                    return self._fallback_script(post)

        return self._fallback_script(post)

    def generate_from_topic(self, topic: str) -> Optional[dict]:
        """ì£¼ì œë§Œìœ¼ë¡œ ëŒ€ë³¸ ìƒì„± (ë°”ì´ëŸ´/ìˆ˜ë™ ëª¨ë“œ) â€” í…Œë§ˆë³„ ë¶„ê¸°"""
        # â˜… í…Œë§ˆ í”„ë¦¬ì…‹ì—ì„œ padded_instruction ê°€ì ¸ì˜¤ê¸°
        preset = self._get_preset(topic)
        padded = (
            f"ì£¼ì œ: '{topic}'\n"
            f"{preset['padded_instruction']}"
        )
        fake = {
            "title": topic,
            "content": padded,
            "source": "viral_topic",
            "_is_viral": True,
        }
        return self.generate(fake)

    # â”€â”€ v6.0 ëŒ€ë³¸ ë°ì´í„° í´ë¦¬ë‹ (image_prompt ì˜¤ì—¼ + ì§€ì‹œë¬¸ ì˜¤ì—¼ + í•„ë“œ ì •ê·œí™”) â”€â”€

    # íŒ¨í„´ A: image_prompt ì „ìš© í‚¤ì›Œë“œ (textì— ìˆìœ¼ë©´ ì˜¤ì—¼)
    _IMG_CONTAMINATION_KW = [
        "ì²« ì¥ë©´ê³¼ ë™ì¼í•œ ìºë¦­í„°", "ë™ì¼í•œ ìºë¦­í„°", "Bê¸‰ ì›¹íˆ°",
        "í´ë¡œì¦ˆì—…", "ë’·ëª¨ìŠµ", "ë°°ê²½ì€", "ê³¼ì¥ëœ í‘œì •",
        "ë‹¨ìˆœí•˜ê³  êµµì€ ì„ ", "í•œêµ­ Bê¸‰", "ì›¹íˆ° ìŠ¤íƒ€ì¼",
        "íŒŒë§ˆë¨¸ë¦¬", "ê½ƒë¬´ëŠ¬", "ë¸”ë¼ìš°ìŠ¤", "ink outline",
        "muted warm", "realistic", "webtoon", "illustration",
    ]

    # íŒ¨í„´ B: ì •ê·œì‹ â€” ì—°ì¶œ ì§€ì‹œë¬¸ì´ textì— ë“¤ì–´ì˜¨ ê²½ìš° (ê´„í˜¸ ì•ˆ ì§€ì‹œ, ì˜ì–´ í”„ë¡¬í”„íŠ¸ ë“±)
    _DIRECTIVE_REGEX = re.compile(
        r'('
        r'\(.*?(ì¥ë©´|ìºë¦­í„°|ë°°ê²½|í‘œì •|í´ë¡œì¦ˆì—…|ë’·ëª¨ìŠµ|ì¡°ëª…|ì¹´ë©”ë¼|ì•µê¸€).*?\)'  # ê´„í˜¸ ì•ˆ í•œêµ­ì–´ ì§€ì‹œ
        r'|'
        r'\[.*?(scene|character|background|close.?up|back\s?view).*?\]'  # ëŒ€ê´„í˜¸ ì•ˆ ì˜ì–´ ì§€ì‹œ
        r'|'
        r'(?:Korean|Naver|webtoon|illustration|Bê¸‰|ink|outline|muted|realistic)'  # ì˜ì–´ í”„ë¡¬í”„íŠ¸ í‚¤ì›Œë“œ
        r'(?:\s*,\s*(?:Korean|Naver|webtoon|illustration|Bê¸‰|ink|outline|muted|realistic)){2,}'  # 3ê°œ ì´ìƒ ì—°ì†
        r')',
        re.IGNORECASE,
    )

    def _clean_script_data(self, script_data: dict) -> dict:
        """ëŒ€ë³¸ JSON í›„ì²˜ë¦¬: ì˜¤ì—¼ ì œê±° + í•„ë“œ ì •ê·œí™” + ë¹ˆ ë¬¸ì¥ ì œê±°

        3ë‹¨ê³„ í´ë¦¬ë‹:
        1) image_prompt í‚¤ì›Œë“œ ì˜¤ì—¼ íƒì§€ â†’ text ë¬´íš¨í™”
        2) ì •ê·œì‹ìœ¼ë¡œ ì—°ì¶œ ì§€ì‹œë¬¸ / ì˜ì–´ í”„ë¡¬í”„íŠ¸ ì”ì¬ ì œê±°
        3) text/emotion/sfx í•„ë“œ ì •ê·œí™” + ë¹ˆ ë¬¸ì¥ ì œê±°
        """
        cleaned_count = 0

        for line in script_data.get("script", []):
            txt = line.get("text", "")
            if not txt:
                continue

            # â”€â”€ Stage 1: image_prompt í‚¤ì›Œë“œ ì˜¤ì—¼ (ê¸°ì¡´ ë¡œì§ ê°•í™”) â”€â”€
            match_count = sum(1 for kw in self._IMG_CONTAMINATION_KW if kw in txt)
            if len(txt) > 20 and match_count >= 2:
                print(f"  âš ï¸  [í´ë¦°] image_prompt í˜¼ì… â†’ ì œê±°: {txt[:50]}...")
                line["text"] = ""
                cleaned_count += 1
                continue

            # â”€â”€ Stage 2: ì •ê·œì‹ìœ¼ë¡œ ì—°ì¶œ ì§€ì‹œë¬¸ ì”ì¬ ì œê±° â”€â”€
            original = txt
            txt = self._DIRECTIVE_REGEX.sub("", txt).strip()
            # ê´„í˜¸/ëŒ€ê´„í˜¸ ì•ˆ ì§€ì‹œë¬¸ë§Œ ë‹¨ë…ìœ¼ë¡œ ë‚¨ì€ ê²½ìš° ì „ì²´ ì œê±°
            txt = re.sub(r'\(.*?(ì¥ë©´|ìºë¦­í„°|ë°°ê²½|í‘œì •|ì¡°ëª…).*?\)', '', txt).strip()
            txt = re.sub(r'\[.*?(scene|character|background).*?\]', '', txt, flags=re.IGNORECASE).strip()
            # textì™€ image_promptê°€ ì™„ì „íˆ ë™ì¼í•˜ë©´ text ë¬´íš¨í™”
            if txt and txt == line.get("image_prompt", ""):
                txt = ""
            if txt != original:
                if not txt:
                    print(f"  âš ï¸  [í´ë¦°] ì§€ì‹œë¬¸ ì „ì²´ ì˜¤ì—¼ â†’ ì œê±°: {original[:50]}...")
                    cleaned_count += 1
                else:
                    print(f"  ğŸ”§  [í´ë¦°] ì§€ì‹œë¬¸ ë¶€ë¶„ ì œê±°: {original[:30]}... â†’ {txt[:30]}...")
            line["text"] = txt

            # â”€â”€ Stage 3: í•„ë“œ ì •ê·œí™” â”€â”€
            # emotion í•„ë“œ: í•œêµ­ì–´ â†’ ì˜ì–´ ë§¤í•‘ + ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ neutralë¡œ êµì •
            valid_emotions = {
                "neutral", "tension", "surprise", "anger", "angry",
                "sad", "fun", "funny", "shock", "shocked", "relief",
                "excited", "warm", "serious", "whisper",
            }
            # â˜… í•œêµ­ì–´ emotion â†’ ì˜ì–´ ë§¤í•‘ (Geminiê°€ í•œêµ­ì–´ë¡œ ë±‰ëŠ” ê²½ìš° ëŒ€ë¹„)
            _KR_EMOTION_MAP = {
                "ì¶©ê²©": "shocked", "ë†€ëŒ": "surprise", "ê²½ì•…": "shocked",
                "ë¶„ë…¸": "angry", "ë¹¡ì¹¨": "angry", "í™”ë‚¨": "angry",
                "ìŠ¬í””": "sad", "ìš°ìš¸": "sad", "í—ˆíƒˆ": "sad", "ì¢Œì ˆ": "sad",
                "ì¬ë¯¸": "funny", "ì›ƒê¹€": "funny", "ìœ ë¨¸": "funny",
                "ê¸´ì¥": "tension", "ë¶ˆì•ˆ": "tension", "ì´ˆì¡°": "tension",
                "ê°ë™": "warm", "ë”°ëœ»": "warm", "ë­‰í´": "warm",
                "ê³µí¬": "whisper", "ë¬´ì„œì›€": "whisper", "ì†Œë¦„": "whisper",
                "í˜„íƒ€": "sad", "ì²´ë…": "sad", "í•œìˆ¨": "sad",
                "í¥ë¶„": "excited", "ì„¤ë ˜": "excited", "ê¸°ëŒ€": "excited",
                "ì§„ì§€": "serious", "ì‹¬ê°": "serious",
                "ì•ˆë„": "relief", "í›„ë ¨": "relief",
                "ê¶ê¸ˆ": "tension", "ì ˆë°•": "tension",
            }
            emo = line.get("emotion", "neutral")
            # ì½¤ë§ˆë¡œ ì—¬ëŸ¬ ê°ì • ë‚˜ì—´ëœ ê²½ìš° ("ìŠ¬í””, í—ˆíƒˆ") â†’ ì²« ë²ˆì§¸ë§Œ ì‚¬ìš©
            if "," in emo or "/" in emo:
                emo = re.split(r'[,/]', emo)[0].strip()
            # í•œêµ­ì–´ ë§¤í•‘ ì‹œë„
            if emo not in valid_emotions:
                mapped = _KR_EMOTION_MAP.get(emo)
                if mapped:
                    line["emotion"] = mapped
                else:
                    # ë¶€ë¶„ ë§¤ì¹­ (e.g. "ê¶ê¸ˆí•¨" â†’ "ê¶ê¸ˆ" ë§¤ì¹­)
                    matched = False
                    for kr, en in _KR_EMOTION_MAP.items():
                        if kr in emo:
                            line["emotion"] = en
                            matched = True
                            break
                    if not matched:
                        line["emotion"] = "neutral"

            # sfx í•„ë“œ: ëŒ€ê´„í˜¸/ê³µë°± ì •ë¦¬ + ìœ ì‚¬ì–´ ë§¤í•‘
            sfx = str(line.get("sfx", ""))
            sfx = re.sub(r'[\[\]\s]', '', sfx).strip()
            # â˜… mapping.jsonì— ì—†ëŠ” SFX íƒœê·¸ â†’ ìœ ì‚¬í•œ íƒœê·¸ë¡œ ìë™ ë³€í™˜
            _SFX_ALIAS_MAP = {
                # ë“œë¼ë§ˆ/ì•¡ì…˜
                "punch_hit": "punch", "hit": "punch", "slap": "punch",
                "drama_punch": "punch", "crash": "glass_break", "break": "glass_break",
                "explosion": "thunder", "boom": "thunder", "slam": "punch",
                # ë°˜ì‘/ê°ì •
                "deep_sigh": "gasp", "sigh": "gasp", "cry": "gasp",
                "scream": "gasp", "wow": "crowd_ooh", "ooh": "crowd_ooh",
                "surprise": "gasp", "shock": "record_scratch",
                # ì „í™˜/UI
                "fast_swoosh": "swoosh", "swipe": "swoosh", "slide": "swoosh",
                "pop": "ding", "question_pop": "ding", "alert": "kakao_alert",
                "notification": "kakao_alert", "bell": "doorbell",
                "click": "typing", "tap": "typing",
                # ì½”ë¯¸ë””
                "giggle": "laugh", "lol": "laugh", "haha": "laugh",
                "comedy": "rimshot", "joke": "rimshot", "spring": "boing",
                # ê¸°íƒ€
                "empty_stomach_growl": "boing", "growl": "boing",
                "money": "cash_register", "coin": "cash_register", "pay": "cash_register",
                "vibrate": "phone_vibrate", "phone": "phone_vibrate",
            }
            if sfx and sfx not in {"", "none", "null"}:
                sfx_lower = sfx.lower()
                if sfx_lower in _SFX_ALIAS_MAP:
                    sfx = _SFX_ALIAS_MAP[sfx_lower]
            line["sfx"] = sfx

            # sfx_volume í•„ë“œ: 0.1~1.0 ë²”ìœ„ ê°•ì œ
            vol = line.get("sfx_volume", 0.7)
            try:
                vol = float(vol)
                vol = max(0.1, min(1.0, vol))
            except (ValueError, TypeError):
                vol = 0.7
            line["sfx_volume"] = vol

            # important_words í•„ë“œ: ë¦¬ìŠ¤íŠ¸ ë³´ì¥
            iw = line.get("important_words", [])
            if isinstance(iw, str):
                iw = [w.strip() for w in iw.split(",") if w.strip()]
            elif not isinstance(iw, list):
                iw = []
            line["important_words"] = iw

        # â”€â”€ ë¹ˆ text ë¬¸ì¥ ì œê±° â”€â”€
        before = len(script_data.get("script", []))
        script_data["script"] = [
            line for line in script_data.get("script", [])
            if line.get("text", "").strip()
        ]
        after = len(script_data.get("script", []))

        if cleaned_count > 0 or before != after:
            print(f"  ğŸ§¹ í´ë¦¬ë‹ ì™„ë£Œ: {cleaned_count}ê±´ ì˜¤ì—¼ ì œê±°, "
                  f"{before}â†’{after}ë¬¸ì¥")

        return script_data

    def _extract_json(self, text: str) -> dict:
        # 0ì°¨ ì „ì²˜ë¦¬: ë§ˆí¬ë‹¤ìš´ ë°±í‹± ì œê±° (```json ... ``` ë˜ëŠ” ``` ... ```)
        text = text.strip()
        if text.startswith("```"):
            text = re.sub(r"^```(?:json)?\s*", "", text)
            text = re.sub(r"\s*```\s*$", "", text)
            text = text.strip()

        # 1ì°¨: ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ë°”ë¡œ JSON íŒŒì‹± ì‹œë„
        try:
            parsed = json.loads(text)
            # â˜… Geminiê°€ ë°°ì—´ [{}]ë¡œ ê°ìŒ€ ìˆ˜ ìˆìŒ â†’ ì²« ë²ˆì§¸ dict ì¶”ì¶œ
            if isinstance(parsed, list) and len(parsed) > 0 and isinstance(parsed[0], dict):
                return parsed[0]
            if isinstance(parsed, dict):
                return parsed
        except (json.JSONDecodeError, TypeError):
            pass

        # 1ì°¨: ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ
        json_match = re.search(r"```json\s*(.*?)\s*```", text, re.DOTALL)
        if json_match:
            try:
                parsed = json.loads(json_match.group(1))
                if isinstance(parsed, list) and len(parsed) > 0 and isinstance(parsed[0], dict):
                    return parsed[0]
                return parsed
            except json.JSONDecodeError:
                pass
        # 2ì°¨: ì¤‘ê´„í˜¸ ë§¤ì¹­ (ê°€ì¥ ë°”ê¹¥ìª½ { } ìŒ ì°¾ê¸°)
        depth = 0
        start_idx = -1
        for i, ch in enumerate(text):
            if ch == '{':
                if depth == 0:
                    start_idx = i
                depth += 1
            elif ch == '}':
                depth -= 1
                if depth == 0 and start_idx >= 0:
                    try:
                        return json.loads(text[start_idx:i+1])
                    except json.JSONDecodeError:
                        start_idx = -1
                        continue
        raise ValueError("JSON íŒŒì‹± ì‹¤íŒ¨: ìœ íš¨í•œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    def _validate_script_accuracy(self, script_data: dict, post: dict) -> dict:
        """ì›ë¬¸ ëŒ€ì¡° ê²€ì¦: AIê°€ ë§Œë“¤ì–´ë‚¸ í—ˆìœ„ ìš”ì†Œ íƒì§€ ë° ì œê±°.

        ê²€ì¦ í•­ëª©:
        1. ì›ë¬¸ì— ì—†ëŠ” ì§ì ‘ ì¸ìš©(ë”°ì˜´í‘œ ëŒ€í™”) íƒì§€
        2. ì˜í•™/ë²•ë¥ /ê¸ˆìœµ í—ˆìœ„ì •ë³´ íŒ¨í„´ íƒì§€
        3. ì¶œì²˜ ë¶ˆëª… í†µê³„/ìˆ˜ì¹˜ íƒì§€
        4. ì›ë¬¸ í•µì‹¬ í‚¤ì›Œë“œ ëˆ„ë½ ì—¬ë¶€ í™•ì¸
        """
        source_text = post.get("content", "")
        script_lines = script_data.get("script", [])
        if not script_lines or not source_text:
            return script_data

        warnings = []
        cleaned_lines = []

        for line in script_lines:
            text = line.get("text", "")
            flagged = False

            # 1) ì›ë¬¸ì— ì—†ëŠ” ì§ì ‘ ì¸ìš©/ëŒ€í™” íƒì§€
            quotes = re.findall(r'["\u201c\u201d](.+?)["\u201c\u201d]', text)
            for q in quotes:
                if len(q) > 5 and q not in source_text:
                    # ì›ë¬¸ì— ì—†ëŠ” ëŒ€ì‚¬ â†’ ë”°ì˜´í‘œ ì œê±°í•˜ê³  ê°„ì ‘í™”
                    text = text.replace(f'"{q}"', q)
                    text = text.replace(f'\u201c{q}\u201d', q)
                    warnings.append(f"ì§ì ‘ì¸ìš© ì œê±°: '{q[:20]}...'")

            # 2) ì˜í•™/ë²•ë¥ /ê¸ˆìœµ í—ˆìœ„ì •ë³´ íŒ¨í„´
            risky_patterns = [
                (r'(\d+)%\s*(í™•ë¥ |ê°€ëŠ¥ì„±|ì¹˜ë£Œìœ¨|ìƒì¡´ìœ¨)', "ì˜í•™ í†µê³„"),
                (r'ë²Œê¸ˆ\s*\d+', "ë²•ë¥  ìˆ˜ì¹˜"),
                (r'(\d+)(ë§Œì›|ì–µì›|ì¡°ì›)', "ê¸ˆì•¡"),
                (r'ì—°êµ¬(ì—\s*ë”°ë¥´ë©´|ê²°ê³¼|íŒ€|ì§„)', "ë¯¸í™•ì¸ ì—°êµ¬ ì¸ìš©"),
                (r'ì „ë¬¸ê°€(ì—\s*ë”°ë¥´ë©´|ë“¤ì€|ê°€)', "ë¯¸í™•ì¸ ì „ë¬¸ê°€ ì¸ìš©"),
            ]
            for pat, label in risky_patterns:
                match = re.search(pat, text)
                if match and match.group(0) not in source_text:
                    warnings.append(f"{label} ê°ì§€(ì›ë¬¸ ë¯¸í™•ì¸): '{match.group(0)}'")
                    # ì œê±°í•˜ì§€ ì•Šë˜, í—¤ì§€ í‘œí˜„ìœ¼ë¡œ ê°ìŒ€ ìˆ˜ ìˆìŒ
                    # ì‹¬ê°í•œ ê²½ìš° ë¼ì¸ êµì²´
                    if label in ("ì˜í•™ í†µê³„", "ë¯¸í™•ì¸ ì—°êµ¬ ì¸ìš©"):
                        text = re.sub(pat, '', text).strip()
                        if not text:
                            flagged = True

            # 3) ë‚ ì§œ/ì‹œê°„ ì¡°ì‘ íƒì§€
            date_m = re.findall(r'(\d{4})ë…„|(\d{1,2})ì›”\s*(\d{1,2})ì¼', text)
            for dm in date_m:
                date_str = ''.join(dm)
                if date_str and date_str not in source_text:
                    warnings.append(f"ì›ë¬¸ì— ì—†ëŠ” ë‚ ì§œ: '{date_str}'")
                    # ë‚ ì§œ êµ¬ì²´í™” ì œê±°
                    text = re.sub(r'\d{4}ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼', 'ì–¼ë§ˆ ì „', text)
                    text = re.sub(r'\d{4}ë…„', 'ìµœê·¼', text)

            if not flagged:
                line["text"] = text
                cleaned_lines.append(line)

        if warnings:
            print(f"  ğŸ” ì •í™•ì„± ê²€ì¦: {len(warnings)}ê±´ ìˆ˜ì •")
            for w in warnings[:5]:
                print(f"     âš ï¸  {w}")

        # 4) ì›ë¬¸ í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨ í™•ì¸
        source_words = set(re.findall(r'[ê°€-í£]{2,}', source_text))
        script_full = " ".join(l.get("text", "") for l in cleaned_lines)
        script_words = set(re.findall(r'[ê°€-í£]{2,}', script_full))
        # ì›ë¬¸ ìƒìœ„ ë¹ˆì¶œ ë‹¨ì–´ ì¤‘ ìŠ¤í¬ë¦½íŠ¸ì— í¬í•¨ëœ ë¹„ìœ¨
        common_source = [w for w in source_words if len(w) >= 3][:30]
        if common_source:
            overlap = sum(1 for w in common_source if w in script_words)
            coverage = overlap / len(common_source)
            if coverage < 0.15:
                print(f"  âš ï¸  ì›ë¬¸ í‚¤ì›Œë“œ ë°˜ì˜ë¥  ë‚®ìŒ: {coverage:.0%} â€” ëŒ€ë³¸ì´ ì›ë¬¸ê³¼ ë™ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ")

        script_data["script"] = cleaned_lines
        script_data["_accuracy_warnings"] = len(warnings)
        return script_data

    def _fallback_script(self, post: dict) -> dict:
        """í´ë°± ëŒ€ë³¸: ì›ë¬¸ ë‚´ìš©ì„ ìµœëŒ€í•œ í™œìš©í•˜ì—¬ ìµœì†Œ í’ˆì§ˆ ë³´ì¥

        â˜… viral_topic/ë°”ì´ëŸ´ ì†ŒìŠ¤ì¼ ê²½ìš° ì‹œìŠ¤í…œ íŒ¨ë”© í…ìŠ¤íŠ¸ê°€ contentì— ë“¤ì–´ì˜¤ë¯€ë¡œ
           ì œëª©ë§Œìœ¼ë¡œ ê°„ê²°í•œ í›…í‚¹ ëŒ€ë³¸ì„ ìƒì„±í•œë‹¤.
        """
        t = post["title"][:12]
        content = post.get("content", "")
        is_viral = post.get("_is_viral", False)

        script_lines = []

        # í›„í‚¹ (í•­ìƒ ë™ì¼)
        script_lines.append({"text": "ì´ê±° ì‹¤í™”ëƒ?", "emotion": "surprise",
                             "highlight": True, "pause_ms": 300,
                             "image_prompt": "ì¶©ê²©ë°›ì€ í‘œì •ì˜ ì‚¬ëŒ ë’·ëª¨ìŠµ, Bê¸‰ ì›¹íˆ° ìŠ¤íƒ€ì¼"})
        script_lines.append({"text": t, "emotion": "tension",
                             "highlight": True, "pause_ms": 0,
                             "image_prompt": f"{t} ì¥ë©´, ê³¼ì¥ëœ í‘œì •, Bê¸‰ ì›¹íˆ° ìŠ¤íƒ€ì¼"})

        if is_viral:
            # â˜… ë°”ì´ëŸ´ ì†ŒìŠ¤: contentê°€ íŒ¨ë”© í…ìŠ¤íŠ¸ì´ë¯€ë¡œ ì œëª© ê¸°ë°˜ ê°„ê²° ëŒ€ë³¸
            script_lines.append({"text": "ì•„ë‹ˆ ì§„ì§œ ì´ê²Œ ë¨?", "emotion": "shocked",
                                 "highlight": False, "pause_ms": 200,
                                 "image_prompt": "ì–´ì´ì—†ì–´í•˜ëŠ” ì‚¬ëŒ, Bê¸‰ ì›¹íˆ° ìŠ¤íƒ€ì¼"})
            script_lines.append({"text": "ë¯¸ì³¤ë‹¤ ã„¹ã…‡", "emotion": "funny",
                                 "highlight": False, "pause_ms": 200,
                                 "image_prompt": "ì›ƒìœ¼ë©° ê³ ê°œ í”ë“œëŠ” ì‚¬ëŒ, Bê¸‰ ì›¹íˆ° ìŠ¤íƒ€ì¼"})
            script_lines.append({"text": "ë‹˜ë“¤ì´ë©´ ì–´ë–¡í•¨?", "emotion": "neutral",
                                 "highlight": True, "pause_ms": 0,
                                 "image_prompt": "ì¹´ë©”ë¼ë¥¼ ë³´ë©° ì§ˆë¬¸í•˜ëŠ” í‘œì •, Bê¸‰ ì›¹íˆ° ìŠ¤íƒ€ì¼"})
        else:
            # ì›ë¬¸ì—ì„œ í•µì‹¬ ë¬¸ì¥ ì¶”ì¶œ (ë§ˆì¹¨í‘œ/ì¤„ë°”ê¿ˆ ê¸°ì¤€ ë¶„ë¦¬)
            source_sents = [s.strip() for s in re.split(r'[.\n]', content) if len(s.strip()) > 10]

            for sent in source_sents[:8]:
                truncated = sent[:15]
                emotion = "neutral"
                if any(kw in sent for kw in ["ã…‹ã…‹", "ì›ƒ", "ì¬ë°Œ"]):
                    emotion = "funny"
                elif any(kw in sent for kw in ["ì†Œë¦„", "ì¶©ê²©", "ë¯¸ì³¤"]):
                    emotion = "shocked"
                elif any(kw in sent for kw in ["ê°ë™", "ëˆˆë¬¼", "ìš¸"]):
                    emotion = "warm"
                script_lines.append({"text": truncated, "emotion": emotion,
                                     "highlight": False, "pause_ms": 200,
                                     "image_prompt": f"{truncated} ì¥ë©´, Bê¸‰ ì›¹íˆ°"})

            script_lines.append({"text": "ì–´ë–»ê²Œ ìƒê°í•´?", "emotion": "neutral",
                                 "highlight": False, "pause_ms": 0,
                                 "image_prompt": "ì§ˆë¬¸í•˜ëŠ” í‘œì •, Bê¸‰ ì›¹íˆ° ìŠ¤íƒ€ì¼"})

        return {
            "title": t,
            "mood": "funny",
            "script": script_lines,
            "tags": ["#ì°", "#ë ˆì „ë“œ", "#ì‹¤í™”", "#ìˆì¸ ", "#ì»¤ë®¤ë‹ˆí‹°",
                     "#ê³µê°", "#ã…‹ã…‹ã…‹", "#ë°˜ì „", "#ëŒ“ê¸€", "#ì‹¤í™”ë°”íƒ•",
                     "#ì›¹íˆ°", "#Bê¸‰", "#í‚¹ë°›", "#ì‚¬ì´ë‹¤", "#ë¯¸ì¹œ"],
            "thumbnail_text": t[:5],
            "description": f"{t} - ì‹¤í™” ê¸°ë°˜ ì°",
        }


# ============================================================
# ğŸ”Š Stage 3: TTS + ìë§‰ íƒ€ì´ë°
# ============================================================
class TTSEngine:
    """v6.0: ë©€í‹°ì—”ì§„ TTS â€” ElevenLabs â†’ OpenAI â†’ edge-tts í´ë°±

    ê° ë¬¸ì¥ì„ ë…ë¦½ì ìœ¼ë¡œ TTS ìƒì„± â†’ ì •í™•í•œ ê¸¸ì´ ì¸¡ì •.
    ElevenLabs: ê°ì •ë³„ voice_settings + word-level timestamps
    OpenAI: ê°ì •ë³„ speed ì¡°ì ˆ
    edge-tts: ê°ì •ë³„ rate/pitch (ë¬´ë£Œ í´ë°±)
    """

    # edge-tts ì „ìš© ê°ì •ë³„ ì†ë„/í”¼ì¹˜ ë§¤í•‘
    EMOTION_PROSODY = {
        "neutral":  {"rate": "+5%",  "pitch": "-1Hz"},
        "tension":  {"rate": "+12%", "pitch": "+1Hz"},
        "surprise": {"rate": "+0%",  "pitch": "+3Hz"},
        "anger":    {"rate": "+8%",  "pitch": "-3Hz"},
        "angry":    {"rate": "+8%",  "pitch": "-3Hz"},
        "sad":      {"rate": "-5%",  "pitch": "-4Hz"},
        "fun":      {"rate": "+10%", "pitch": "+2Hz"},
        "funny":    {"rate": "+10%", "pitch": "+2Hz"},
        "shock":    {"rate": "-3%",  "pitch": "+0Hz"},
        "shocked":  {"rate": "-3%",  "pitch": "+0Hz"},
        "relief":   {"rate": "+3%",  "pitch": "-2Hz"},
        "excited":  {"rate": "+15%", "pitch": "+4Hz"},
        "warm":     {"rate": "-2%",  "pitch": "-2Hz"},
        "serious":  {"rate": "+0%",  "pitch": "-3Hz"},
        "whisper":  {"rate": "-8%",  "pitch": "-5Hz"},
    }

    def __init__(self, config: Config):
        self.config = config
        self._elevenlabs = None
        self._engine_order = []
        self._init_engines()

    def _init_engines(self):
        """ì—”ì§„ ìš°ì„ ìˆœìœ„ í•´ê²°: ElevenLabs â†’ edge-tts"""
        engine_pref = self.config.tts_engine

        if engine_pref == "auto":
            if self.config.elevenlabs_api_key:
                try:
                    from elevenlabs_tts import ElevenLabsTTS
                    self._elevenlabs = ElevenLabsTTS(
                        self.config.elevenlabs_api_key,
                        self.config.elevenlabs_voice_id,
                    )
                    self._engine_order.append("elevenlabs")
                except ImportError:
                    print("  âš ï¸  elevenlabs_tts ëª¨ë“ˆ ì—†ìŒ â†’ ìŠ¤í‚µ")
            self._engine_order.append("edge")

        elif engine_pref == "elevenlabs":
            from elevenlabs_tts import ElevenLabsTTS
            self._elevenlabs = ElevenLabsTTS(
                self.config.elevenlabs_api_key,
                self.config.elevenlabs_voice_id,
            )
            self._engine_order = ["elevenlabs", "edge"]

        else:  # "edge"
            self._engine_order = ["edge"]

        print(f"  ğŸ”Š TTS ì—”ì§„ ìš°ì„ ìˆœìœ„: {' â†’ '.join(self._engine_order)}")

    async def generate(self, script_data: dict, work_dir: str) -> list[dict]:
        """v6.0: ë©€í‹°ì—”ì§„ TTS ìƒì„± â€” ë¬¸ì¥ë³„ ìµœì  ì—”ì§„ ìë™ ì„ íƒ"""
        print(f"\n{'='*60}")
        print(f"ğŸ”Š Stage 3: TTS ìƒì„± (v6.0 ë©€í‹°ì—”ì§„: {' â†’ '.join(self._engine_order)})")
        print(f"{'='*60}")

        script_lines = script_data.get("script", [])
        chunks = []
        current_ms = 0
        word_timings_all = []  # word-level íƒ€ì´ë° ì „ì²´ ìˆ˜ì§‘

        for idx, line in enumerate(script_lines):
            text = line["text"]
            emotion = line.get("emotion", "neutral")
            prosody = self.EMOTION_PROSODY.get(emotion, self.EMOTION_PROSODY["neutral"])

            # ë¬¸ì¥ ê°„ ê°„ê²© (80ms + pause_ms)
            if idx > 0:
                pause_extra = line.get("pause_ms", 0)
                current_ms += 80 + pause_extra

            audio_path = os.path.join(work_dir, f"sent_{idx:03d}.mp3")

            try:
                # â˜… ë©€í‹°ì—”ì§„ ë””ìŠ¤íŒ¨ì²˜
                result = await self._generate_sentence(
                    text, emotion, prosody, audio_path
                )
                duration_ms = result["duration_ms"]
                word_ts = result.get("word_timings", [])
                engine_used = result.get("engine", "unknown")

            except Exception as e:
                print(f"  âš ï¸  TTS ì „ì²´ ì‹¤íŒ¨ [{idx}] {text}: {e}")
                duration_ms = 1500
                word_ts = []
                engine_used = "silence"
                # ë¬´ìŒ íŒŒì¼ ìƒì„±
                subprocess.run([
                    FFMPEG_PATH, "-y", "-f", "lavfi",
                    "-i", f"anoisesrc=a=0.001:c=pink:r=44100:d=1.5",
                    "-c:a", "libmp3lame", "-b:a", "128k", audio_path,
                ], capture_output=True)

            # word_timingsë¥¼ ì ˆëŒ€ íƒ€ì„ë¼ì¸ìœ¼ë¡œ ì˜¤í”„ì…‹
            for wt in word_ts:
                wt["start_ms"] += current_ms
                wt["end_ms"] += current_ms
            word_timings_all.extend(word_ts)

            start_ms = current_ms
            end_ms = current_ms + duration_ms

            chunks.append({
                "index": idx,
                "text": text,
                "emotion": emotion,
                "highlight": line.get("highlight", False),
                "scene_hint": line.get("scene_hint", ""),
                "important_words": line.get("important_words", []),
                "image_prompt": line.get("image_prompt", ""),
                "audio_file": audio_path,
                "batch_idx": idx,
                "start_ms": start_ms,
                "end_ms": end_ms,
                "duration_ms": duration_ms,
                "pause_ms": line.get("pause_ms", 0),
                "word_timings": word_ts,
                "sfx": re.sub(r'[\[\]]', '', str(line.get("sfx", ""))).strip(),
                "sfx_volume": line.get("sfx_volume", 0.7),
            })

            current_ms = end_ms

            emo = emotion[:3]
            marker = "â­" if line.get("highlight") else "  "
            eng_tag = f"[{engine_used}]" if engine_used != "edge" else ""
            print(
                f"  ğŸ™ï¸ {marker}[{idx+1:02d}] "
                f"{eng_tag}[{emo}|{prosody['rate']}/{prosody['pitch']}] "
                f"{text} ({duration_ms}ms)"
            )

        # word_timings.json ì €ì¥
        if word_timings_all:
            timings_path = os.path.join(work_dir, "word_timings.json")
            with open(timings_path, "w", encoding="utf-8") as f:
                json.dump(word_timings_all, f, ensure_ascii=False, indent=2)
            print(f"  ğŸ“ Word timings ì €ì¥: {len(word_timings_all)}ê°œ ë‹¨ì–´")

        total = current_ms / 1000
        print(f"\n  âœ… TTS ì™„ë£Œ: {len(chunks)}ë¬¸ì¥, {total:.1f}ì´ˆ")
        return chunks

    async def _generate_sentence(
        self, text: str, emotion: str, prosody: dict, audio_path: str
    ) -> dict:
        """v6.0: ì—”ì§„ ìš°ì„ ìˆœìœ„ ë””ìŠ¤íŒ¨ì²˜ â€” ì¸ì¦ ì‹¤íŒ¨ ì—”ì§„ì€ ì„¸ì…˜ ë‚´ ìë™ ë¸”ë™ë¦¬ìŠ¤íŠ¸"""
        if not hasattr(self, "_dead_engines"):
            self._dead_engines = set()  # ì„¸ì…˜ ë‚´ ì¸ì¦ ì‹¤íŒ¨ ì—”ì§„ ê¸°ì–µ

        for engine_name in self._engine_order:
            # â˜… ì´ë¯¸ ì¸ì¦ ì‹¤íŒ¨ë¡œ ì£½ì€ ì—”ì§„ì€ ìŠ¤í‚µ (ë§¤ ë¬¸ì¥ë§ˆë‹¤ ì¬ì‹œë„ ë‚­ë¹„ ë°©ì§€)
            if engine_name in self._dead_engines:
                continue

            try:
                if engine_name == "elevenlabs" and self._elevenlabs:
                    result = await self._elevenlabs.generate_sentence(
                        text, emotion, audio_path
                    )
                    result["engine"] = "elevenlabs"
                    return result

                elif engine_name == "edge":
                    result = await self._generate_edge(text, prosody, audio_path)
                    result["engine"] = "edge"
                    return result

            except Exception as e:
                err_str = str(e)
                # ì¸ì¦ ì‹¤íŒ¨(401) â†’ ì´ ì„¸ì…˜ì—ì„œ í•´ë‹¹ ì—”ì§„ ì˜êµ¬ ë¹„í™œì„±í™”
                if "ì¸ì¦ ì‹¤íŒ¨" in err_str or "401" in err_str:
                    self._dead_engines.add(engine_name)
                    print(f"    âŒ {engine_name} ì¸ì¦ ì‹¤íŒ¨ â†’ ì„¸ì…˜ ë‚´ ë¹„í™œì„±í™”")
                else:
                    print(f"    âš ï¸  {engine_name} ì‹¤íŒ¨: {e}")
                continue

        # ì „ë¶€ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ throw (ìƒìœ„ì—ì„œ ë¬´ìŒ ìƒì„±)
        raise RuntimeError("ëª¨ë“  TTS ì—”ì§„ ì‹¤íŒ¨")

    async def _generate_edge(
        self, text: str, prosody: dict, audio_path: str
    ) -> dict:
        """ê¸°ì¡´ edge-tts ë¡œì§ (í´ë°±ìš© ë³´ì¡´)"""
        communicate = edge_tts.Communicate(
            text=text,
            voice=self.config.tts_voice,
            rate=prosody["rate"],
            pitch=prosody["pitch"],
        )

        with open(audio_path, "wb") as f:
            async for ev in communicate.stream():
                if ev["type"] == "audio":
                    f.write(ev["data"])

        if not os.path.exists(audio_path) or os.path.getsize(audio_path) < 100:
            raise ValueError("edge-tts ë¹ˆ ì˜¤ë””ì˜¤ íŒŒì¼")

        duration_ms = self._get_duration_ms(audio_path)
        return {
            "audio_file": audio_path,
            "duration_ms": duration_ms,
            "word_timings": [],
        }

    def _get_duration_ms(self, path: str) -> int:
        """ì˜¤ë””ì˜¤ íŒŒì¼ ê¸¸ì´ë¥¼ ë°€ë¦¬ì´ˆë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        # 1ì°¨: ffprobe ì‚¬ìš©
        if FFPROBE_PATH:
            try:
                r = subprocess.run(
                    [FFPROBE_PATH, "-v", "quiet", "-show_entries",
                     "format=duration", "-of", "csv=p=0", path],
                    capture_output=True, text=True, encoding="utf-8", errors="replace"
                )
                if r.returncode == 0 and r.stdout.strip():
                    return int(float(r.stdout.strip()) * 1000)
            except (OSError, ValueError) as e:
                print(f"  âš ï¸  ffprobe ì¸¡ì • ì‹¤íŒ¨: {e}")

        # 2ì°¨: ffmpeg -i ë¡œ duration íŒŒì‹± (ffprobe ì—†ì„ ë•Œ)
        try:
            r = subprocess.run(
                [FFMPEG_PATH, "-i", path, "-f", "null", "-"],
                capture_output=True, text=True, encoding="utf-8", errors="replace"
            )
            m = re.search(r"Duration:\s*(\d+):(\d+):(\d+)\.(\d+)", r.stderr)
            if m:
                h, mi, s, cs = int(m.group(1)), int(m.group(2)), int(m.group(3)), int(m.group(4))
                return (h * 3600 + mi * 60 + s) * 1000 + cs * 10
        except (OSError, ValueError) as e:
            print(f"  âš ï¸  ffmpeg ì¸¡ì • ì‹¤íŒ¨: {e}")

        return 2000


# ============================================================
# ğŸ”Š Stage 3.5: SFX íš¨ê³¼ìŒ ì‹œìŠ¤í…œ
# ============================================================
class SFXManager:
    """
    SFX(íš¨ê³¼ìŒ) ê´€ë¦¬ì â€” YouShorts v6.0
    â”€ assets/sfx/mapping.json ê¸°ë°˜ íƒœê·¸â†’íŒŒì¼ ë§¤í•‘
    â”€ chunksì—ì„œ SFX ì´ë²¤íŠ¸ ì¶”ì¶œ â†’ FFmpeg amix ì˜¤ë²„ë ˆì´
    â”€ â˜… SFX ë³¼ë¥¨ í•˜ë“œ ë¦¬ë¯¸í„°: TTS ìŒì„± ëŒ€ë¹„ ìµœëŒ€ 60%
    """

    def __init__(self, base_dir: str = ""):
        """
        Args:
            base_dir: í”„ë¡œì íŠ¸ ë£¨íŠ¸ (assets/sfx/ ê¸°ì¤€ì )
        """
        if not base_dir:
            base_dir = os.path.dirname(os.path.abspath(__file__))
        self.sfx_dir = os.path.join(base_dir, "assets", "sfx")
        self.mapping = self._load_mapping()

    def _load_mapping(self) -> dict:
        """mapping.json ë¡œë“œ â†’ {tag: {file, volume, category}}"""
        mapping_path = os.path.join(self.sfx_dir, "mapping.json")
        if not os.path.exists(mapping_path):
            print(f"  âš ï¸  SFX mapping.json ì—†ìŒ: {mapping_path}")
            return {}
        try:
            with open(mapping_path, "r", encoding="utf-8") as f:
                import json as _json
                data = _json.load(f)
            # íŒŒì¼ ì¡´ì¬ í™•ì¸
            valid = {}
            for tag, info in data.items():
                full_path = os.path.join(self.sfx_dir, info["file"])
                if os.path.exists(full_path):
                    info["_full_path"] = full_path
                    valid[tag] = info
                else:
                    print(f"  âš ï¸  SFX íŒŒì¼ ì—†ìŒ (ìŠ¤í‚µ): {full_path}")
            print(f"  ğŸ”Š SFX ë¡œë“œ: {len(valid)}/{len(data)}ê°œ íƒœê·¸ ì‚¬ìš© ê°€ëŠ¥")
            return valid
        except Exception as e:
            print(f"  âš ï¸  SFX mapping.json ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}

    def get_sfx_path(self, tag: str) -> str:
        """íƒœê·¸ â†’ SFX íŒŒì¼ ê²½ë¡œ ë°˜í™˜ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)"""
        info = self.mapping.get(tag, {})
        return info.get("_full_path", "")

    def get_default_volume(self, tag: str) -> float:
        """íƒœê·¸ â†’ ê¸°ë³¸ ë³¼ë¥¨ ë°˜í™˜ (mapping.jsonì— ì •ì˜ëœ ê°’)"""
        info = self.mapping.get(tag, {})
        return info.get("volume", 0.5)

    def collect_sfx_from_chunks(self, chunks: list[dict]) -> list[dict]:
        """chunksì—ì„œ SFX ì´ë²¤íŠ¸ ì¶”ì¶œ

        Returns:
            [{
                "start_ms": int,       # í•´ë‹¹ ë¬¸ì¥ ì‹œì‘ ì‹œì 
                "sfx_path": str,       # SFX íŒŒì¼ ê²½ë¡œ
                "volume": float,       # ìµœì¢… ë³¼ë¥¨ (0.0~0.6 í•˜ë“œ ë¦¬ë°‹)
                "tag": str,            # ì›ë³¸ íƒœê·¸
            }]
        """
        events = []
        for chunk in chunks:
            tag = chunk.get("sfx", "").strip()
            if not tag:
                continue

            # â˜… [bracket] í¬ë§· ì•ˆì „ ì²˜ë¦¬: "[thunder]" â†’ "thunder"
            tag = re.sub(r'[\[\]]', '', tag).strip()
            if not tag:
                continue

            sfx_path = self.get_sfx_path(tag)
            if not sfx_path:
                print(f"    âš ï¸  SFX íƒœê·¸ '{tag}' ë§¤í•‘ ì—†ìŒ (ìŠ¤í‚µ)")
                continue

            # ë³¼ë¥¨ ê²°ì •: chunkì— ì§€ì •ëœ ê°’ > mapping ê¸°ë³¸ê°’
            raw_volume = chunk.get("sfx_volume", self.get_default_volume(tag))

            # â˜…â˜…â˜… í•˜ë“œ ë¦¬ë¯¸í„°: SFX ë³¼ë¥¨ì€ TTS ëŒ€ë¹„ ìµœëŒ€ 60% â˜…â˜…â˜…
            # TTS voice weight = 1.0 ê¸°ì¤€, SFXëŠ” 0.6 ì´í•˜ë¡œ ê°•ì œ
            clamped_volume = min(float(raw_volume), 0.6)
            clamped_volume = max(clamped_volume, 0.05)  # ìµœì†Œê°’

            events.append({
                "start_ms": chunk.get("start_ms", 0),
                "sfx_path": sfx_path,
                "volume": clamped_volume,
                "tag": tag,
            })

        if events:
            print(f"  ğŸ”Š SFX ì´ë²¤íŠ¸ {len(events)}ê°œ ì¶”ì¶œ "
                  f"(ë³¼ë¥¨ ë¦¬ë°‹: ìµœëŒ€ 60%)")

        return events

    def mix_sfx_into_audio(
        self,
        voice_path: str,
        sfx_events: list[dict],
        output_path: str,
    ) -> bool:
        """SFX ì´ë²¤íŠ¸ë¥¼ voice ì˜¤ë””ì˜¤ì— ì˜¤ë²„ë ˆì´ (FFmpeg)

        â˜… í•µì‹¬ ì›ì¹™:
        - TTS voice = weight 1.0 (ê¸°ì¤€)
        - ê° SFX = weight â‰¤ 0.6 (í•˜ë“œ ë¦¬ë°‹)
        - FFmpeg amixë¡œ ë‹¤ì¤‘ SFX ë™ì‹œ ë¯¹ì‹±

        Args:
            voice_path: ë§ˆìŠ¤í„°ë§ëœ voice ì˜¤ë””ì˜¤ (BGM ë•í‚¹ í›„)
            sfx_events: collect_sfx_from_chunks() ê²°ê³¼
            output_path: ìµœì¢… ì¶œë ¥ ê²½ë¡œ

        Returns:
            True if success
        """
        if not sfx_events:
            return False

        if not os.path.exists(voice_path):
            print(f"  âš ï¸  SFX ë¯¹ì‹±: voice íŒŒì¼ ì—†ìŒ")
            return False

        # SFX 5ê°œ ì œí•œ (FFmpeg í•„í„° ë³µì¡ë„ ê´€ë¦¬)
        if len(sfx_events) > 5:
            print(f"  âš ï¸  SFX {len(sfx_events)}ê°œ â†’ 5ê°œë¡œ ì œí•œ")
            sfx_events = sfx_events[:5]

        try:
            # â”€â”€ FFmpeg filter_complex ë¹Œë“œ â”€â”€
            # [0:a] = voice (ê¸°ì¤€)
            # [1:a], [2:a], ... = SFX íŒŒì¼ë“¤
            #
            # ê° SFXì— adelay + volume ì ìš© í›„ amixë¡œ í•©ì¹¨
            inputs = ["-i", os.path.abspath(voice_path)]
            filter_parts = []
            mix_inputs = ["[0:a]"]  # voiceëŠ” í•­ìƒ ì²« ë²ˆì§¸
            weights = ["1"]  # voice weight = 1.0

            for i, evt in enumerate(sfx_events):
                sfx_idx = i + 1  # FFmpeg ì…ë ¥ ì¸ë±ìŠ¤ (0=voice)
                inputs.extend(["-i", os.path.abspath(evt["sfx_path"])])

                delay_ms = max(0, evt["start_ms"])
                vol = evt["volume"]  # ì´ë¯¸ 0.6 ì´í•˜ë¡œ í´ë¨í•‘ë¨

                # adelayë¡œ ì‹œì‘ ìœ„ì¹˜ ì¡°ì ˆ + volume ì¡°ì ˆ
                filter_parts.append(
                    f"[{sfx_idx}:a]adelay={delay_ms}|{delay_ms},"
                    f"volume={vol:.2f}[sfx{i}]"
                )
                mix_inputs.append(f"[sfx{i}]")
                weights.append("1")  # ê°œë³„ volume ì´ë¯¸ ì ìš©ë¨

            # amixë¡œ ìµœì¢… ë¯¹ì‹±
            n_inputs = len(mix_inputs)
            weight_str = " ".join(weights)
            mix_label = "".join(mix_inputs)
            filter_parts.append(
                f"{mix_label}amix=inputs={n_inputs}:duration=first"
                f":weights={weight_str}:normalize=0"
            )

            filter_complex = ";".join(filter_parts)

            cmd = [
                FFMPEG_PATH, "-y",
                *inputs,
                "-filter_complex", filter_complex,
                "-c:a", "libmp3lame", "-b:a", "192k", "-ar", "44100",
                os.path.abspath(output_path),
            ]

            r = subprocess.run(
                cmd, capture_output=True, text=True,
                encoding="utf-8", errors="replace", timeout=30,
            )

            if r.returncode == 0 and os.path.exists(output_path):
                size = os.path.getsize(output_path)
                if size > 1000:
                    print(f"  âœ… SFX ì˜¤ë²„ë ˆì´ ì™„ë£Œ ({len(sfx_events)}ê°œ, "
                          f"ë³¼ë¥¨ â‰¤60%)")
                    return True

            print(f"  âš ï¸  SFX ë¯¹ì‹± FFmpeg ì‹¤íŒ¨: {r.stderr[:200] if r.stderr else 'unknown'}")
            return False

        except subprocess.TimeoutExpired:
            print(f"  âš ï¸  SFX ë¯¹ì‹± íƒ€ì„ì•„ì›ƒ (30ì´ˆ)")
            return False
        except Exception as e:
            print(f"  âš ï¸  SFX ë¯¹ì‹± ì˜¤ë¥˜: {e}")
            return False

    @property
    def available_tags(self) -> list[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ SFX íƒœê·¸ ëª©ë¡"""
        return list(self.mapping.keys())


# ============================================================
# ğŸ¬ Stage 4: ì˜ìƒ ì¡°ë¦½ (ìŠ¤í¬ë¦°ìƒ· ë°°ê²½ + ìì—°ìŠ¤ëŸ¬ìš´ ìë§‰)
# ============================================================
class VideoAssembler:
    """
    v3 í•µì‹¬ ë³€ê²½:
    - ë°°ê²½: ë‹¨ìƒ‰ â†’ ì»¤ë®¤ë‹ˆí‹° ê¸€ ìŠ¤í¬ë¦°ìƒ· (ë¸”ëŸ¬+ì–´ë‘¡ê²Œ)
    - ìë§‰: ASS â†’ Pillowë¡œ í”„ë ˆì„ë³„ ë Œë”ë§ (í°íŠ¸ ììœ ë„ â†‘)
    - ì¥ë©´ ì „í™˜: ìŠ¤í¬ë¦°ìƒ· ê°„ ë¶€ë“œëŸ¬ìš´ ì „í™˜
    """

    def __init__(self, config: Config):
        self.config = config
        self.w = config.width
        self.h = config.height
        self.font = FontManager.get_font(config.font_size)
        self.font_bold = FontManager.get_font(config.font_size_highlight, bold=True)

    def assemble(self, script_data: dict, chunks: list[dict],
                 screenshots: list[str], work_dir: str,
                 scene_videos: list[dict] = None,
                 ai_images: list[dict] = None) -> str:
        """
        v7.0: ì›¹íˆ°í˜• ì‡¼ì¸  â€” AI ì´ë¯¸ì§€ + Ken Burns + ë§í’ì„  ìë§‰
        (ai_images ì—†ìœ¼ë©´ v6.2 Satisfying Video í´ë°±)
        """
        scene_videos = scene_videos or []
        ai_images = ai_images or []

        # ì›¹íˆ° ëª¨ë“œ vs ë¹„ë””ì˜¤ ëª¨ë“œ ë¶„ê¸°
        has_images = any(img.get("image_path") for img in ai_images)
        if has_images:
            return self._assemble_webtoon(script_data, chunks, ai_images, work_dir)

        print(f"\n{'='*60}")
        print(f"ğŸ¬ Stage 4: ì˜ìƒ ì¡°ë¦½ (v6.2 Satisfying Video ëª¨ë“œ)")
        print(f"{'='*60}")

        # chunk_idx ìë™ ì‚½ì… (ìë§‰ ìƒ‰ìƒ ë²ˆê°ˆì•„ í‘œì‹œìš©)
        for ci, chunk in enumerate(chunks):
            chunk["chunk_idx"] = ci

        # Step 1: ì˜¤ë””ì˜¤ í•©ì¹˜ê¸°
        concat_audio = os.path.join(work_dir, "full_audio.mp3")
        self._concat_audio(chunks, concat_audio, work_dir)

        total_ms = max(c["end_ms"] for c in chunks) + 500
        total_sec = total_ms / 1000

        # Step 2: FFmpeg ì§ì ‘ ì¡°ë¦½ (í”„ë ˆì„ ë Œë”ë§ ì œê±° â†’ ì†ë„ ëŒ€í­ í–¥ìƒ)
        # ë°°ê²½ ë¹„ë””ì˜¤ ê²½ë¡œ ì°¾ê¸°
        bg_video = None
        for sv in scene_videos:
            vp = sv.get("video_path", "")
            if vp and os.path.exists(vp):
                bg_video = vp
                break

        if not bg_video:
            # í´ë°±: ê²€ì • ë°°ê²½ ìƒì„±
            print("  âš ï¸  Satisfying ë°°ê²½ ì—†ìŒ â†’ ê²€ì • ë°°ê²½ í´ë°±")
            bg_video = os.path.join(work_dir, "black_bg.mp4")
            cmd_bg = [
                FFMPEG_PATH, "-y",
                "-f", "lavfi", "-i",
                f"color=c=black:s={self.w}x{self.h}:r={self.config.fps}:d={total_sec + 1}",
                "-c:v", "libx264", "-preset", "ultrafast", "-crf", "23",
                "-pix_fmt", "yuv420p",
                os.path.abspath(bg_video),
            ]
            subprocess.run(cmd_bg, capture_output=True, text=True,
                           encoding="utf-8", errors="replace", timeout=60)

        # Step 3: ë°°ê²½ ë£¨í”„ + Mute + Dimming â†’ ì¤‘ê°„ íŒŒì¼
        print(f"  ğŸ”„ ë°°ê²½ ë¹„ë””ì˜¤ ë£¨í”„ + Dimming ì²˜ë¦¬ ì¤‘...")
        looped_bg = os.path.join(work_dir, "looped_bg.mp4")

        # FFmpeg: stream_loopìœ¼ë¡œ ë£¨í”„ + eq=brightnessë¡œ ì–´ë‘¡ê²Œ + ì•½í•œ blur
        cmd_loop = [
            FFMPEG_PATH, "-y",
            "-stream_loop", "-1",  # ë¬´í•œ ë£¨í”„
            "-i", os.path.abspath(bg_video),
            "-t", f"{total_sec + 0.5}",  # ì „ì²´ ê¸¸ì´
            "-vf", (
                f"scale={self.w}:{self.h}:force_original_aspect_ratio=increase,"
                f"crop={self.w}:{self.h},"
                f"eq=brightness=-0.12:contrast=1.1,"
                f"gblur=sigma=1.5"
            ),
            "-an",  # ì˜¤ë””ì˜¤ Mute
            "-c:v", "libx264",
            "-preset", "fast",
            "-crf", "18",
            "-pix_fmt", "yuv420p",
            "-r", str(self.config.fps),
            os.path.abspath(looped_bg),
        ]

        result = subprocess.run(cmd_loop, capture_output=True, text=True,
                                encoding="utf-8", errors="replace", timeout=180)
        if result.returncode != 0:
            print(f"  âš ï¸  ë°°ê²½ ë£¨í”„ ì‹¤íŒ¨: {result.stderr[-300:] if result.stderr else ''}")
            # í´ë°±: ê²€ì • ë°°ê²½
            cmd_bg = [
                FFMPEG_PATH, "-y",
                "-f", "lavfi", "-i",
                f"color=c=black:s={self.w}x{self.h}:r={self.config.fps}:d={total_sec + 1}",
                "-c:v", "libx264", "-preset", "ultrafast", "-crf", "23",
                "-pix_fmt", "yuv420p",
                os.path.abspath(looped_bg),
            ]
            subprocess.run(cmd_bg, capture_output=True, text=True,
                           encoding="utf-8", errors="replace", timeout=60)

        print(f"  âœ… ë°°ê²½ ë£¨í”„ ì™„ë£Œ!")

        # Step 4: ASS ìë§‰ íŒŒì¼ ìƒì„± (FFmpeg drawtext ëŒ€ì‹  Pillow í”„ë ˆì„ ë Œë”ë§)
        # â†’ Pillow ë Œë”ë§ì´ í°íŠ¸ ì œì–´ì— ë” ìœ ë¦¬
        frames_dir = os.path.join(work_dir, "frames")
        os.makedirs(frames_dir, exist_ok=True)

        # ë°°ê²½ ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ
        print(f"  ğŸï¸  ë°°ê²½ í”„ë ˆì„ ì¶”ì¶œ ì¤‘...")
        bg_frames_dir = os.path.join(work_dir, "_bg_frames")
        os.makedirs(bg_frames_dir, exist_ok=True)

        bg_pattern = os.path.join(bg_frames_dir, "bg_%06d.jpg")
        cmd_extract = [
            FFMPEG_PATH, "-y",
            "-i", os.path.abspath(looped_bg),
            "-q:v", "2",
            os.path.abspath(bg_pattern),
        ]
        subprocess.run(cmd_extract, capture_output=True, text=True,
                        encoding="utf-8", errors="replace", timeout=300)

        # ì¶”ì¶œëœ ë°°ê²½ í”„ë ˆì„ ë¡œë“œ
        bg_frame_files = sorted([f for f in os.listdir(bg_frames_dir) if f.endswith(".jpg")])
        total_frames = len(bg_frame_files)
        if total_frames == 0:
            total_frames = int(total_sec * self.config.fps)

        print(f"  ğŸ–¼ï¸  {total_frames}í”„ë ˆì„ ìë§‰ ë Œë”ë§ ì¤‘ (Satisfying ìŠ¤íƒ€ì¼)...")

        # v6.0 ì „ìš© í°íŠ¸ ë¡œë“œ
        shorts_font = FontManager.get_shorts_font(int(self.config.font_size * 1.3))
        shorts_font_large = FontManager.get_shorts_font(int(self.config.font_size * 1.5))

        # v9.0: ë°°ê²½ í”„ë ˆì„ ìºì‹œ (ê°™ì€ ì´ë¯¸ì§€ ì¬ë¡œë“œ ë°©ì§€)
        _bg_cache = {}

        def _load_bg_frame(idx):
            if idx < len(bg_frame_files):
                bg_path = os.path.join(bg_frames_dir, bg_frame_files[idx])
                if bg_path not in _bg_cache:
                    try:
                        img = Image.open(bg_path).convert("RGB")
                        if img.size != (self.w, self.h):
                            img = img.resize((self.w, self.h), Image.LANCZOS)
                        _bg_cache[bg_path] = img
                    except Exception:
                        _bg_cache[bg_path] = None
                cached = _bg_cache.get(bg_path)
                return cached.copy() if cached else self._create_cinematic_gradient("neutral")
            return self._create_cinematic_gradient("neutral")

        # ë°°ê²½ ìºì‹œ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ì ˆì•½ â€” ìµœê·¼ 60í”„ë ˆì„ë§Œ)
        cache_limit = self.config.fps * 2

        for frame_idx in range(total_frames):
            current_time_ms = (frame_idx / self.config.fps) * 1000

            # ë°°ê²½ í”„ë ˆì„ ë¡œë“œ (ìºì‹œ í™œìš©)
            frame = _load_bg_frame(frame_idx)

            # ìºì‹œ í¬ê¸° ì œí•œ
            if len(_bg_cache) > cache_limit:
                oldest_key = next(iter(_bg_cache))
                del _bg_cache[oldest_key]

            # í˜„ì¬ ëŒ€ì‚¬ ì°¾ê¸°
            active_chunk = None
            for ci, chunk in enumerate(chunks):
                if chunk["start_ms"] <= current_time_ms <= chunk["end_ms"]:
                    active_chunk = chunk
                    break

            # v9.0 í˜„ëŒ€ì  ìë§‰ ë Œë”ë§
            if active_chunk:
                frame = self._render_subtitle(frame, active_chunk, current_time_ms)

            # ì•„ì›ƒíŠ¸ë¡œ: ë§ˆì§€ë§‰ 2ì´ˆ
            remaining_sec = (total_ms - current_time_ms) / 1000
            if 0 <= remaining_sec <= 2.0:
                frame = self._render_cta_outro(frame, remaining_sec)

            # ì €ì¥ (JPEG quality 85 â†’ íŒŒì¼ í¬ê¸° 20% ê°ì†Œ, ì‹œê° ì°¨ì´ ë¬´)
            frame_path = os.path.join(frames_dir, f"frame_{frame_idx:06d}.jpg")
            frame.save(frame_path, quality=85)

            # ì§„í–‰ë¥  (10ì´ˆë§ˆë‹¤)
            if frame_idx % (self.config.fps * 10) == 0:
                pct = (frame_idx / max(1, total_frames)) * 100
                print(f"  ğŸ“Š ë Œë”ë§ ì§„í–‰: {pct:.0f}% ({frame_idx}/{total_frames})")

        print(f"  âœ… í”„ë ˆì„ ë Œë”ë§ ì™„ë£Œ!")

        # Step 5: FFmpeg ìµœì¢… ì¸ì½”ë”©
        title_safe = re.sub(r'[^\wê°€-í£]', '_',
                            script_data.get("title", "shorts"))[:20]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = f"shorts_{title_safe}_{timestamp}.mp4"
        output_path = os.path.join(self.config.output_dir, output_filename)

        abs_frames_pattern = os.path.abspath(
            os.path.join(frames_dir, "frame_%06d.jpg")
        )
        abs_audio = os.path.abspath(concat_audio)
        abs_output = os.path.abspath(output_path)

        print(f"  ğŸ”§ FFmpeg CRF ì¸ì½”ë”© ì¤‘...")

        cmd = [
            FFMPEG_PATH, "-y",
            "-framerate", str(self.config.fps),
            "-i", abs_frames_pattern,
            "-i", abs_audio,
            "-c:v", "libx264",
            "-preset", "medium",
            "-crf", "20",
            "-profile:v", "high",
            "-level", "4.1",
            "-maxrate", "8000k",
            "-bufsize", "8000k",
            "-c:a", "aac",
            "-b:a", "256k",
            "-ar", "44100",
            "-pix_fmt", "yuv420p",
            "-shortest",
            "-movflags", "+faststart",
            "-metadata", f"title={script_data.get('title', 'Shorts')}",
            abs_output,
        ]

        result = subprocess.run(cmd, capture_output=True, text=True,
                                encoding="utf-8", errors="replace")

        if result.returncode != 0:
            print(f"  âš ï¸  FFmpeg ì—ëŸ¬: {result.stderr[-500:] if result.stderr else 'unknown'}")
            print(f"  ğŸ”„ ê°„ì†Œí™” ë²„ì „ìœ¼ë¡œ ì¬ì‹œë„...")
            return self._assemble_simple_fallback(
                concat_audio, total_sec, chunks, output_path, work_dir
            )

        size_mb = os.path.getsize(output_path) / (1024 * 1024)
        print(f"  âœ… ì˜ìƒ ì™„ì„±! {output_path} ({size_mb:.1f}MB)")

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        shutil.rmtree(frames_dir, ignore_errors=True)
        shutil.rmtree(bg_frames_dir, ignore_errors=True)
        if os.path.exists(looped_bg):
            os.remove(looped_bg)

        return output_path

    def _create_cinematic_gradient(self, emotion: str = "neutral") -> Image.Image:
        """v9.0: ê°ì •ë³„ 3ìƒ‰ ë©”ì‹œ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ (ë¹„ë””ì˜¤ ì—†ì„ ë•Œ í´ë°±)

        ê¸°ì¡´ 2ìƒ‰ ë‹¨ìˆœ ê·¸ë¼ë°ì´ì…˜ â†’ 3ìƒ‰ ë©”ì‹œë¡œ ì„¸ë ¨ëœ ëŠë‚Œ.
        ìƒë‹¨(c1) â†’ ì¤‘ê°„(c2) â†’ í•˜ë‹¨(c3) ìì—°ìŠ¤ëŸ¬ìš´ ì „í™˜.
        """
        # 3ìƒ‰ ë©”ì‹œ ê·¸ë¼ë°ì´ì…˜ (ìƒë‹¨, ì¤‘ê°„, í•˜ë‹¨)
        EMOTION_COLORS_3 = {
            "neutral":  [(15, 15, 30), (20, 18, 35), (28, 22, 38)],
            "shocked":  [(45, 8, 15), (30, 10, 25), (15, 12, 35)],
            "excited":  [(50, 30, 5),  (40, 20, 25), (20, 15, 40)],
            "tension":  [(8, 10, 35),  (20, 8, 25),  (35, 10, 15)],
            "warm":     [(40, 25, 10), (30, 18, 20), (18, 15, 30)],
            "sad":      [(10, 15, 35), (12, 12, 30), (18, 10, 25)],
            "funny":    [(35, 30, 8),  (25, 22, 20), (15, 18, 35)],
            "serious":  [(10, 10, 18), (15, 12, 22), (22, 18, 28)],
            "angry":    [(50, 5, 5),   (35, 8, 18),  (15, 10, 30)],
            "whisper":  [(12, 12, 22), (10, 15, 28), (8, 10, 20)],
            "surprise": [(40, 15, 10), (25, 12, 28), (12, 15, 38)],
            "relief":   [(15, 25, 20), (18, 20, 28), (22, 18, 35)],
        }
        colors = EMOTION_COLORS_3.get(emotion, EMOTION_COLORS_3["neutral"])
        c1, c2, c3 = colors

        img = Image.new("RGB", (self.w, self.h))
        draw = ImageDraw.Draw(img)
        mid_point = self.h * 0.45  # ìƒë‹¨~ì¤‘ê°„ ì „í™˜ì 

        for y in range(self.h):
            if y < mid_point:
                # ìƒë‹¨ â†’ ì¤‘ê°„
                ratio = y / mid_point
                r = int(c1[0] * (1 - ratio) + c2[0] * ratio)
                g = int(c1[1] * (1 - ratio) + c2[1] * ratio)
                b = int(c1[2] * (1 - ratio) + c2[2] * ratio)
            else:
                # ì¤‘ê°„ â†’ í•˜ë‹¨
                ratio = (y - mid_point) / (self.h - mid_point)
                r = int(c2[0] * (1 - ratio) + c3[0] * ratio)
                g = int(c2[1] * (1 - ratio) + c3[1] * ratio)
                b = int(c2[2] * (1 - ratio) + c3[2] * ratio)
            draw.line([(0, y), (self.w, y)], fill=(r, g, b))
        return img

    def _generate_ai_image(self, scene_hint: str, work_dir: str,
                            idx: int, context_text: str = "") -> Optional[str]:
        """
        v5.0: Pillow ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ (Imagen ì œê±° â€” API ë¹„ìš© 0ì›)
        scene_hintì— ë”°ë¼ ë¶„ìœ„ê¸°ë³„ ìƒ‰ìƒ ê·¸ë¼ë°ì´ì…˜ ìƒì„±
        """
        try:
            w, h = self.config.width, self.config.height

            # scene_hint í‚¤ì›Œë“œë¡œ ìƒ‰ìƒ ë§¤í•‘
            hint_lower = scene_hint.lower() if scene_hint else ""
            if any(k in hint_lower for k in ("ê³µí¬", "horror", "dark", "ì†Œë¦„", "ë¯¸ìŠ¤í„°ë¦¬")):
                c1, c2 = (15, 5, 25), (40, 10, 10)
            elif any(k in hint_lower for k in ("ì¶©ê²©", "shock", "surprise", "ë°˜ì „")):
                c1, c2 = (20, 10, 5), (60, 20, 10)
            elif any(k in hint_lower for k in ("ì›ƒ", "funny", "comedy", "ã…‹ã…‹", "ë°ˆ")):
                c1, c2 = (10, 20, 30), (30, 50, 20)
            elif any(k in hint_lower for k in ("ìŠ¬", "sad", "ê°ë™", "ëˆˆë¬¼")):
                c1, c2 = (10, 15, 35), (20, 20, 50)
            else:
                c1, c2 = (20, 22, 30), (35, 25, 20)

            img = Image.new("RGB", (w, h))
            for y in range(h):
                ratio = y / h
                r = int(c1[0] + (c2[0] - c1[0]) * ratio)
                g = int(c1[1] + (c2[1] - c1[1]) * ratio)
                b = int(c1[2] + (c2[2] - c1[2]) * ratio)
                for x in range(w):
                    img.putpixel((x, y), (r, g, b))

            path = os.path.join(work_dir, f"ai_bg_{idx:03d}.png")
            img.save(path, quality=85)
            print(f"    ğŸ¨ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ ìƒì„±: {scene_hint[:40]}...")
            return path
        except Exception as e:
            print(f"    âš ï¸  ë°°ê²½ ìƒì„± ì‹¤íŒ¨: {e}")
        return None

    def _prepare_backgrounds(self, screenshots: list[str],
                              total_frames: int,
                              script_data: dict = None,
                              work_dir: str = "") -> list[Image.Image]:
        """
        v4.1: 3ë‹¨ ë¹„ì£¼ì–¼ ë ˆì´ì•„ì›ƒ
        â”€ ë°°ê²½(í•˜ë‹¨): ìŠ¤í¬ë¦°ìƒ· 1.5ë°° í™•ëŒ€ + GaussianBlur(20px) â†’ ê¹Šì´ê°ë§Œ
        â”€ ì¤‘ì•™(ë©”ì¸): ìŠ¤í¬ë¦°ìƒ· ì„ ëª… ì›ë³¸ (ë¸”ëŸ¬ ì—†ìŒ) + ì™¸ê³½ì„  + ê·¸ë¦¼ì â†’ ë¦¬ì–¼ë¦¬í‹°
        â”€ ìƒë‹¨: íƒ€ì´í‹€ë°”ëŠ” í”„ë ˆì„ ë£¨í”„ì—ì„œ _render_title_bar()ê°€ ì²˜ë¦¬
        â”€ AI ë°°ê²½ì€ scene_hint ë§¥ë½ ì •ë°€ í”„ë¡¬í”„íŠ¸ë¡œ ìƒì„±
        """
        print(f"  ğŸ–¼ï¸  ë°°ê²½ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ (3ë‹¨ ë ˆì´ì•„ì›ƒ)...")
        backgrounds = []

        # â”€â”€ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ (highlight ì¥ë©´, ìµœëŒ€ 3ì¥) â”€â”€
        ai_images = {}
        if script_data and self.config.use_ai_bg and work_dir:
            lines = script_data.get("script", [])
            ai_targets = []
            for i, line in enumerate(lines):
                if line.get("highlight") or line.get("emotion") in ("shock", "surprise"):
                    hint = line.get("scene_hint", "dramatic cinematic atmosphere")
                    ctx = line.get("text", "")
                    ai_targets.append((i, hint, ctx))
            ai_targets = ai_targets[:3]

            for target_idx, hint, ctx in ai_targets:
                ai_path = self._generate_ai_image(hint, work_dir, target_idx, ctx)
                if ai_path:
                    try:
                        ai_img = Image.open(ai_path).convert("RGB")
                        ai_img = self._fit_to_vertical(ai_img)
                        enhancer = ImageEnhance.Brightness(ai_img)
                        ai_img = enhancer.enhance(0.55)
                        ai_images[target_idx] = ai_img
                    except Exception as e:
                        print(f"    âš ï¸  AI ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

        # â”€â”€ 3ë‹¨ ë ˆì´ì•„ì›ƒ í•©ì„± â”€â”€
        if not screenshots:
            bg = self._create_gradient_bg(0)
            backgrounds.append(bg)
        else:
            for ss_path in screenshots:
                try:
                    orig = Image.open(ss_path).convert("RGB")
                    fitted = self._fit_to_vertical(orig)

                    # â–¼ ë°°ê²½ ë ˆì´ì–´: 1.5ë°° í™•ëŒ€ + GaussianBlur(20px) + ì–´ë‘¡ê²Œ
                    bg_w, bg_h = int(self.w * 1.5), int(self.h * 1.5)
                    bg_layer = fitted.resize((bg_w, bg_h), Image.LANCZOS)
                    left = (bg_w - self.w) // 2
                    top = (bg_h - self.h) // 2
                    bg_layer = bg_layer.crop((left, top, left + self.w, top + self.h))
                    bg_layer = bg_layer.filter(ImageFilter.GaussianBlur(radius=20))
                    enhancer = ImageEnhance.Brightness(bg_layer)
                    bg_layer = enhancer.enhance(0.30)

                    # â–¼ ì „ê²½ ë ˆì´ì–´: ì„ ëª…í•œ ì›ë³¸ (ë¸”ëŸ¬ ì—†ìŒ) + ì™¸ê³½ì„  + ê·¸ë¦¼ì
                    # ìƒë‹¨ íƒ€ì´í‹€ë°”(~60px) ì•„ë˜, ìë§‰ ì˜ì—­(h*0.60~) ìœ„ì— ë°°ì¹˜
                    fg_w = int(self.w * 0.88)
                    fg_h = int(fitted.height * (fg_w / fitted.width))
                    max_fg_h = int(self.h * 0.50)
                    if fg_h > max_fg_h:
                        fg_h = max_fg_h
                        fg_w = int(fitted.width * (fg_h / fitted.height))
                    fg = fitted.resize((fg_w, fg_h), Image.LANCZOS)

                    fg_x = (self.w - fg_w) // 2
                    fg_y = int(self.h * 0.08)  # íƒ€ì´í‹€ë°” ë°”ë¡œ ì•„ë˜

                    # ê·¸ë¦¼ì (8px offset + blur 15px)
                    shadow = Image.new("RGBA", (self.w, self.h), (0, 0, 0, 0))
                    shadow_draw = ImageDraw.Draw(shadow)
                    shadow_draw.rectangle(
                        [(fg_x + 6, fg_y + 6), (fg_x + fg_w + 6, fg_y + fg_h + 6)],
                        fill=(0, 0, 0, 140)
                    )
                    shadow = shadow.filter(ImageFilter.GaussianBlur(radius=15))

                    # í•©ì„±
                    composite = bg_layer.convert("RGBA")
                    composite = Image.alpha_composite(composite, shadow)

                    # í°ìƒ‰ ì™¸ê³½ì„  (4px)
                    border = 4
                    fg_draw = ImageDraw.Draw(composite)
                    fg_draw.rectangle(
                        [(fg_x - border, fg_y - border),
                         (fg_x + fg_w + border, fg_y + fg_h + border)],
                        fill=(255, 255, 255, 230)
                    )
                    # ì„ ëª…í•œ ì›ë³¸ ë¶™ì´ê¸° (ë¸”ëŸ¬ ì—†ìŒ)
                    composite.paste(fg, (fg_x, fg_y))

                    backgrounds.append(composite.convert("RGB"))
                except Exception as e:
                    print(f"    âš ï¸  ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    backgrounds.append(self._create_gradient_bg(len(backgrounds)))

        if not backgrounds:
            backgrounds = [self._create_gradient_bg(0)]

        # AI ì´ë¯¸ì§€ë¥¼ ë°°ê²½ ë¦¬ìŠ¤íŠ¸ì— ì‚½ì…
        if ai_images:
            total_bg = len(backgrounds)
            script_len = len(script_data.get("script", [])) if script_data else 1
            for line_idx, ai_bg in ai_images.items():
                bg_pos = min(int(line_idx / script_len * total_bg), total_bg - 1)
                if bg_pos < len(backgrounds):
                    backgrounds.insert(bg_pos + 1, ai_bg)
            print(f"    ğŸ¨ AI ë°°ê²½ {len(ai_images)}ì¥ ì‚½ì… ì™„ë£Œ")

        return backgrounds

    def _fit_to_vertical(self, img: Image.Image) -> Image.Image:
        """ì´ë¯¸ì§€ë¥¼ 1080x1920ì— ë§ê²Œ í¬ë¡­+ë¦¬ì‚¬ì´ì¦ˆ"""
        target_ratio = self.w / self.h  # 0.5625
        img_ratio = img.width / img.height

        if img_ratio > target_ratio:
            # ì´ë¯¸ì§€ê°€ ë” ë„“ìŒ â†’ ì¢Œìš° í¬ë¡­
            new_w = int(img.height * target_ratio)
            left = (img.width - new_w) // 2
            img = img.crop((left, 0, left + new_w, img.height))
        else:
            # ì´ë¯¸ì§€ê°€ ë” ë†’ìŒ â†’ ìƒí•˜ í¬ë¡­
            new_h = int(img.width / target_ratio)
            top = (img.height - new_h) // 2
            img = img.crop((0, top, img.width, top + new_h))

        return img.resize((self.w, self.h), Image.LANCZOS)

    def _create_gradient_bg(self, idx: int) -> Image.Image:
        """ê·¸ë¼ë°ì´ì…˜ í´ë°± ë°°ê²½"""
        img = Image.new("RGB", (self.w, self.h))
        draw = ImageDraw.Draw(img)
        gradients = [
            [(30, 25, 40), (50, 35, 25)],
            [(25, 35, 30), (40, 25, 40)],
            [(35, 30, 25), (25, 30, 45)],
        ]
        c1, c2 = gradients[idx % len(gradients)]
        for y in range(self.h):
            r = y / self.h
            color = tuple(int(c1[i] * (1-r) + c2[i] * r) for i in range(3))
            draw.line([(0, y), (self.w, y)], fill=color)
        return img

    def _render_title_bar(self, frame: Image.Image, title: str,
                           alpha: float = 1.0) -> Image.Image:
        """
        v4.1: ì„¸ë ¨ëœ ìƒë‹¨ íƒ€ì´í‹€ ë°”
        â”€ ë…¸ë€ìƒ‰ ì•…ì„¼íŠ¸ ë°•ìŠ¤ + í•µì‹¬ ì£¼ì œ ê³ ì • íƒ€ì´í‹€
        â”€ ì–´ë‘ìš´ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ìœ¼ë¡œ ì‹œì¸ì„± í™•ë³´
        """
        overlay = Image.new("RGBA", (self.w, self.h), (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)
        font = FontManager.get_font(30, bold=True)

        # íƒ€ì´í‹€ í…ìŠ¤íŠ¸ (ìµœëŒ€ 18ì)
        title_text = title[:18] + ("..." if len(title) > 18 else "")
        bbox = draw.textbbox((0, 0), title_text, font=font)
        tw, th = bbox[2] - bbox[0], bbox[3] - bbox[1]

        bar_h = th + 32
        a = int(220 * alpha)

        # ë°°ê²½: ê·¸ë¼ë°ì´ì…˜ (ìœ„ìª½ ë¶ˆíˆ¬ëª… â†’ ì•„ë˜ìª½ ë°˜íˆ¬ëª…)
        for y in range(bar_h + 10):
            fade = max(0, a - int(y * 1.5))
            draw.line([(0, y), (self.w, y)], fill=(10, 10, 10, fade))

        # ë…¸ë€ìƒ‰ ì•…ì„¼íŠ¸ ë¼ì¸ (ìƒë‹¨ 3px)
        draw.rectangle([(0, 0), (self.w, 3)], fill=(255, 220, 0, a))

        # í…ìŠ¤íŠ¸ ì¤‘ì•™ (Pillow stroke_width)
        tx = (self.w - tw) // 2
        ty = 8 + (bar_h - th) // 2
        draw.text((tx, ty), title_text, font=font,
                   fill=(255, 255, 255, int(250 * alpha)),
                   stroke_width=2,
                   stroke_fill=(0, 0, 0, int(200 * alpha)))

        frame = frame.convert("RGBA")
        return Image.alpha_composite(frame, overlay).convert("RGB")

    def _render_cta_outro(self, frame: Image.Image,
                           remaining_sec: float) -> Image.Image:
        """v9.0: CTA ê°œì„  â€” êµ¬ë… ìœ ë„ ì œê±°, ëŒ“ê¸€ ì•„ì´ì½˜ + ì—´ë¦° ì§ˆë¬¸ ê°•ì¡°

        ìˆì¸ ì—ì„œ "ì¢‹ì•„ìš”/êµ¬ë…" ì§ì ‘ ìœ ë„ëŠ” ì—­íš¨ê³¼.
        ëŒ€ì‹  ë§ˆì§€ë§‰ ì—´ë¦° ì§ˆë¬¸ì„ í¬ê²Œ í‘œì‹œ + ëŒ“ê¸€ ì•„ì´ì½˜ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ìœ ë„.
        """
        overlay = Image.new("RGBA", (self.w, self.h), (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)

        # í˜ì´ë“œì¸ (0â†’1 over 0.4ì´ˆ)
        alpha = min(1.0, (2.0 - remaining_sec) / 0.4)

        # ëŒ“ê¸€ ì•„ì´ì½˜ (ğŸ’¬) + "ëŒ“ê¸€ë¡œ ì•Œë ¤ì¤˜" ì‘ì€ í…ìŠ¤íŠ¸
        font_icon = FontManager.get_font(40, bold=True)
        font_hint = FontManager.get_font(24, bold=False)

        # ì‚´ì§ ë°”ìš´ìŠ¤ (1ì´ˆ ì£¼ê¸°)
        bounce = 1.0 + 0.05 * math.sin((2.0 - remaining_sec) * 3.14 * 2)

        # ëŒ“ê¸€ íŒíŠ¸ ìœ„ì¹˜ (í•˜ë‹¨ 88%)
        hint_y = int(self.h * 0.88)
        a = int(200 * alpha)

        # "ğŸ’¬ ëŒ“ê¸€ë¡œ ì•Œë ¤ì¤˜" í…ìŠ¤íŠ¸
        hint_text = "ëŒ“ê¸€ë¡œ ì•Œë ¤ì¤˜"
        bbox = draw.textbbox((0, 0), hint_text, font=font_hint)
        tw = bbox[2] - bbox[0]
        tx = (self.w - tw) // 2

        # ë°˜íˆ¬ëª… ë°°ê²½ í•„ (íŒíŠ¸ í…ìŠ¤íŠ¸ ì£¼ë³€ë§Œ)
        pad = 16
        draw.rounded_rectangle(
            [(tx - pad, hint_y - pad // 2), (tx + tw + pad, hint_y + (bbox[3] - bbox[1]) + pad // 2)],
            radius=12, fill=(0, 0, 0, int(100 * alpha))
        )

        draw.text((tx, hint_y), hint_text, font=font_hint,
                   fill=(255, 255, 255, a),
                   stroke_width=2, stroke_fill=(0, 0, 0, a))

        frame = frame.convert("RGBA")
        return Image.alpha_composite(frame, overlay).convert("RGB")

    def _render_subtitle(self, frame: Image.Image, chunk: dict,
                          current_ms: float) -> Image.Image:
        """
        v10.0 ìë§‰ ê°œì„ 
        â”€ í°íŠ¸: ê¸°ì¡´ ëŒ€ë¹„ 1.4ë°° í¬ê²Œ
        â”€ ë°˜íˆ¬ëª… ê²€ì • ë°°ê²½ë°•ìŠ¤ (opacity 0.6)
        â”€ important_words: ë…¸ë€ìƒ‰(#FFD700) + glow
        â”€ highlight: ë…¸ë€ìƒ‰(#FFD60A) + ìŠ¤ì¼€ì¼ 1.15x
        â”€ ìœ„ì¹˜: í™”ë©´ í•˜ë‹¨ 15% ê³ ì • (85%)
        â”€ ì¤„ë°”ê¿ˆ: ë‹¨ì–´ ê²½ê³„ ê¸°ì¤€
        â”€ ì• ë‹ˆë©”ì´ì…˜: cubic-bezier ë°”ìš´ìŠ¤ ë“±ì¥
        """
        text = chunk["text"]
        start_ms = chunk["start_ms"]
        end_ms = chunk["end_ms"]
        elapsed = current_ms - start_ms
        remaining = end_ms - current_ms
        is_highlight = chunk.get("highlight", False)
        important_words = chunk.get("important_words", [])

        # â”€â”€ í˜ì´ë“œ ì¸/ì•„ì›ƒ â”€â”€
        alpha = 1.0
        fade_in_ms = 120
        fade_out_ms = 80
        if elapsed < fade_in_ms:
            alpha = elapsed / fade_in_ms
        elif remaining < fade_out_ms:
            alpha = remaining / fade_out_ms
        alpha = max(0.0, min(1.0, alpha))

        # â”€â”€ í°íŠ¸ (v10.0: 1.4ë°° í¬ê¸° ì¦ê°€) â”€â”€
        base_font_size = int(self.config.font_size * 1.96)  # 56 * 1.96 â‰ˆ 110px
        # ì²« ìë§‰ 1.6ë°° (ì˜¤í”„ë‹ ì„íŒ©íŠ¸)
        chunk_idx = chunk.get("chunk_idx", -1)
        if chunk_idx == 0:
            base_font_size = int(base_font_size * 1.6)
        if is_highlight:
            base_font_size = int(base_font_size * 1.15)
        font = FontManager.get_shorts_font(base_font_size)
        font_big = FontManager.get_shorts_font(int(base_font_size * 1.15))
        stroke_px = 4

        # â”€â”€ ìƒ‰ìƒ â”€â”€
        if is_highlight:
            text_color = (255, 214, 10)       # ë…¸ë€ìƒ‰ (#FFD60A)
        else:
            text_color = (255, 255, 255)       # í°ìƒ‰
        imp_color = (255, 215, 0)              # ë…¸ë€ìƒ‰ (#FFD700) â€” important_words

        has_kinetic = bool(important_words)

        # â”€â”€ ì¤„ë°”ê¿ˆ (ë‹¨ì–´ ê²½ê³„ ê¸°ì¤€) â”€â”€
        max_chars = 14
        lines = self._word_boundary_wrap(text, max_chars)

        # â”€â”€ ì¸¡ì • â”€â”€
        draw_temp = ImageDraw.Draw(frame)
        line_heights, line_widths = [], []
        for line in lines:
            bbox = draw_temp.textbbox((0, 0), line, font=font, stroke_width=stroke_px)
            line_widths.append(bbox[2] - bbox[0])
            line_heights.append(bbox[3] - bbox[1])

        line_gap = 10
        total_h = sum(line_heights) + (len(lines) - 1) * line_gap

        # â”€â”€ ìœ„ì¹˜: í•˜ë‹¨ 85% (í™”ë©´ í•˜ë‹¨ 15% ê³ ì •) â”€â”€
        text_block_y = int(self.h * 0.85) - total_h

        # â”€â”€ ë“±ì¥ ì• ë‹ˆë©”ì´ì…˜: cubic-bezier(0.34, 1.56, 0.64, 1) ë°”ìš´ìŠ¤ â”€â”€
        if elapsed < fade_in_ms:
            t = elapsed / fade_in_ms
            # overshoot easing: ì‚´ì§ ìœ„ë¡œ ê°”ë‹¤ ë‚´ë ¤ì˜¤ëŠ” ë°”ìš´ìŠ¤
            ease_t = 1 + 2.56 * (t - 1) ** 3 + 1.56 * (t - 1) ** 2
            ease_t = max(0.0, min(1.2, ease_t))
            slide_offset = int(40 * (1 - ease_t))
            text_block_y += slide_offset

        # â”€â”€ ê°•ì¡° ë‹¨ì–´ íŒ íš¨ê³¼ â”€â”€
        bounce_scale = 1.0
        if has_kinetic and 80 < elapsed < 400:
            bt = (elapsed - 80) / 320
            bounce_scale = 1.0 + 0.12 * math.sin(bt * math.pi)

        # â”€â”€ ì˜¤ë²„ë ˆì´ ë Œë”ë§ â”€â”€
        overlay = Image.new("RGBA", (self.w, self.h), (0, 0, 0, 0))
        draw = ImageDraw.Draw(overlay)

        a = int(255 * alpha)
        shadow_a = int(150 * alpha)

        # â”€â”€ ë°˜íˆ¬ëª… ê²€ì • ë°°ê²½ë°•ìŠ¤ (opacity 0.6) â”€â”€
        max_line_w = max(line_widths) if line_widths else 0
        pad_x, pad_y = 30, 16
        box_x1 = (self.w - max_line_w) // 2 - pad_x
        box_y1 = text_block_y - pad_y
        box_x2 = (self.w + max_line_w) // 2 + pad_x
        box_y2 = text_block_y + total_h + pad_y
        box_alpha = int(153 * alpha)  # 0.6 * 255 = 153
        draw.rounded_rectangle(
            [box_x1, box_y1, box_x2, box_y2],
            radius=12, fill=(0, 0, 0, box_alpha),
        )

        # â”€â”€ í…ìŠ¤íŠ¸ ë Œë”ë§ â”€â”€
        text_y = text_block_y
        for i, line in enumerate(lines):
            segments = self._segment_important(line, important_words)
            total_seg_w = 0
            for seg_text, is_imp in segments:
                seg_font = font_big if is_imp else font
                bbox = draw_temp.textbbox((0, 0), seg_text, font=seg_font, stroke_width=stroke_px)
                total_seg_w += bbox[2] - bbox[0]

            cursor_x = (self.w - total_seg_w) // 2

            for seg_text, is_imp in segments:
                if is_imp and has_kinetic:
                    seg_font = font_big
                    seg_color = imp_color
                    y_offset = -int((bounce_scale - 1.0) * 15)
                else:
                    seg_font = font
                    seg_color = text_color
                    y_offset = 0

                seg_bbox = draw_temp.textbbox((0, 0), seg_text, font=seg_font, stroke_width=stroke_px)
                seg_w = seg_bbox[2] - seg_bbox[0]
                seg_y = text_y + y_offset

                # 1) ë“œë¡­ ì„€ë„ìš° (4px offset, ì‚´ì§ ë¸”ëŸ¬ ëŠë‚Œ)
                draw.text((cursor_x + 3, seg_y + 3), seg_text, font=seg_font,
                           fill=(0, 0, 0, shadow_a),
                           stroke_width=2, stroke_fill=(0, 0, 0, shadow_a))

                # 2) ë©”ì¸ í…ìŠ¤íŠ¸ + ë‘êº¼ìš´ ê²€ì • ì™¸ê³½ì„ 
                draw.text((cursor_x, seg_y), seg_text, font=seg_font,
                           fill=(*seg_color, a),
                           stroke_width=stroke_px,
                           stroke_fill=(0, 0, 0, int(240 * alpha)))

                # 3) important_words glow íš¨ê³¼ (ë…¸ë€ ê¸€ìì— ì¶”ê°€ ê°•ì¡°)
                if is_imp and has_kinetic:
                    glow_a = int(60 * alpha * bounce_scale)
                    draw.text((cursor_x, seg_y), seg_text, font=seg_font,
                               fill=(*imp_color, glow_a),
                               stroke_width=stroke_px + 2,
                               stroke_fill=(*imp_color, int(glow_a * 0.3)))

                cursor_x += seg_w

            text_y += line_heights[i] + line_gap

        frame = frame.convert("RGBA")
        frame = Image.alpha_composite(frame, overlay)
        return frame.convert("RGB")

    def _word_boundary_wrap(self, text: str, max_chars: int) -> list[str]:
        """ë‹¨ì–´ ê²½ê³„ ê¸°ì¤€ ì¤„ë°”ê¿ˆ (ê¸€ììˆ˜ ê¸°ì¤€ë³´ë‹¤ ìì—°ìŠ¤ëŸ¬ì›€)"""
        if len(text) <= max_chars:
            return [text]

        # í•œêµ­ì–´ ì¡°ì‚¬/ì–´ë¯¸ ê²½ê³„ì—ì„œ ì¤„ë°”ê¿ˆ ì‹œë„
        break_chars = " .,!?ì€ëŠ”ì´ê°€ì„ë¥¼ì—ì„œë„ë¡œì˜ì™€ê³¼"
        mid = len(text) // 2
        best_break = mid

        for offset in range(min(7, mid)):
            for pos in [mid + offset, mid - offset]:
                if 0 < pos < len(text) and text[pos] in break_chars:
                    best_break = pos + (1 if text[pos] != " " else 0)
                    break
            else:
                continue
            break

        result = [text[:best_break].strip(), text[best_break:].strip()]
        # 3ì¤„ ì´ìƒ ë°©ì§€
        final = []
        for line in result:
            if len(line) > max_chars + 5:
                m = len(line) // 2
                final.append(line[:m].strip())
                final.append(line[m:].strip())
            else:
                final.append(line)
        return final[:3]

    def _assemble_webtoon(self, script_data: dict, chunks: list[dict],
                           ai_images: list[dict], work_dir: str) -> str:
        """
        v7.0 ì›¹íˆ°í˜• ì‡¼ì¸  ì¡°ë¦½
        â”€ ê° ì¥ë©´ë§ˆë‹¤ AI ì´ë¯¸ì§€ + Ken Burns ì¤Œì¸/ì•„ì›ƒ
        â”€ ë§í’ì„  ìŠ¤íƒ€ì¼ ìë§‰ (í•˜ë‹¨ 30%)
        â”€ ì¥ë©´ ì „í™˜: í˜ì´ë“œ
        """
        print(f"\n{'='*60}")
        print(f"ğŸ¬ Stage 4: ì˜ìƒ ì¡°ë¦½ (v7.0 ì›¹íˆ° ëª¨ë“œ)")
        print(f"{'='*60}")

        # chunk_idx ì‚½ì…
        for ci, chunk in enumerate(chunks):
            chunk["chunk_idx"] = ci

        # Step 1: ì˜¤ë””ì˜¤
        concat_audio = os.path.join(work_dir, "full_audio.mp3")
        self._concat_audio(chunks, concat_audio, work_dir)

        total_ms = max(c["end_ms"] for c in chunks) + 500
        total_sec = total_ms / 1000
        total_frames = int(total_sec * self.config.fps)

        # Step 2: ì´ë¯¸ì§€ â†’ ì¥ë©´ íƒ€ì„ë¼ì¸ ë§¤í•‘
        # ai_images: [{"chunk_idx": 0, "end_idx": 2, "image_path": "..."}]
        scene_timeline = []  # [(start_ms, end_ms, image_path)]
        for img_info in ai_images:
            sidx = img_info["chunk_idx"]
            eidx = img_info["end_idx"]
            img_path = img_info.get("image_path")
            if sidx < len(chunks) and eidx < len(chunks):
                s_ms = chunks[sidx]["start_ms"]
                e_ms = chunks[eidx]["end_ms"]
                scene_timeline.append((s_ms, e_ms, img_path))
        # ë¹ˆ êµ¬ê°„ ì²˜ë¦¬: ì‹œì‘ ì „, ë í›„
        if not scene_timeline:
            scene_timeline = [(0, total_ms, None)]

        # Step 3: ì´ë¯¸ì§€ ë¡œë“œ + Ken Burns í”„ë ˆì„ ë Œë”ë§
        print(f"  ğŸ–¼ï¸  {total_frames}í”„ë ˆì„ ë Œë”ë§ ì¤‘ (ì›¹íˆ° + Ken Burns)...")

        frames_dir = os.path.join(work_dir, "frames")
        os.makedirs(frames_dir, exist_ok=True)

        # ì´ë¯¸ì§€ ìºì‹œ
        img_cache = {}
        for st in scene_timeline:
            ipath = st[2]
            if ipath and os.path.exists(ipath) and ipath not in img_cache:
                try:
                    img = Image.open(ipath).convert("RGB")
                    img = img.resize((self.w, self.h), Image.LANCZOS)
                    img_cache[ipath] = img
                except Exception:
                    img_cache[ipath] = None

        # ì¥ë©´ ì „í™˜ ì‹œê°„ ê³„ì‚° (ì¥ë©´ë³„ highlight/emotion ë§¤í•‘)
        _scene_highlights = {}
        for img_info in ai_images:
            sidx = img_info["chunk_idx"]
            if sidx < len(chunks):
                _scene_highlights[img_info.get("image_path")] = chunks[sidx].get("highlight", False)

        prev_scene_idx = -1
        prev_frame = None

        for frame_idx in range(total_frames):
            current_ms = (frame_idx / self.config.fps) * 1000

            # í˜„ì¬ ì¥ë©´ ì°¾ê¸°
            current_img_path = None
            scene_start_ms = 0
            scene_end_ms = total_ms
            scene_idx = 0
            for si, (s_ms, e_ms, ipath) in enumerate(scene_timeline):
                if s_ms <= current_ms <= e_ms:
                    current_img_path = ipath
                    scene_start_ms = s_ms
                    scene_end_ms = e_ms
                    scene_idx = si
                    break

            # ë°°ê²½ ì´ë¯¸ì§€ ë¡œë“œ
            base_img = img_cache.get(current_img_path)
            if base_img:
                frame = base_img.copy()
            else:
                frame = self._create_cinematic_gradient(
                    self._get_current_emotion(chunks, current_ms))

            # Ken Burns íš¨ê³¼ (v9.0 ê°ì • ì—°ë™)
            cur_emotion = self._get_current_emotion(chunks, current_ms)
            frame = self._apply_ken_burns(frame, current_ms,
                                           scene_start_ms, scene_end_ms, scene_idx,
                                           emotion=cur_emotion)

            # â˜… ì¥ë©´ ì „í™˜ íš¨ê³¼ (crossfade / í‘ë°±â†’ì»¬ëŸ¬ / ë¹ ë¥¸ì»·)
            if scene_idx != prev_scene_idx and prev_scene_idx >= 0 and prev_frame:
                elapsed_in_scene = current_ms - scene_start_ms
                is_highlight = _scene_highlights.get(current_img_path, False)

                if cur_emotion == "shocked":
                    # shocked: ë¹ ë¥¸ ì»· 0.1ì´ˆ (3í”„ë ˆì„)
                    trans_ms = 100
                elif is_highlight:
                    # highlight: í‘ë°±â†’ì»¬ëŸ¬ ì „í™˜ 0.3ì´ˆ
                    trans_ms = 300
                else:
                    # ê¸°ë³¸: crossfade 0.3ì´ˆ
                    trans_ms = 300

                if elapsed_in_scene < trans_ms:
                    blend_ratio = elapsed_in_scene / trans_ms
                    if is_highlight and cur_emotion != "shocked":
                        # í‘ë°±â†’ì»¬ëŸ¬: ì´ì „ í”„ë ˆì„ì„ í‘ë°±ìœ¼ë¡œ ë³€í™˜ í›„ ë¸”ë Œë“œ
                        from PIL import ImageOps
                        gray_prev = ImageOps.grayscale(prev_frame).convert("RGB")
                        frame = Image.blend(gray_prev, frame, blend_ratio)
                    else:
                        # ì¼ë°˜ crossfade
                        frame = Image.blend(prev_frame, frame, blend_ratio)

            if scene_idx != prev_scene_idx:
                prev_scene_idx = scene_idx
            prev_frame = frame.copy()

            # Dimming (ì´ë¯¸ì§€ ìœ„ ìë§‰ ê°€ë…ì„±)
            overlay_dim = Image.new("RGBA", (self.w, self.h), (0, 0, 0, 50))
            frame = frame.convert("RGBA")
            frame = Image.alpha_composite(frame, overlay_dim).convert("RGB")

            # í˜„ì¬ ëŒ€ì‚¬ ì°¾ê¸°
            active_chunk = None
            for chunk in chunks:
                if chunk["start_ms"] <= current_ms <= chunk["end_ms"]:
                    active_chunk = chunk
                    break

            # ë§í’ì„  ìë§‰ (í•˜ë‹¨ 30%)
            if active_chunk:
                frame = self._render_balloon_subtitle(frame, active_chunk, current_ms)

            # ì•„ì›ƒíŠ¸ë¡œ
            remaining_sec = (total_ms - current_ms) / 1000
            if 0 <= remaining_sec <= 2.0:
                frame = self._render_cta_outro(frame, remaining_sec)

            # â˜… ì—”ë”© í˜ì´ë“œì•„ì›ƒ: ë§ˆì§€ë§‰ 1.5ì´ˆ ì˜ìƒ fade to black
            if remaining_sec <= 1.5 and remaining_sec > 0:
                fade_alpha = int(255 * (1.0 - remaining_sec / 1.5))
                fade_overlay = Image.new("RGBA", (self.w, self.h), (0, 0, 0, fade_alpha))
                frame = frame.convert("RGBA")
                frame = Image.alpha_composite(frame, fade_overlay).convert("RGB")

            # ì €ì¥
            frame_path = os.path.join(frames_dir, f"frame_{frame_idx:06d}.jpg")
            frame.save(frame_path, quality=92)

            if frame_idx % (self.config.fps * 10) == 0:
                pct = (frame_idx / max(1, total_frames)) * 100
                print(f"  ğŸ“Š ë Œë”ë§ ì§„í–‰: {pct:.0f}% ({frame_idx}/{total_frames})")

        print(f"  âœ… í”„ë ˆì„ ë Œë”ë§ ì™„ë£Œ!")

        # Step 4: FFmpeg ì¸ì½”ë”©
        title_safe = re.sub(r'[^\wê°€-í£]', '_',
                            script_data.get("title", "shorts"))[:20]
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_filename = f"shorts_{title_safe}_{timestamp}.mp4"
        output_path = os.path.join(self.config.output_dir, output_filename)

        abs_frames = os.path.abspath(os.path.join(frames_dir, "frame_%06d.jpg"))
        abs_audio = os.path.abspath(concat_audio)
        abs_output = os.path.abspath(output_path)

        print(f"  ğŸ”§ FFmpeg CRF ì¸ì½”ë”© ì¤‘...")
        cmd = [
            FFMPEG_PATH, "-y",
            "-framerate", str(self.config.fps),
            "-i", abs_frames,
            "-i", abs_audio,
            "-c:v", "libx264", "-preset", "medium", "-crf", "20",
            "-profile:v", "high", "-level", "4.1",
            "-maxrate", "8000k", "-bufsize", "8000k",
            "-c:a", "aac", "-b:a", "256k", "-ar", "44100",
            "-af", f"afade=t=out:st={max(0, total_sec - 1.5):.1f}:d=1.5",
            "-pix_fmt", "yuv420p", "-shortest",
            "-movflags", "+faststart",
            "-metadata", f"title={script_data.get('title', 'Shorts')}",
            abs_output,
        ]
        result = subprocess.run(cmd, capture_output=True, text=True,
                                encoding="utf-8", errors="replace")

        if result.returncode != 0:
            print(f"  âš ï¸  FFmpeg ì—ëŸ¬ â†’ Satisfying í´ë°±")
            return self._assemble_simple_fallback(
                concat_audio, total_sec, chunks, output_path, work_dir)

        size_mb = os.path.getsize(output_path) / (1024 * 1024)
        print(f"  âœ… ì˜ìƒ ì™„ì„±! {output_path} ({size_mb:.1f}MB)")

        shutil.rmtree(frames_dir, ignore_errors=True)
        return output_path

    # â”€â”€ v9.0 ê°ì • ì—°ë™ Ken Burns ëª¨ì…˜ í”„ë¡œí•„ â”€â”€
    _MOTION_PROFILES = {
        "excited":  {"scale_start": 1.0,  "scale_end": 1.20, "pan_speed": 1.2},
        "shocked":  {"scale_start": 1.18, "scale_end": 1.0,  "pan_speed": 2.0},  # ë¹ ë¥¸ ì¤Œì•„ì›ƒ
        "sad":      {"scale_start": 1.08, "scale_end": 1.0,  "pan_speed": 0.4},  # ëŠë¦°
        "funny":    {"scale_start": 1.0,  "scale_end": 1.10, "pan_speed": 1.0},
        "tension":  {"scale_start": 1.0,  "scale_end": 1.05, "pan_speed": 0.6},  # ë¯¸ì„¸ ì¤Œ
        "angry":    {"scale_start": 1.20, "scale_end": 1.0,  "pan_speed": 2.5},  # ê³µê²©ì 
        "warm":     {"scale_start": 1.0,  "scale_end": 1.08, "pan_speed": 0.5},
        "whisper":  {"scale_start": 1.10, "scale_end": 1.05, "pan_speed": 0.3},
        "surprise": {"scale_start": 1.15, "scale_end": 1.0,  "pan_speed": 1.8},
        "neutral":  {"scale_start": 1.0,  "scale_end": 1.06, "pan_speed": 0.7},
        "serious":  {"scale_start": 1.0,  "scale_end": 1.04, "pan_speed": 0.5},
        "relief":   {"scale_start": 1.08, "scale_end": 1.0,  "pan_speed": 0.8},
    }

    def _apply_ken_burns(self, frame: Image.Image, current_ms: float,
                          scene_start: float, scene_end: float,
                          scene_idx: int, emotion: str = "neutral") -> Image.Image:
        """v10.0 Ken Burns: ê°ì • ì—°ë™ ì¤Œ + ì˜¤í”„ë‹ ê°•í™”"""
        scene_duration = max(scene_end - scene_start, 1)
        progress = (current_ms - scene_start) / scene_duration
        progress = max(0.0, min(1.0, progress))

        # â˜… ì˜¤í”„ë‹ ê°•í™”: ì²« ì¥ë©´ 2ì´ˆ ì¤Œì•„ì›ƒâ†’ì¤Œì¸ (1.3x â†’ 1.0x â†’ 1.1x)
        if scene_idx == 0 and current_ms < 2000:
            t = current_ms / 2000
            # ease-in-out: ì¤Œì•„ì›ƒ(1.3x) â†’ ì¤Œì¸(1.05x)
            s_start = 1.30
            s_end = 1.05
            eased = 1 - (1 - t) ** 3  # ease-out cubic
            scale = s_start + (s_end - s_start) * eased
        else:
            # ê°ì •ë³„ ëª¨ì…˜ í”„ë¡œí•„
            profile = self._MOTION_PROFILES.get(emotion, self._MOTION_PROFILES["neutral"])
            s_start = profile["scale_start"]
            s_end = profile["scale_end"]
            eased = 1 - (1 - progress) ** 2
            scale = s_start + (s_end - s_start) * eased

        w, h = frame.size
        new_w = int(w * scale)
        new_h = int(h * scale)

        frame_scaled = frame.resize((new_w, new_h), Image.LANCZOS)

        # pan ë°©í–¥ (scene_idx ê¸°ë°˜ ê²°ì • â€” ëœë¤ ëŠë‚Œì´ì§€ë§Œ ì¬í˜„ ê°€ëŠ¥)
        pan_directions = [(0, 0), (1, 0), (-1, 0), (0, 1), (0, -1), (1, 1), (-1, -1)]
        pan_dx, pan_dy = pan_directions[scene_idx % len(pan_directions)]

        max_pan = int((new_w - w) * 0.4 * progress)
        left = (new_w - w) // 2 + pan_dx * max_pan
        top = (new_h - h) // 2 + pan_dy * max_pan

        # ê²½ê³„ í´ë¨í”„
        left = max(0, min(new_w - w, left))
        top = max(0, min(new_h - h, top))

        return frame_scaled.crop((left, top, left + w, top + h))

    def _render_balloon_subtitle(self, frame: Image.Image, chunk: dict,
                                   current_ms: float) -> Image.Image:
        """v9.0 ì›¹íˆ° ëª¨ë“œ ìë§‰ â€” _render_subtitleê³¼ ë™ì¼ ìŠ¤íƒ€ì¼ í†µì¼"""
        # ì›¹íˆ° ëª¨ë“œë„ ë™ì¼í•œ í˜„ëŒ€ì  ìë§‰ ì‚¬ìš©
        return self._render_subtitle(frame, chunk, current_ms)

    def _segment_important(self, line: str, important_words: list) -> list:
        """ë¼ì¸ì„ (text, is_important) ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„ë¦¬"""
        if not important_words:
            return [(line, False)]
        segments = []
        remaining = line
        while remaining:
            earliest_pos = len(remaining)
            earliest_word = None
            for iw in important_words:
                pos = remaining.find(iw)
                if pos != -1 and pos < earliest_pos:
                    earliest_pos = pos
                    earliest_word = iw
            if earliest_word is None:
                segments.append((remaining, False))
                break
            if earliest_pos > 0:
                segments.append((remaining[:earliest_pos], False))
            segments.append((earliest_word, True))
            remaining = remaining[earliest_pos + len(earliest_word):]
        return segments if segments else [(line, False)]

    def _get_current_emotion(self, chunks: list, current_ms: float) -> str:
        """í˜„ì¬ ì‹œê°„ì˜ ê°ì • ë°˜í™˜"""
        for c in chunks:
            if c["start_ms"] <= current_ms <= c["end_ms"]:
                return c.get("emotion", "neutral")
        return "neutral"

    def _draw_text_with_stroke(self, draw: ImageDraw.Draw,
                                x: int, y: int, text: str,
                                font: ImageFont.FreeTypeFont,
                                color: tuple, alpha: float,
                                stroke_px: int = 4):
        """v4.2: Pillow ë‚´ì¥ stroke_width ì‚¬ìš© â†’ 49ë£¨í”„â†’1ì½œ (20ë°° ê°€ì†)"""
        a = int(255 * alpha)
        stroke_a = int(230 * alpha)
        shadow_a = int(140 * alpha)

        # 1) ê·¸ë¦¼ì (5px offset)
        draw.text((x + 5, y + 5), text, font=font,
                   fill=(0, 0, 0, shadow_a))

        # 2) ì™¸ê³½ì„  + ë©”ì¸ í…ìŠ¤íŠ¸ (Pillow built-in stroke_width)
        draw.text((x, y), text, font=font,
                   fill=(*color, a),
                   stroke_width=stroke_px,
                   stroke_fill=(0, 0, 0, stroke_a))

    def _concat_audio(self, chunks: list[dict], output: str, work_dir: str):
        """
        v6.0: pydub Silence Trim + Cross-fade ë¯¹ì‹±
        â”€ ê° ë¬¸ì¥ ì•ë’¤ ë¬´ìŒ ìë™ ì œê±°
        â”€ 100ms í¬ë¡œìŠ¤í˜ì´ë“œë¡œ ìˆ¨ ì‰´ í‹ˆ ì—†ì´ ì—°ê²° (í‹±í†¡ ìŠ¤íƒ€ì¼)
        â”€ Voice EQ + BGM + Sidechain Ducking -20dB
        """
        # â”€â”€ Step 1: pydub í¬ë¡œìŠ¤í˜ì´ë“œ concat â”€â”€
        raw_voice = os.path.join(work_dir, "voice_raw.mp3")

        # â”€â”€ Step 1: FFmpegë¡œ silence trim + crossfade concat â”€â”€
        # pydubì˜ ffprobe ì˜ì¡´ì„± ë¬¸ì œ íšŒí”¼ â†’ FFmpeg ì§ì ‘ ì²˜ë¦¬
        print(f"  ğŸ”— FFmpeg í¬ë¡œìŠ¤í˜ì´ë“œ ë¯¹ì‹± ({len(chunks)}ë¬¸ì¥)...")

        try:
            # ê° ë¬¸ì¥ ì•ë’¤ ë¬´ìŒ ì œê±° â†’ trimmed íŒŒì¼ ìƒì„±
            trimmed_files = []
            for i, chunk in enumerate(chunks):
                audio_file = chunk.get("audio_file", "")
                if not audio_file or not os.path.exists(audio_file):
                    continue

                trimmed = os.path.join(work_dir, f"trimmed_{i:03d}.mp3")
                # silenceremove: ì•ë’¤ ë¬´ìŒ ì œê±° (threshold -40dB)
                cmd_trim = [
                    FFMPEG_PATH, "-y", "-i", os.path.abspath(audio_file),
                    "-af", (
                        "silenceremove=start_periods=1:start_silence=0.02:start_threshold=-40dB,"
                        "areverse,"
                        "silenceremove=start_periods=1:start_silence=0.02:start_threshold=-40dB,"
                        "areverse"
                    ),
                    "-c:a", "libmp3lame", "-b:a", "192k", "-ar", "44100",
                    os.path.abspath(trimmed),
                ]
                subprocess.run(cmd_trim, capture_output=True, text=True,
                               encoding="utf-8", errors="replace", timeout=10)

                if os.path.exists(trimmed) and os.path.getsize(trimmed) > 500:
                    trimmed_files.append(trimmed)
                else:
                    trimmed_files.append(os.path.abspath(audio_file))

            if not trimmed_files:
                raise Exception("íŠ¸ë¦¬ë°ëœ íŒŒì¼ ì—†ìŒ")

            # í¬ë¡œìŠ¤í˜ì´ë“œ concat: FFmpeg acrossfade í•„í„° ì²´ì¸
            # 2ê°œì”© ìˆœì°¨ ë³‘í•© (ì²´ì¸ì´ ë„ˆë¬´ ê¸¸ë©´ FFmpeg ì—ëŸ¬)
            # â†’ ê°„ì†Œí™”: concat + adelayë¡œ -100ms ê²¹ì¹¨ íš¨ê³¼
            concat_list = os.path.join(work_dir, "concat_list.txt")
            with open(concat_list, "w", encoding="utf-8") as f:
                for i, trimmed in enumerate(trimmed_files):
                    abs_path = os.path.abspath(trimmed).replace("\\", "/")
                    f.write(f"file '{abs_path}'\n")

            # concat í›„ acrossface ëŒ€ì‹  ê°„ê²© 50msë¡œ íƒ€ì´íŠ¸í•˜ê²Œ
            subprocess.run([
                FFMPEG_PATH, "-y", "-f", "concat", "-safe", "0",
                "-i", os.path.abspath(concat_list),
                "-c:a", "libmp3lame", "-b:a", "192k", "-ar", "44100",
                os.path.abspath(raw_voice),
            ], capture_output=True, text=True, encoding="utf-8", errors="replace")

            if os.path.exists(raw_voice) and os.path.getsize(raw_voice) > 1000:
                print(f"  âœ… Silence Trim + Concat ì™„ë£Œ")
            else:
                raise Exception("concat ê²°ê³¼ íŒŒì¼ ì—†ìŒ")

        except Exception as e:
            print(f"  âš ï¸  í¬ë¡œìŠ¤í˜ì´ë“œ ì‹¤íŒ¨ ({e}), ê¸°ë³¸ concat í´ë°±...")
            concat_list = os.path.join(work_dir, "concat_list.txt")
            with open(concat_list, "w", encoding="utf-8") as f:
                for i, chunk in enumerate(chunks):
                    if i > 0:
                        pause_file = os.path.join(work_dir, f"pause_{i:03d}.mp3")
                        subprocess.run([
                            FFMPEG_PATH, "-y", "-f", "lavfi",
                            "-i", "anullsrc=r=44100:cl=mono",
                            "-t", "0.05",
                            "-c:a", "libmp3lame", "-b:a", "128k",
                            "-ar", "44100", pause_file
                        ], capture_output=True)
                        abs_pause = os.path.abspath(pause_file).replace("\\", "/")
                        f.write(f"file '{abs_pause}'\n")
                    abs_audio = os.path.abspath(chunk.get('audio_file', '')).replace("\\", "/")
                    f.write(f"file '{abs_audio}'\n")

            subprocess.run([
                FFMPEG_PATH, "-y", "-f", "concat", "-safe", "0",
                "-i", concat_list,
                "-c:a", "libmp3lame", "-b:a", "128k", "-ar", "44100",
                raw_voice
            ], capture_output=True, text=True, encoding="utf-8", errors="replace")

        if not os.path.exists(raw_voice):
            if chunks and os.path.exists(chunks[0].get("audio_file", "")):
                shutil.copy2(chunks[0]["audio_file"], raw_voice)
            else:
                return

        # â”€â”€ Step 2: Voice ë§ˆìŠ¤í„°ë§ (ê°•í™” EQ + compressor) â”€â”€
        print(f"  ğŸ›ï¸  Voice ë§ˆìŠ¤í„°ë§...")
        mastered_voice = os.path.join(work_dir, "voice_mastered.mp3")
        voice_filter = (
            "acompressor=threshold=-18dB:ratio=4:attack=5:release=50,"
            "equalizer=f=200:t=q:w=1:g=3,"
            "equalizer=f=3000:t=q:w=0.8:g=2,"
            "equalizer=f=5000:t=q:w=1:g=1,"
            "loudnorm=I=-14:TP=-1:LRA=9"
        )
        r = subprocess.run([
            FFMPEG_PATH, "-y", "-i", raw_voice,
            "-af", voice_filter,
            "-c:a", "libmp3lame", "-b:a", "192k", "-ar", "44100",
            mastered_voice
        ], capture_output=True, text=True, encoding="utf-8", errors="replace")
        if r.returncode != 0:
            print(f"  âš ï¸  Voice ë§ˆìŠ¤í„°ë§ ì‹¤íŒ¨, raw ì‚¬ìš©")
            mastered_voice = raw_voice

        # â”€â”€ Step 3: BGM ìƒì„± + Sidechain Ducking (-20dB) â”€â”€
        if self.config.bgm_enabled:
            print(f"  ğŸµ ì•°ë¹„ì–¸íŠ¸ ë“œë¡  BGM + Sidechain Ducking (-20dB)...")
            total_sec = max(c["end_ms"] for c in chunks) / 1000 + 1
            bgm_file = os.path.join(work_dir, "bgm.mp3")
            # v4.2: ì‚¬ì¸íŒŒ ì•°ë¹„ì–¸íŠ¸ ë“œë¡  (220Hz+330Hz+440Hz)
            # í•‘í¬ë…¸ì´ì¦ˆ ëŒ€ì‹  ë”°ëœ»í•œ ë“œë¡  â†’ ëª°ì…ê° + ì§‘ì¤‘ë„ UP
            drone_src = (
                f"sine=f=220:r=44100:d={total_sec:.1f},"
                f"volume=0.03[s1];"
                f"sine=f=330:r=44100:d={total_sec:.1f},"
                f"volume=0.02[s2];"
                f"sine=f=440:r=44100:d={total_sec:.1f},"
                f"volume=0.015[s3];"
                f"[s1][s2][s3]amix=inputs=3:duration=shortest,"
                f"lowpass=f=500,"
                f"afade=t=in:st=0:d=1.5,"
                f"afade=t=out:st={max(0, total_sec - 2):.1f}:d=2,"
                f"volume=0.4"
            )
            subprocess.run([
                FFMPEG_PATH, "-y", "-f", "lavfi",
                "-i", drone_src,
                "-c:a", "libmp3lame", "-b:a", "64k", "-ar", "44100",
                bgm_file
            ], capture_output=True)

            if not os.path.exists(bgm_file):
                print(f"  âš ï¸  BGM ìƒì„± ì‹¤íŒ¨, voiceë§Œ ì‚¬ìš©")
                shutil.move(mastered_voice, output)
                return

            ducked_output = os.path.join(work_dir, "final_mix.mp3")
            abs_voice = os.path.abspath(mastered_voice)
            abs_bgm = os.path.abspath(bgm_file)

            # Sidechain: TTS êµ¬ê°„ BGM 30%ë¡œ ê°ì†Œ (attack 10ms, release 200ms)
            duck_filter = (
                "[1:a]acompressor=threshold=0.008:ratio=20:attack=10:release=200"
                ":detection=peak:link=average:level_sc=1[bgm_ducked];"
                "[0:a][bgm_ducked]amix=inputs=2:weights=1 0.15:duration=shortest"
            )
            r2 = subprocess.run([
                FFMPEG_PATH, "-y",
                "-i", abs_voice,
                "-i", abs_bgm,
                "-filter_complex", duck_filter,
                "-c:a", "libmp3lame", "-b:a", "192k", "-ar", "44100",
                ducked_output
            ], capture_output=True, text=True, encoding="utf-8", errors="replace")

            if r2.returncode == 0:
                shutil.move(ducked_output, output)
                print(f"  âœ… BGM + Sidechain Ducking (-20dB) ì™„ë£Œ")
            else:
                print(f"  âš ï¸  Ducking ì‹¤íŒ¨, voiceë§Œ ì‚¬ìš©")
                shutil.move(mastered_voice, output)
        else:
            shutil.move(mastered_voice, output)
            print(f"  âœ… Voice ë§ˆìŠ¤í„°ë§ ì™„ë£Œ (BGM ì—†ìŒ)")

        # â”€â”€ Step 4: SFX íš¨ê³¼ìŒ ì˜¤ë²„ë ˆì´ (â˜… BGM ë•í‚¹ ì´í›„ ìµœì¢… ë‹¨ê³„) â”€â”€
        try:
            sfx_mgr = SFXManager()
            sfx_events = sfx_mgr.collect_sfx_from_chunks(chunks)
            if sfx_events and os.path.exists(output):
                sfx_output = os.path.join(work_dir, "final_with_sfx.mp3")
                if sfx_mgr.mix_sfx_into_audio(output, sfx_events, sfx_output):
                    shutil.move(sfx_output, output)
                else:
                    print(f"  âš ï¸  SFX ë¯¹ì‹± ì‹¤íŒ¨, SFX ì—†ì´ ì§„í–‰")
            elif sfx_events:
                print(f"  âš ï¸  SFX ì˜¤ë²„ë ˆì´ ìŠ¤í‚µ: output íŒŒì¼ ì—†ìŒ")
        except Exception as e:
            print(f"  âš ï¸  SFX ì‹œìŠ¤í…œ ì˜¤ë¥˜ (ë¬´ì‹œ): {e}")

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for tmp in [raw_voice, mastered_voice,
                     os.path.join(work_dir, "bgm.mp3"),
                     os.path.join(work_dir, "final_mix.mp3"),
                     os.path.join(work_dir, "final_with_sfx.mp3")]:
            if os.path.exists(tmp) and tmp != output:
                try:
                    os.remove(tmp)
                except OSError:
                    pass

    def _assemble_simple_fallback(self, audio: str, duration: float,
                                   chunks: list, output: str,
                                   work_dir: str) -> str:
        """í”„ë ˆì„ ë Œë”ë§ ì‹¤íŒ¨ ì‹œ ASS ìë§‰ í´ë°±"""
        print(f"  ğŸ”„ ASS ìë§‰ í´ë°± ëª¨ë“œ...")
        ass_file = os.path.join(work_dir, "subs.ass")
        self._generate_ass_fallback(chunks, ass_file)

        # ASS íŒŒì¼ ê²½ë¡œì—ì„œ Windows ë°±ìŠ¬ë˜ì‹œë¥¼ ì´ìŠ¤ì¼€ì´í”„
        ass_escaped = ass_file.replace("\\", "/").replace(":", "\\\\:")
        cmd = [
            FFMPEG_PATH, "-y",
            "-f", "lavfi",
            "-i", f"color=c=0x1a1a1a:s={self.w}x{self.h}:d={duration:.2f}:r={self.config.fps}",
            "-i", audio,
            "-vf", f"ass={ass_escaped}",
            "-c:v", "libx264", "-preset", "fast",
            "-b:v", "2000k", "-minrate", "1500k", "-maxrate", "5000k", "-bufsize", "4000k",
            "-c:a", "aac", "-b:a", "256k", "-ar", "44100",
            "-shortest", "-pix_fmt", "yuv420p",
            output,
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, encoding="utf-8", errors="replace")
        if result.returncode != 0:
            print(f"  âš ï¸  ASS í´ë°±ë„ ì‹¤íŒ¨, ìë§‰ ì—†ì´ ì¬ì‹œë„...")
            cmd_simple = [
                FFMPEG_PATH, "-y",
                "-f", "lavfi",
                "-i", f"color=c=0x1a1a1a:s={self.w}x{self.h}:d={duration:.2f}:r={self.config.fps}",
                "-i", audio,
                "-c:v", "libx264", "-preset", "fast",
                "-b:v", "2000k", "-minrate", "1500k", "-maxrate", "5000k", "-bufsize", "4000k",
                "-c:a", "aac", "-b:a", "256k", "-ar", "44100",
                "-shortest", "-pix_fmt", "yuv420p",
                output,
            ]
            subprocess.run(cmd_simple, capture_output=True)
        return output

    def _generate_ass_fallback(self, chunks: list, output: str):
        """ASS ìë§‰ í´ë°± ìƒì„±"""
        ass = f"""[Script Info]
Title: Shorts
ScriptType: v4.00+
PlayResX: {self.w}
PlayResY: {self.h}

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,NanumSquareRound,58,&H00000000,&H000000FF,&H00000000,&H0000CCFF,-1,0,0,0,100,100,0,0,3,3,0,2,60,60,400,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""
        for c in chunks:
            s = self._ms_to_ass(c["start_ms"])
            e = self._ms_to_ass(c["end_ms"])
            ass += f"Dialogue: 0,{s},{e},Default,,0,0,0,,{c['text']}\n"

        with open(output, "w", encoding="utf-8") as f:
            f.write(ass)

    @staticmethod
    def _ms_to_ass(ms: int) -> str:
        t = ms / 1000
        h = int(t // 3600)
        m = int((t % 3600) // 60)
        s = int(t % 60)
        cs = int((t % 1) * 100)
        return f"{h}:{m:02d}:{s:02d}.{cs:02d}"


# ============================================================
# ğŸ­ ë©”ì¸ íŒŒì´í”„ë¼ì¸
# ============================================================
class ShortsFactory:
    def __init__(self, config: Config):
        self.config = config
        self.scraper = CommunityScraper(config)
        self.viral_scraper = ViralSourceScraper()  # v5.0: ë°”ì´ëŸ´ ì†ŒìŠ¤
        self.stock_fetcher = StockVideoFetcher()   # v5.1: Pexels ìŠ¤í†¡ ë¹„ë””ì˜¤
        self.image_gen = ImageGenerator()            # v7.0: AI ì´ë¯¸ì§€ ìƒì„±
        self.scriptgen = ScriptGenerator(config)
        self.tts = TTSEngine(config)
        self.assembler = VideoAssembler(config)

    def _viral_to_posts(self, viral_items: list[dict]) -> list[dict]:
        """v6.0: ì»¤ë®¤ë‹ˆí‹° í•«ê¸€ â†’ ì‹¤í™” ì¬êµ¬ì„±(Reconstructive) í”„ë¡¬í”„íŠ¸ ë¸Œë¦¿ì§€

        í•µì‹¬: ì œëª©ë§Œìœ¼ë¡œ Geminiê°€ ì»¤ë®¤ë‹ˆí‹° íŠ¹ìœ ì˜ ë¬¸ì²´ì™€ ê°ì„±ì„ 100% ëª¨ë°©í•˜ì—¬
        ì‹¤ì œ ìˆì—ˆì„ ë²•í•œ ë§µê³  ì§  ì°ì„ ì—­ì‚° ì¬êµ¬ì„±í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ì„¤ê³„.
        """

        # ì†ŒìŠ¤ë³„ ë¬¸ì²´/í†¤ ì§€ì‹œ
        _SOURCE_TONE = {
            "ë„¤ì´íŠ¸íŒ": (
                "ë„¤ì´íŠ¸íŒ 'í†¡ì»¤ë“¤ì˜ ì„ íƒ' ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•˜ë¼. "
                "ì‹œì–´ë¨¸ë‹ˆ/ë‚¨í¸/ì‹œëŒ/ì§ì¥ìƒì‚¬/ì¹œêµ¬ ê°™ì€ ì¸ê°„ê´€ê³„ ê°ˆë“±ì´ í•µì‹¬ì´ë‹¤. "
                "ê¸€ì“´ì´ê°€ ì–µìš¸í•˜ê³  ë¶„í•œ ë§ˆìŒìœ¼ë¡œ í† ë¡œí•˜ëŠ” 1ì¸ì¹­ ì‹œì , "
                "êµ¬ì–´ì²´+ë°˜ë§ í˜¼í•©, ê°ì •ì´ì… í­ë°œí•˜ëŠ” ì „ê°œ, "
                "ëŒ“ê¸€ëŸ¬ë“¤ì´ 'ì´ê±´ ì°¸ìœ¼ë©´ ì•ˆ ë¨' í•˜ê³  ë¶„ë…¸í•  ë§Œí•œ ì „ê°œë¡œ êµ¬ì„±."
            ),
            "ì¸ìŠ¤í‹°ì¦ˆ": (
                "ì¸ìŠ¤í‹°ì¦ˆ ì¸ê¸°ê¸€ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•˜ë¼. "
                "ì¼ìƒì—ì„œ ë²Œì–´ì§„ ê³µê°í˜• ì—í”¼ì†Œë“œ, ê°€ë²¼ìš´ ìœ ë¨¸ì™€ ë°˜ì „, "
                "'ã…‹ã…‹ã…‹' 'ã„¹ã…‡' ê°™ì€ ì¸í„°ë„· ì¶•ì•½ì–´ ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©, "
                "10~30ëŒ€ê°€ ê³µê°í•˜ë©° ëŒ“ê¸€ ë‹¬ê³  ì‹¶ì–´ì§€ëŠ” í†¤."
            ),
            "ì—í¨ì½”ë¦¬ì•„": (
                "ì—í¨ì½”ë¦¬ì•„ ë² ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•˜ë¼. "
                "ì‹œì‚¬ ì´ìŠˆë“  ìœ ë¨¸ë“  íŒ©íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ë¹ ë¥´ê²Œ ì „ë‹¬í•˜ê³ , "
                "íŠ¹ìœ ì˜ '~í•¨' '~ì¸ë“¯' ëë§íˆ¬, ì´ë¯¸ì§€ ì²¨ë¶€ ëŠë‚Œì˜ ë¬˜ì‚¬, "
                "í•µì‹¬ ì •ë³´ â†’ ë°˜ì „ â†’ ëŒ“ê¸€ ë°˜ì‘ ì˜ˆì¸¡ê¹Œì§€ í¬í•¨."
            ),
            "ë””ì‹œì‹¤ë² ": (
                "ë””ì‹œì¸ì‚¬ì´ë“œ ì‹¤ì‹œê°„ë² ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•˜ë¼. "
                "ìê·¹ì ì´ê³  íŒŒê²©ì ì¸ ì „ê°œ, ë””ì‹œ íŠ¹ìœ ì˜ ê±°ì¹œ ë¬¸ì²´, "
                "'ã…‹ã…‹ã…‹' 'ã„·ã„·' 'ë¯¸ì³¤ã…‹ã…‹' ê°™ì€ í‘œí˜„ ììœ ë¡­ê²Œ ì‚¬ìš©, "
                "ì¶©ê²©ì  ë°˜ì „ì´ë‚˜ ì–´ì´ì—†ëŠ” ê²°ë§ë¡œ ë§ˆë¬´ë¦¬."
            ),
            "êµ¬ê¸€íŠ¸ë Œë“œ": (
                "í˜„ì¬ í•œêµ­ì—ì„œ ì‹¤ì‹œê°„ í™”ì œì¸ í‚¤ì›Œë“œë‹¤. "
                "ì´ í‚¤ì›Œë“œê°€ ì™œ í™”ì œì¸ì§€ ì¶”ì¸¡í•´ì„œ, "
                "ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ëŒê³  ìˆì„ ë²•í•œ ì° í˜•íƒœë¡œ ì¬êµ¬ì„±í•˜ë¼. "
                "íŒ©íŠ¸ì™€ ì¶”ì¸¡ì„ ì„ë˜, ì‹œì²­ìê°€ 'ì§„ì§œ?' í•˜ê³  ë°˜ì‘í•  ì „ê°œë¡œ."
            ),
        }

        posts = []
        for item in viral_items[:self.config.crawl_count]:
            title = item.get("title", "")
            source = item.get("source", "viral")
            body = item.get("content", "")
            comments = item.get("comments", 0)
            views = item.get("views", 0)

            # ì†ŒìŠ¤ë³„ í†¤ ì§€ì‹œ ì„ íƒ
            tone = _SOURCE_TONE.get(source, _SOURCE_TONE["ì¸ìŠ¤í‹°ì¦ˆ"])

            # â˜… ì‹¤í™” ì¬êµ¬ì„± í”„ë¡¬í”„íŠ¸
            padded_content = (
                f"[ì›ë³¸ ì œëª©] {title}\n"
                f"[ì¶œì²˜] {source} (ëŒ“ê¸€ {comments}ê°œ, ì¡°íšŒ {views:,})\n"
                f"[ë³¸ë¬¸] {body[:300] if body else '(ë³¸ë¬¸ ì—†ìŒ â€” ì œëª©ë§Œìœ¼ë¡œ ì—­ì‚° ì¬êµ¬ì„± í•„ìš”)'}\n\n"
                f"[ëŒ€ë³¸ ì‘ì„± ì§€ì‹œ]\n"
                f"{tone}\n\n"
                f"ìœ„ ì œëª©ì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤ì œ {source}ì— ì˜¬ë¼ì™”ì„ ë²•í•œ "
                f"ë§µê³  ì§  ì‹¤í™” ì—í”¼ì†Œë“œë¥¼ ì—­ì‚°í•˜ì—¬ ì¬êµ¬ì„±í•˜ë¼.\n"
                f"- êµ¬ì²´ì ì¸ ë””í…Œì¼(ì¥ì†Œ, ëŒ€í™”, ìƒí™©)ì„ ì‚´ë ¤ì„œ ìƒìƒí•˜ê²Œ\n"
                f"- ê°ì • ë³€í™”ê°€ ëª…í™•í•œ ê¸°ìŠ¹ì „ê²° êµ¬ì¡°\n"
                f"- ë°˜ì „ ë˜ëŠ” ì¹´íƒ€ë¥´ì‹œìŠ¤ ìˆëŠ” ì „ê°œ (ë‹¨, ì–µì§€ í›ˆí›ˆí•¨ ê¸ˆì§€)\n"
                f"- ì‹œì²­ìê°€ ëŒ“ê¸€ì„ ì•ˆ ë‹¬ê³ ëŠ” ëª» ë°°ê¸°ëŠ” ë§ˆë¬´ë¦¬\n"
                f"- 10ëŒ€~60ëŒ€ ì „ ì—°ë ¹ëŒ€ê°€ ê³µê° ê°€ëŠ¥í•œ ì†Œì¬ë¡œ êµ¬ì„±\n"
            )

            posts.append({
                "title": title,
                "content": padded_content,
                "source": source,
                "url": item.get("url", ""),
                "screenshots": [],
                "_is_viral": True,
            })
        return posts

    async def run(self) -> list[str]:
        start_time = time.time()
        output_files = []

        print("\n" + "ğŸ¬" * 30)
        print("  YouTube Shorts íŒ©í† ë¦¬ v5.0 'The Viral Machine'")
        print("  ğŸŒ ë©€í‹°í”Œë«í¼ + ğŸ”¥ ë°”ì´ëŸ´ í”„ë¡¬í”„íŠ¸ + ğŸµ ë“œë¡  BGM + âš¡ ë°”ì´ëŸ´ ê°€ì‚°ì  ì •ë ¬")
        print("ğŸ¬" * 30)

        # Stage 1: í¬ë¡¤ë§ + ìŠ¤í¬ë¦°ìƒ·
        if self.config.skip_crawl and self.config.manual_topic:
            posts = [{
                "title": self.config.manual_topic,
                "content": self.config.manual_topic,
                "source": "manual",
                "screenshots": [],
            }]
        elif self.config.source == "viral":
            # â”€â”€ v5.0: ë°”ì´ëŸ´ ì†ŒìŠ¤ ìš°ì„  í¬ë¡¤ë§ â”€â”€
            viral_items = self.viral_scraper.collect_all()
            if viral_items:
                posts = self._viral_to_posts(viral_items)
                print(f"\n  ğŸ”¥ ë°”ì´ëŸ´ ì†ŒìŠ¤ {len(posts)}ê°œ ì„ ì • ì™„ë£Œ")
            else:
                print("  âš ï¸  ë°”ì´ëŸ´ ì†ŒìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨ â†’ ì»¤ë®¤ë‹ˆí‹° í´ë°±")
                posts = self.scraper.scrape_with_screenshots()
        else:
            posts = self.scraper.scrape_with_screenshots()

        if not posts:
            print("âŒ í¬ë¡¤ë§ ê²°ê³¼ ì—†ìŒ!")
            return []

        # ê° ê¸€ë§ˆë‹¤ ì˜ìƒ ìƒì„±
        for idx, post in enumerate(posts):
            print(f"\n{'ğŸ¬'*20}")
            print(f"  [{idx+1}/{len(posts)}] {post['title'][:40]}")
            print(f"{'ğŸ¬'*20}")

            work_dir = os.path.join(
                self.config.output_dir,
                f"_work_{idx}_{datetime.now().strftime('%H%M%S')}"
            )
            os.makedirs(work_dir, exist_ok=True)

            try:
                # Stage 2: ëŒ€ë³¸
                if self.config.skip_crawl and self.config.manual_topic:
                    script_data = self.scriptgen.generate_from_topic(
                        self.config.manual_topic
                    )
                elif post.get("_is_viral"):
                    # ë°”ì´ëŸ´ ì†ŒìŠ¤ â†’ í† í”½ ê¸°ë°˜ ëŒ€ë³¸ ìƒì„±
                    script_data = self.scriptgen.generate_from_topic(
                        post["title"]
                    )
                else:
                    script_data = self.scriptgen.generate(post)

                if script_data is None:
                    print(f"  â­ï¸  ì†ŒìŠ¤ í’ˆì§ˆ ë¶€ì¡±, ê±´ë„ˆëœ€")
                    continue

                # ëŒ€ë³¸ ì €ì¥
                with open(os.path.join(work_dir, "script.json"), "w",
                          encoding="utf-8") as f:
                    json.dump(script_data, f, ensure_ascii=False, indent=2)

                # v7.0: AI ì´ë¯¸ì§€ ìƒì„± (ì›¹íˆ° ëª¨ë“œ)
                ai_images = []
                try:
                    ai_images = self.image_gen.generate_scene_images(
                        script_data, work_dir
                    )
                except Exception as img_err:
                    print(f"  âš ï¸  AI ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {img_err}")

                # v5.1: Pexels ìŠ¤í†¡ ë¹„ë””ì˜¤ (AI ì´ë¯¸ì§€ ì—†ì„ ë•Œ í´ë°±)
                scene_videos = []
                if not ai_images and self.config.use_stock_video:
                    scene_videos = self.stock_fetcher.fetch_scene_videos(
                        script_data, work_dir
                    )

                # ìŠ¤í†¡ ë¹„ë””ì˜¤ ì—†ìœ¼ë©´ í´ë°±ìš© ìŠ¤í¬ë¦°ìƒ·
                screenshots = post.get("screenshots", [])

                # Stage 3: TTS
                chunks = await self.tts.generate(script_data, work_dir)
                if not chunks:
                    print("  âš ï¸  TTS ì‹¤íŒ¨, ê±´ë„ˆëœ€")
                    continue

                # Stage 4: ì˜ìƒ ì¡°ë¦½ (AIì´ë¯¸ì§€ ìš°ì„  â†’ ìŠ¤í†¡ë¹„ë””ì˜¤ â†’ ê·¸ë¼ë°ì´ì…˜)
                output_path = self.assembler.assemble(
                    script_data, chunks, screenshots, work_dir,
                    scene_videos=scene_videos,
                    ai_images=ai_images,
                )
                output_files.append(output_path)

                # ë©”íƒ€ ì €ì¥
                duration_sec = max(c["end_ms"] for c in chunks) / 1000
                meta = {
                    "video": output_path,
                    "script": script_data,
                    "chunks": len(chunks),
                    "duration_sec": duration_sec,
                    "screenshots": screenshots,
                    "created": datetime.now().isoformat(),
                }
                with open(output_path.replace(".mp4", "_meta.json"), "w",
                          encoding="utf-8") as f:
                    json.dump(meta, f, ensure_ascii=False, indent=2)

                # v4.0: upload_info.json (ì—…ë¡œë“œ ì¤€ë¹„ ì™„ë£Œ)
                upload_info = {
                    "title": script_data.get("title", "ìˆì¸ "),
                    "description": script_data.get("description",
                        f"{script_data.get('title', '')} #ìˆì¸  #ì° #ë ˆì „ë“œ"),
                    "tags": [t.replace("#", "") for t in
                             script_data.get("tags", ["ìˆì¸ ", "ì°", "ë ˆì „ë“œ"])],
                    "thumbnail_text": script_data.get("thumbnail_text", ""),
                    "category": "22",  # People & Blogs
                    "privacy": "public",
                    "shorts": True,
                    "duration_sec": round(duration_sec, 1),
                    "video_file": os.path.basename(output_path),
                    "created": datetime.now().isoformat(),
                }
                upload_path = output_path.replace(".mp4", "_upload_info.json")
                with open(upload_path, "w", encoding="utf-8") as f:
                    json.dump(upload_info, f, ensure_ascii=False, indent=2)
                print(f"  ğŸ“‹ upload_info.json ìƒì„± ì™„ë£Œ")

            except Exception as e:
                print(f"  âŒ ì—ëŸ¬: {e}")
                import traceback
                traceback.print_exc()
            finally:
                # work_dir ì„ì‹œ íŒŒì¼ ì •ë¦¬
                if os.path.exists(work_dir):
                    try:
                        shutil.rmtree(work_dir, ignore_errors=True)
                    except OSError:
                        pass

        # ë¦¬í¬íŠ¸
        elapsed = time.time() - start_time
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ìµœì¢… ë¦¬í¬íŠ¸")
        print(f"{'='*60}")
        print(f"  â±ï¸  ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ")
        print(f"  ğŸ¬ ìƒì„± ì˜ìƒ: {len(output_files)}ê°œ")
        for f in output_files:
            if os.path.exists(f):
                sz = os.path.getsize(f) / (1024*1024)
                print(f"     ğŸ“ {f} ({sz:.1f}MB)")
            else:
                print(f"     âš ï¸  {f} (íŒŒì¼ ë¯¸ìƒì„±)")
        print(f"{'='*60}\n")

        return output_files


# ============================================================
# ğŸš€ CLI
# ============================================================
def parse_args():
    p = argparse.ArgumentParser(
        description="ğŸ¬ YouTube Shorts íŒ©í† ë¦¬ v6.0 'The Viral Machine'",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  python main.py                                          # ë°”ì´ëŸ´ ì†ŒìŠ¤ ìë™ (ê¸°ë³¸ê°’)
  python main.py --source viral --count 3                 # ë°”ì´ëŸ´ ì†ŒìŠ¤ 3ê°œ
  python main.py --source dcinside --gallery humor --count 3
  python main.py --source natepann --count 5
  python main.py --url "https://gall.dcinside.com/board/view/..."
  python main.py --topic "ìƒê²¬ë¡€ íŒŒí†  ì°" --skip-crawl
  python main.py --url "https://reddit.com/r/.../..." --video-edit  # ì˜ìƒâ†’ìˆì¸ 
  python main.py --url "https://youtube.com/watch?v=..." --video-edit
  python main.py --tts-engine elevenlabs --source viral --count 1
  python main.py --tts-engine edge --topic "í…ŒìŠ¤íŠ¸" --skip-crawl

í™˜ê²½ë³€ìˆ˜:
  GOOGLE_API_KEY      Gemini API í‚¤ (í•„ìˆ˜, ë¬´ë£Œ)
  ELEVENLABS_API_KEY  ElevenLabs TTS (ì„ íƒ, 1ìˆœìœ„ ê³ í’ˆì§ˆ)
  OPENAI_API_KEY      OpenAI TTS (ì„ íƒ, 2ìˆœìœ„)
  GOAPI_KEY           GoAPI Midjourney (ì„ íƒ, ì´ë¯¸ì§€ ìƒì„±)
  APIFY_API_TOKEN     Apify API í† í° (ì„ íƒ, ì»¤ë®¤ë‹ˆí‹° í¬ë¡¤ë§ ì‹œ)
        """
    )

    src = p.add_argument_group("ğŸ“¡ í¬ë¡¤ë§")
    src.add_argument("--source",
                     choices=["viral",
                              "natepann", "dcinside",
                              "dcinside_realtime_best", "dcinside_hit",
                              "fmkorea", "ruliweb", "instiz", "theqoo"],
                     default="viral")
    src.add_argument("--gallery", default="humor")
    src.add_argument("--count", type=int, default=3)
    src.add_argument("--url", default="")

    scr = p.add_argument_group("ğŸ“ ëŒ€ë³¸")
    scr.add_argument("--topic", default="")
    scr.add_argument("--theme",
                     choices=["auto", "gossip", "life_hack", "empathy", "mystery"],
                     default="auto",
                     help="ì½˜í…ì¸  í…Œë§ˆ (auto=ì£¼ì œ ê¸°ë°˜ ìë™ ê°ì§€)")
    scr.add_argument("--skip-crawl", action="store_true")
    scr.add_argument("--script-json", default="",
                     help="ëŒ€ë³¸ JSON íŒŒì¼ ê²½ë¡œ (í¬ë¡¤ë§+Gemini ê±´ë„ˆë›°ê³  ë°”ë¡œ TTSâ†’ì˜ìƒ)")

    vid = p.add_argument_group("ğŸ¬ ì˜ìƒ í¸ì§‘ (--urlê³¼ í•¨ê»˜ ì‚¬ìš©)")
    vid.add_argument("--video-edit", action="store_true",
                     help="URL ì˜ìƒì„ ë‹¤ìš´ë°›ì•„ í•˜ì´ë¼ì´íŠ¸ â†’ ìˆì¸  ìë™ ë³€í™˜ (yt-dlp í•„ìš”)")

    tts = p.add_argument_group("ğŸ”Š TTS")
    tts.add_argument("--tts-engine",
                     choices=["auto", "elevenlabs", "openai", "edge"],
                     default="auto",
                     help="TTS ì—”ì§„ ì„ íƒ (auto=í‚¤ ê¸°ë°˜ ìë™, elevenlabs=1ìˆœìœ„, openai=2ìˆœìœ„, edge=ë¬´ë£Œ)")
    tts.add_argument("--voice", default="ko-KR-InJoonNeural")
    tts.add_argument("--rate", default="+15%")
    tts.add_argument("--pitch", default="-1Hz")

    out = p.add_argument_group("ğŸ“ ì¶œë ¥")
    out.add_argument("--output", default="./output")
    out.add_argument("--quality", type=int, default=80)

    return p.parse_args()


async def main():
    args = parse_args()

    config = Config(
        source=args.source,
        gallery=args.gallery,
        crawl_count=args.count,
        target_url=args.url,
        manual_topic=args.topic,
        theme=args.theme,
        skip_crawl=args.skip_crawl or bool(args.topic),
        tts_engine=args.tts_engine,
        tts_voice=args.voice,
        tts_rate=args.rate,
        tts_pitch=args.pitch,
        quality=args.quality,
        output_dir=args.output,
    )

    # v6.2: Gemini ë¡¤ë°± â€” GOOGLE_API_KEY í•„ìˆ˜
    if not config.google_api_key:
        print("âŒ GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”! (ëŒ€ë³¸ + ì´ë¯¸ì§€ ìƒì„±)")
        print("   export GOOGLE_API_KEY='AIza...'")
        print("   (ë¬´ë£Œ: https://aistudio.google.com/apikey)")
        sys.exit(1)

    # â”€â”€ ìˆ˜ë™ ëŒ€ë³¸ ëª¨ë“œ (--script-json) â”€â”€
    if args.script_json:
        script_path = os.path.abspath(args.script_json)
        if not os.path.exists(script_path):
            print(f"âŒ ëŒ€ë³¸ íŒŒì¼ ì—†ìŒ: {script_path}")
            sys.exit(1)

        with open(script_path, "r", encoding="utf-8") as f:
            script_data = json.load(f)

        print(f"\n{'='*60}")
        print(f"ğŸ“ ìˆ˜ë™ ëŒ€ë³¸ ëª¨ë“œ: {script_data.get('title', '?')}")
        print(f"  ë¬¸ì¥: {len(script_data.get('script', []))}ê°œ")
        print(f"{'='*60}")

        work_dir = os.path.join(config.output_dir,
                                f"_manual_{datetime.now().strftime('%H%M%S')}")
        os.makedirs(work_dir, exist_ok=True)

        # v7.0: AI ì´ë¯¸ì§€ ìƒì„± (ì›¹íˆ° ëª¨ë“œ)
        ai_images = []
        try:
            image_gen = ImageGenerator()
            ai_images = image_gen.generate_scene_images(script_data, work_dir)
        except Exception as img_err:
            print(f"  âš ï¸  AI ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {img_err}")

        # Pexels ìŠ¤í†¡ ë¹„ë””ì˜¤ (AI ì´ë¯¸ì§€ ì—†ì„ ë•Œ í´ë°±)
        scene_videos = []
        if not ai_images and config.use_stock_video:
            fetcher = StockVideoFetcher()
            scene_videos = fetcher.fetch_scene_videos(script_data, work_dir)

        # TTS
        tts = TTSEngine(config)
        chunks = await tts.generate(script_data, work_dir)
        if not chunks:
            print("âŒ TTS ì‹¤íŒ¨")
            sys.exit(1)

        # ì˜ìƒ ì¡°ë¦½ (AIì´ë¯¸ì§€ ìš°ì„  â†’ ìŠ¤í†¡ë¹„ë””ì˜¤ â†’ ê·¸ë¼ë°ì´ì…˜)
        assembler = VideoAssembler(config)
        output_path = assembler.assemble(
            script_data, chunks, [], work_dir,
            scene_videos=scene_videos,
            ai_images=ai_images,
        )

        # ë©”íƒ€ ì €ì¥
        duration_sec = max(c["end_ms"] for c in chunks) / 1000
        upload_info = {
            "title": script_data.get("title", ""),
            "description": script_data.get("description", ""),
            "tags": [t.lstrip("#") for t in script_data.get("tags", [])],
            "thumbnail_text": script_data.get("thumbnail_text", ""),
            "category": "22",
            "privacy": "public",
            "shorts": True,
            "duration_sec": duration_sec,
            "video_file": os.path.basename(output_path),
            "created": datetime.now().isoformat(),
        }
        info_path = output_path.replace(".mp4", "_upload_info.json")
        with open(info_path, "w", encoding="utf-8") as f:
            json.dump(upload_info, f, ensure_ascii=False, indent=2)

        size_mb = os.path.getsize(output_path) / (1024 * 1024)
        print(f"\nğŸ‰ ì™„ë£Œ! {output_path} ({size_mb:.1f}MB, {duration_sec:.1f}ì´ˆ)")
        return

    # â”€â”€ ì˜ìƒ í¸ì§‘ ëª¨ë“œ (--video-edit) â”€â”€
    if args.video_edit:
        if not args.url:
            print("âŒ --video-edit ëª¨ë“œì—ëŠ” --url í•„ìˆ˜!")
            print("   python main.py --url 'https://...' --video-edit")
            sys.exit(1)

        editor = VideoAutoEditor(config)
        result = await editor.process_url_async(args.url)
        if result:
            print(f"\nğŸ‰ ì˜ìƒ ìˆì¸  ë³€í™˜ ì™„ë£Œ: {result}")
        else:
            print("ğŸ˜¢ ì˜ìƒ í¸ì§‘ ì‹¤íŒ¨")
        return

    # â”€â”€ ì¼ë°˜ ëª¨ë“œ (í¬ë¡¤ë§ â†’ ëŒ€ë³¸ â†’ TTS â†’ ì˜ìƒ) â”€â”€
    if not config.apify_api_token:
        print("âš ï¸  APIFY_API_TOKEN ë¯¸ì„¤ì • â†’ í´ë°± í¬ë¡¤ë§")

    factory = ShortsFactory(config)
    results = await factory.run()

    if results:
        print("ğŸ‰ ì™„ë£Œ!")
    else:
        print("ğŸ˜¢ ìƒì„±ëœ ì˜ìƒ ì—†ìŒ")


if __name__ == "__main__":
    asyncio.run(main())
